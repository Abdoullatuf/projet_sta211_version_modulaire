    "# ğŸ“Š STA211 - EDA & PrÃ©traitement des DonnÃ©es"
    "Ce notebook rÃ©alise lâ€™analyse exploratoire des donnÃ©es (EDA) et le prÃ©traitement du dataset **Internet Advertisements** dans le cadre du module **STA211**. Lâ€™objectif est de prÃ©dire si une image est une publicitÃ© (`ad.`) ou non (`noad.`), en optimisant le **score F1** sur un jeu de test.\n",
    "## ğŸ” Objectifs :\n",
    "- **Explorer les caractÃ©ristiques du dataset**\n",
    "  - Dimensions des donnÃ©es (2459 lignes dâ€™entraÃ®nement, 820 lignes de test, 1558 variables explicatives).\n",
    "  - Types de variables : 3 quantitatives (gÃ©omÃ©trie des images) et 1555 binaires (mots-clÃ©s, URL, etc.).\n",
    "  - Distribution des classes : analyse du dÃ©sÃ©quilibre (13.99% `ad.` vs 86.01% `noad.`).\n",
    "- **Analyser la qualitÃ© des donnÃ©es**\n",
    "  - DÃ©tecter et traiter les valeurs aberrantes (outliers).\n",
    "  - VÃ©rifier la cohÃ©rence des donnÃ©es (types, valeurs inattendues).\n",
    "  - Distributions univariÃ©es (histogrammes, box-plots, QQ-plots).\n",
    "  - CorrÃ©lations bivariÃ©es et multivariÃ©es (ACP, AFM, cartes de Kohonen).\n",
    "  - Identification des mots-clÃ©s les plus discriminants pour la classe `ad.`.\n",
    "- **PrÃ©traiter les donnÃ©es pour la modÃ©lisation**\n",
    "  - Encodage de la variable cible (`ad.`/`noad.` â†’ 1/0).\n",
    "  - Transformation des variables quantitatives (Yeo-Johnson, discrÃ©tisation).\n",
    "  - Gestion du dÃ©sÃ©quilibre via SMOTE ou pondÃ©ration des classes.\n",
    "  - SÃ©paration train/test stratifiÃ©e (80-20) pour validation.\n",
    "# DÃ©finition des mÃ©tadonnÃ©es du projet\n",
    "**Objectif** : DÃ©finir les mÃ©tadonnÃ©es du projet pour assurer la traÃ§abilitÃ© et la reproductibilitÃ© du notebook. Ces informations identifient le projet, lâ€™auteur, la version, et la pÃ©riode de rÃ©alisation.\n",
    "**Contexte** : Dans le cadre du challenge *Internet Advertisements*, ces mÃ©tadonnÃ©es servent Ã  documenter le travail rÃ©alisÃ© pour la classification binaire (`ad.` vs `noad.`) et Ã  faciliter lâ€™Ã©valuation pÃ©dagogique.\n",
    "**MÃ©thodologie** : Les mÃ©tadonnÃ©es sont stockÃ©es dans des variables globales et affichÃ©es pour confirmation. Une date dynamique est utilisÃ©e pour reflÃ©ter le moment de lâ€™exÃ©cution.\n",
    "**Prochaines Ã©tapes** : Configurer lâ€™environnement et charger les donnÃ©es (section suivante)."
   "execution_count": null,
   "outputs": [],
    "## DÃ©finition des mÃ©tadonnÃ©es du projet\n",
    "# MÃ©tadonnÃ©es du projet\n",
    "# VÃ©rification des mÃ©tadonnÃ©es\n",
    "print(\"ğŸ“‹ MÃ©tadonnÃ©es du projet\")\n",
    "        raise TypeError(f\"La mÃ©tadonnÃ©e '{key}' doit Ãªtre une chaÃ®ne de caractÃ¨res, reÃ§u {type(value)}\")\n",
    "# Sauvegarde des mÃ©tadonnÃ©es dans un fichier (optionnel)\n",
    "print(f\"âœ… MÃ©tadonnÃ©es sauvegardÃ©es dans : {metadata_file}\")"
    "# Table des matiÃ¨res\n",
    "    - 2.2 [Import des bibliothÃ¨ques](#import-des-bibliotheques)\n",
    "    - 2.3 [Configuration des paramÃ¨tres du projet](#configuration-parametres-projet)\n",
    "3. [Chargement et aperÃ§u des donnÃ©es](#chargement-et-apercu-des-donnees)\n",
    "    - 3.1 [Chargement des jeux de donnÃ©es bruts](#chargement-des-jeux-de-donnees-bruts)\n",
    "    - 4.4 [Analyse des corrÃ©lations](#analyse-des-correlations)\n",
    "5. [PrÃ©traitement avancÃ©](#pretraitement-avance)\n",
    "    - 5.2 [DÃ©tection et suppression des outliers](#detection-et-suppression-des-outliers)\n",
    "        - 5.3.1 [Imputation de X4 par la mÃ©diane](#imputation-x4-mediane)\n",
    "        - 5.3.2 [PrÃ©paration pour l'imputation multivariÃ©e](#preparation-imputation-multivariee)\n",
    "    - 5.4 [DÃ©tection et traitement des variables collinÃ©aires](#detection-et-traitement-des-variables-collineaires)\n",
    "    - 6.1 [Application du pipeline de prÃ©traitement (KNN)](#pipeline-knn)\n",
    "    - 6.2 [Application du pipeline de prÃ©traitement (MICE)](#pipeline-mice)\n",
    "    - 6.3 [Comparaison des mÃ©thodes d'imputation](#comparaison-methodes)\n",
    "    - 6.4 [GÃ©nÃ©ration des fichiers pour la modÃ©lisation](#generation-des-fichiers-pour-la-modelisation)\n",
    "7. [Validation du prÃ©traitement](#validation-pretraitement)\n",
    "    - 7.1 [VÃ©rification de la qualitÃ© des donnÃ©es](#verification-qualite)\n",
    "9. [Annexes / Visualisations complÃ©mentaires](#annexes)"
   "execution_count": null,
   "outputs": [],
    "# Installation des packages (dÃ©commenter si nÃ©cessaire)\n",
    "# ğŸ” DÃ©tection de l'environnement\n",
    "print(f\"ğŸ”§ Environnement dÃ©tectÃ© : {ENV}\")\n",
    "# ğŸš— Montage de Google Drive si nÃ©cessaire\n",
    "    print(\"âœ… Google Drive montÃ© avec succÃ¨s\")\n",
    "# ğŸ“ DÃ©finir les chemins selon lâ€™environnement\n",
    "    print(f\"âœ… Module path ajoutÃ© : {module_path}\")\n",
    "# ğŸ“¦ Chargement des chemins\n",
    "    print(\"âœ… Configuration des chemins rÃ©ussie\")\n",
    "    print(f\"âŒ Erreur : impossible d'importer setup_project_paths\")\n",
    "# ğŸ”§ Ajout manuel OUTPUTS_DIR si absent\n",
    "# ğŸ“‹ Affichage Markdown des chemins\n",
    "        key: \"âœ…\" if Path(path).exists() else \"âŒ\"\n",
    "### ğŸ“‚ **Chemins configurÃ©s pour le projet**\n",
    "**LÃ©gende :** âœ… = Existe | âŒ = N'existe pas\n",
    "# ğŸ”§ Infos systÃ¨me\n",
    "print(f\"\\nğŸ Python version : {sys.version.split()[0]}\")\n",
    "print(f\"ğŸ“ Working directory : {os.getcwd()}\")\n",
    "# ğŸ“Œ Variables globales\n",
    "# ğŸ“Œ Fichiers finaux filtrÃ©s (MICE)\n",
    "# (optionnel) Fichiers finaux filtrÃ©s (KNN)\n",
    "## 2.2 Import des bibliothÃ¨ques"
   "execution_count": null,
   "outputs": [],
    "## 2.2 Import des bibliothÃ¨ques <a id=\"import-des-bibliotheques\"></a>\n",
    "# ğŸ“¦ Modules standards\n",
    "# ğŸ§® Manipulation des donnÃ©es\n",
    "# ğŸ“Š Visualisation\n",
    "# âš™ï¸ PrÃ©traitement & ModÃ¨les\n",
    "from sklearn.experimental import enable_iterative_imputer  # â¬…ï¸ NÃ©cessaire pour IterativeImputer\n",
    "# ğŸ“ˆ Statistiques\n",
    "# ğŸ” Optionnel : UMAP\n",
    "    print(\"âš ï¸ UMAP non disponible. Certaines visualisations seront dÃ©sactivÃ©es.\")\n",
    "# ğŸ² Configuration globale\n",
    "# DÃ©finition de RANDOM_STATE\n",
    "# ğŸ” VÃ©rification des modules critiques\n",
    "print(\"\\nğŸ” VÃ©rification des modules critiques :\")\n",
    "        print(f\"  âœ… {name}\")\n",
    "        print(f\"  âŒ {name} - problÃ¨me lors de l'import\")\n",
    "# âš™ï¸ RÃ©sumÃ© de configuration\n",
    "print(f\"\\nâš™ï¸ Configuration :\")\n",
    "## 2.3 Configuration des paramÃ¨tres du projet"
   "execution_count": null,
   "outputs": [],
    "## 2.3 Configuration des paramÃ¨tres du projet <a id=\"configuration-parametres-projet\"></a>\n",
    "# ğŸ“¦ Import de la classe ProjectConfig et de la fonction de crÃ©ation\n",
    "    print(\"âŒ Erreur : impossible d'importer depuis 'config.project_config'\")\n",
    "# ğŸ› ï¸ CrÃ©ation de la configuration avec les mÃ©tadonnÃ©es + chemins\n",
    "# ğŸ¯ Ciblage de la mÃ©trique F1 pour le challenge\n",
    "# ğŸ‘ï¸ Affichage de la configuration\n",
    "# ğŸ“Œ Exemples d'accÃ¨s Ã  des valeurs clÃ©s\n",
    "print(\"\\nğŸ“Œ Exemples d'accÃ¨s Ã  la configuration :\")\n",
    "print(f\"  - MÃ©thode d'imputation X4 : {config.get('PROJECT_CONFIG.IMPUTATION_METHODS.X4')}\")\n",
    "# ğŸ’¾ Sauvegarde de la configuration dans le dossier 'config'\n",
    "# ğŸŒ Rendre la configuration disponible globalement\n",
    "print(\"\\nâœ… Configuration chargÃ©e et disponible globalement\")\n"
    "# 3. Chargement et aperÃ§u des donnÃ©es <a id=\"chargement-et-apercu-des-donnees\"></a>\n",
    "## 3.1 Chargement des jeux de donnÃ©es bruts <a id=\"chargement-des-jeux-de-donnees-bruts\"></a>\n",
    "**Objectif** : Charger les datasets dâ€™entraÃ®nement (`data_train.csv`) et de test (`data_test.csv`), vÃ©rifier leur structure, et prÃ©parer la variable cible pour lâ€™analyse exploratoire.\n",
    "**ThÃ©orie** : Un chargement correct des donnÃ©es est essentiel pour garantir la reproductibilitÃ© et la validitÃ© des analyses. La vÃ©rification des dimensions et des types de donnÃ©es permet de dÃ©tecter les erreurs tÃ´t dans le processus.\n",
    "**MÃ©thodologie** : Nous utilisons la fonction `load_data` pour charger les fichiers CSV, nettoyons les donnÃ©es (suppression des guillemets, gestion des doublons), encodons la variable cible (`ad.` â†’ 1, `noad.` â†’ 0), et affichons un rÃ©sumÃ© des dimensions et types.\n",
    "**Prochaines Ã©tapes** : Inspecter les colonnes et types (section 3.2) et analyser la distribution de la variable cible (section 3.3)."
   "execution_count": null,
   "outputs": [],
    "## 3.1 Chargement des jeux de donnÃ©es bruts <a id=\"chargement-des-jeux-de-donnees-bruts\"></a>\n",
    "#from modules.preprocessing.data_loader import load_data  # en local si jamais ne fonctionne pas, dÃ©coche ce si.\n",
    "# ğŸ“ VÃ©rification de lâ€™existence du dossier RAW_DATA_DIR\n",
    "    raise NameError(\"âŒ RAW_DATA_DIR nâ€™est pas dÃ©fini. VÃ©rifiez la configuration dans la section 2.1.\")\n",
    "    raise FileNotFoundError(f\"âŒ Dossier RAW_DATA_DIR introuvable : {raw_data_dir}\")\n",
    "# ğŸ“‚ Chargement des fichiers CSV\n",
    "print(\"ğŸ“‚ Chargement des jeux de donnÃ©es...\")\n",
    "# ğŸ·ï¸ Renommer 'outcome' en 'y' si nÃ©cessaire\n",
    "    print(\"âœ… Colonne 'outcome' renommÃ©e en 'y'\")\n",
    "    raise ValueError(\"âŒ Colonne 'y' ou 'outcome' manquante dans df_study\")\n",
    "# ğŸ”¢ VÃ©rification des dimensions attendues\n",
    "    print(f\"âš ï¸ Dimensions inattendues pour df_study : {df_study.shape} (attendu : {expected_train_shape})\")\n",
    "    print(f\"âš ï¸ Dimensions inattendues pour df_eval : {df_eval.shape} (attendu : {expected_test_shape})\")\n",
    "# ğŸ” VÃ©rification de la variable cible\n",
    "print(\"\\nğŸ” Valeurs uniques de y :\", df_study['y'].unique())\n",
    "print(\"ğŸ” Type de y :\", df_study['y'].dtype)\n",
    "# ğŸ“Š RÃ©sumÃ©\n",
    "print(f\"\\nğŸ“Š RÃ©sumÃ© :\")\n",
    "print(f\"  - Fichier dâ€™Ã©tude     : {df_study.shape}\")\n",
    "print(f\"  - Fichier dâ€™Ã©valuation : {df_eval.shape}\")\n",
    "print(\"\\nâœ… Chargement terminÃ© avec succÃ¨s !\")\n"
   "execution_count": null,
   "outputs": [],
    "print(\"ğŸ” Inspection des types de donnÃ©es\")\n",
    "# ğŸ” RÃ©sumÃ© des types dans df_study\n",
    "print(\"\\nğŸ“Š Types de donnÃ©es dans df_study :\")\n",
    "# ğŸ“Œ Identification des colonnes par type\n",
    "# ğŸ” VÃ©rification binaire rÃ©elle parmi les colonnes int\n",
    "print(f\"\\nğŸ“ˆ Colonnes continues : {len(continuous_cols)}\")\n",
    "print(f\"ğŸ”¢ Colonnes binaires : {len(binary_cols)}\")\n",
    "print(f\"ğŸ“¦ Colonnes catÃ©gorielles : {len(categorical_cols)}\")\n",
    "    print(f\"âš ï¸ Colonnes int64 non binaires dÃ©tectÃ©es (extrait) : {non_binary_cols[:5]}\")\n",
    "# ğŸ¯ Variable cible 'y'\n",
    "    print(\"\\nğŸ¯ Variable cible 'y' :\")\n",
    "    print(\"âŒ La colonne cible 'y' est manquante\")\n",
    "# ğŸ”„ Comparaison avec df_eval\n",
    "print(\"\\nğŸ”„ Comparaison avec df_eval :\")\n",
    "# âš–ï¸ VÃ©rification des types entre df_study et df_eval\n",
    "print(\"\\nğŸ” VÃ©rification de la cohÃ©rence des types entre fichiers :\")\n",
    "    print(\"âš ï¸ IncohÃ©rences de type dÃ©tectÃ©es :\")\n",
    "        print(f\"  - {col}: {t1} (Ã©tude) vs {t2} (Ã©val)\")\n",
    "    print(\"âœ… Types cohÃ©rents entre df_study et df_eval\")\n",
    "# ğŸ’¾ Mise Ã  jour de la configuration\n",
    "print(\"\\nğŸ’¾ Mise Ã  jour de la configuration...\")\n",
    "# ğŸ“‹ RÃ©sumÃ© final\n",
    "print(\"\\nğŸ“Š RÃ©sumÃ© des colonnes (hors 'y') :\")\n",
    "print(f\"  - Colonnes catÃ©gorielles : {len(categorical_cols)}\")\n",
   "execution_count": null,
   "outputs": [],
    "print(\"\\nğŸ¯ Analyse de la distribution de la variable cible\")\n",
    "# VÃ©rification de la prÃ©sence de 'y'\n",
    "    raise ValueError(\"âŒ Colonne cible 'y' introuvable dans df_study\")\n",
    "print(\"\\nğŸ“Š Distribution de la variable cible (y) :\")\n",
    "# Ratio de dÃ©sÃ©quilibre\n",
    "print(f\"\\nğŸ“ˆ Ratio de dÃ©sÃ©quilibre : {imbalance_ratio:.2f}:1\")\n",
    "print(f\"   â†’ Pour chaque publicitÃ©, il y a {imbalance_ratio:.1f} non-publicitÃ©s\")\n",
    "ax1.set_ylabel('Nombre d\\'Ã©chantillons')\n",
    "ax1.set_xticklabels(['Non-publicitÃ© (0)', 'PublicitÃ© (1)'], rotation=0)\n",
    "# Sauvegarde sÃ©curisÃ©e dans un sous-dossier\n",
    "# Impact pour la modÃ©lisation\n",
    "print(\"\\nğŸ’¡ Implications pour la modÃ©lisation :\")\n",
    "print(f\"  - Dataset fortement dÃ©sÃ©quilibrÃ© ({imbalance_ratio:.1f}:1)\")\n",
    "print(\"  - StratÃ©gies recommandÃ©es :\")\n",
    "print(\"    â€¢ Utiliser stratify=True lors du train/test split\")\n",
    "print(\"    â€¢ Appliquer SMOTE ou class_weight='balanced'\")\n",
    "print(\"    â€¢ Optimiser pour F1-score (mÃ©trique du challenge)\")\n",
    "print(\"    â€¢ Envisager un stacking ou un modÃ¨le robuste aux dÃ©sÃ©quilibres\")\n",
    "p = target_pct[1] / 100  # PrÃ©cision et recall identiques si on prÃ©dit toujours 1\n",
    "print(f\"\\nğŸ“Š F1-score baseline (prÃ©dire toujours 'ad.') : {baseline_f1:.3f}\")\n",
    "print(\"   â†’ Les modÃ¨les devront dÃ©passer ce seuil pour Ãªtre utiles\")\n"
    "**Objectif** : Identifier les valeurs manquantes dans le dataset dâ€™entraÃ®nement et dâ€™Ã©valuation, analyser leur pattern (MCAR, MAR, MNAR), et proposer une stratÃ©gie dâ€™imputation adaptÃ©e.\n",
    "**ThÃ©orie** : Les valeurs manquantes peuvent Ãªtre MCAR (alÃ©atoires), MAR (liÃ©es Ã  dâ€™autres variables observÃ©es), ou MNAR (liÃ©es Ã  la variable elle-mÃªme). Une corrÃ©lation significative entre lâ€™indicateur de valeurs manquantes et la variable cible suggÃ¨re un pattern MAR, nÃ©cessitant une imputation sophistiquÃ©e (k-NN, MICE).\n",
    "**MÃ©thodologie** : Nous calculons le pourcentage de valeurs manquantes par colonne, visualisons leur pattern via une heatmap, et analysons la corrÃ©lation entre les indicateurs de valeurs manquantes et la variable cible encodÃ©e. Une stratÃ©gie dâ€™imputation est proposÃ©e en fonction des rÃ©sultats.\n",
    "**Prochaines Ã©tapes** : Si un pattern MAR est confirmÃ©, prÃ©parer une imputation multivariÃ©e (section 5.3). VÃ©rifier lâ€™impact des imputations sur les performances des modÃ¨les."
   "execution_count": null,
   "outputs": [],
    "print(\"ğŸ” Analyse des valeurs manquantes\")\n",
    "print(\"\\nğŸ“Š Analyse globale des valeurs manquantes :\")\n",
    "# Analyse dÃ©taillÃ©e pour les colonnes continues\n",
    "print(\"\\nğŸ“ˆ DÃ©tail des valeurs manquantes pour les variables continues :\")\n",
    "        # CrÃ©er une matrice binaire des valeurs manquantes\n",
    "        sns.heatmap(missing_matrix.T, cmap='RdYlBu', cbar_kws={'label': 'Manquant (1) / PrÃ©sent (0)'})\n",
    "        plt.xlabel('Ã‰chantillons')\n",
    "        print(\"\\nğŸ” Analyse du type de valeurs manquantes (MAR vs MCAR) :\")\n",
    "        # CorrÃ©lation entre les valeurs manquantes et la cible\n",
    "            print(f\"  - {col}: corrÃ©lation avec y = {correlation_with_target:.3f}\")\n",
    "                print(f\"    â†’ Potentiellement MAR (Missing At Random)\")\n",
    "                print(f\"    â†’ Potentiellement MCAR (Missing Completely At Random)\")\n",
    "    print(\"\\nâœ… Aucune valeur manquante dÃ©tectÃ©e dans le dataset !\")\n",
    "# Analyse pour le fichier d'Ã©valuation aussi\n",
    "print(\"\\nğŸ“Š Analyse des valeurs manquantes dans le fichier d'Ã©valuation :\")\n",
    "    print(\"\\nğŸ”„ Comparaison des patterns de valeurs manquantes :\")\n",
    "    print(f\"  - Fichier d'Ã©tude : {missing_stats['percent_missing']:.2f}% manquant\")\n",
    "    print(f\"  - Fichier d'Ã©valuation : {missing_stats_eval['percent_missing']:.2f}% manquant\")\n",
    "    # StratÃ©gie d'imputation recommandÃ©e\n",
    "    print(\"\\nğŸ’¡ StratÃ©gie d'imputation recommandÃ©e :\")\n",
    "            print(f\"  - X4 ({x4_missing_pct:.1f}% manquant) : Imputation par la mÃ©diane\")\n",
    "        print(f\"  - X1, X2, X3 (variables continues) : KNN ou MICE (imputation multivariÃ©e)\")"
   "execution_count": null,
   "outputs": [],
    "print(\"\\nğŸ”§ Correction du type de X4...\")\n",
    "# VÃ©rifier que X4 ne contient que 0 et 1\n",
    "    # Imputer d'abord les valeurs manquantes par la mÃ©diane\n",
    "    print(f\"âœ… X4 converti en int64 aprÃ¨s imputation par la mÃ©diane ({X4_median})\")\n",
    "    # Mettre Ã  jour la configuration\n",
    "    continuous_cols = ['X1', 'X2', 'X3']  # Mise Ã  jour locale\n",
    "    print(\"âš ï¸ X4 contient des valeurs autres que 0 et 1, conservation en float64\")\n",
    "\n",
    "# RÃ©sumÃ© final\n",
    "print(\"\\nğŸ“Š RÃ©sumÃ© des valeurs manquantes aprÃ¨s traitement de X4 :\")\n",
    "print(f\"  - X1, X2, X3 : ~27% manquant â†’ Ã€ traiter avec KNN/MICE\")\n",
    "print(f\"  - X4 : ImputÃ© et converti en binaire\")\n",
    "print(f\"  - Pattern MAR dÃ©tectÃ© pour X1, X2, X3 (corrÃ©lation avec y â‰ˆ -0.10)\")\n",
    "print(f\"  - Les patterns sont cohÃ©rents entre fichiers d'Ã©tude et d'Ã©valuation\")"
    "print(\"ğŸ“Š Analyse statistique des variables quantitatives\")\n",
    "# Lancement de lâ€™analyse complÃ¨te\n",
   "execution_count": null,
   "outputs": []
    "print(\"ğŸ“Š Visualisation des distributions et des boxplots\")\n",
   "execution_count": null,
   "outputs": []
    "## ğŸ“Š SynthÃ¨se de l'analyse statistique\n",
    "### Variables analysÃ©es : X1, X2, X3 (~1780 observations chacune)\n",
    "**ğŸ” Principales observations :**\n",
    "- **Distributions non-normales** : Toutes variables fortement asymÃ©triques (skewness : 1.6 Ã  7.1)\n",
    "- **293 outliers** dÃ©tectÃ©s (~16% des donnÃ©es)\n",
    "- **CorrÃ©lations notables** : X2-X3 (r=0.53), X1-X3 (r=-0.29)\n",
    "**âš ï¸ Points d'attention :**\n",
    "- Ã‰cart important moyenne/mÃ©diane pour toutes variables\n",
    "- X3 particuliÃ¨rement problÃ©matique (skewness=7.06, kurtosis=63.4)\n",
    "- Tests de Shapiro-Wilk : p<0.001 (rejet normalitÃ©)\n",
    "**ğŸ”„ Actions requises :**\n",
    "- **Transformation Yeo-Johnson** recommandÃ©e avant analyse paramÃ©trique\n",
    "- ConsidÃ©rer mÃ©thodes robustes/non-paramÃ©triques\n",
   "execution_count": null,
   "outputs": [],
    "print(\"ğŸ”¢ Analyse de la distribution des variables binaires\")\n",
    "print(f\"\\nğŸ“Š Nombre total de variables binaires : {len(binary_cols)}\")\n",
    "# Taux de prÃ©sence (valeurs Ã  1)\n",
    "print(f\"\\nğŸ“Š Statistiques des taux de prÃ©sence :\")\n",
    "print(f\"  - MÃ©diane : {presence_series.median():.2f}%\")\n",
    "# SparsitÃ© globale\n",
    "print(f\"\\nğŸ“Š SparsitÃ© globale : {sparsity:.2f}% de zÃ©ros\")\n",
    "plt.xlabel('Taux de prÃ©sence (%)')\n",
    "plt.title('Distribution des taux de prÃ©sence des variables binaires')\n",
    "print(\"\\nâœ… Analyse des variables binaires terminÃ©e\")\n",
    "print(\"   â†’ Dataset trÃ¨s sparse, adaptÃ© pour des mÃ©thodes de sÃ©lection de features\")\n"
    "## 4.5 Analyse des corrÃ©lations combinÃ©es <a id=\"analyse-correlations-combinees\"></a>\n",
   "execution_count": null,
   "outputs": [],
    "## 4.5 Analyse des corrÃ©lations combinÃ©es <a id=\"analyse-correlations-combinees\"></a>\n",
    "print(\"ğŸ”— Lancement de l'analyse combinÃ©e des corrÃ©lations (features â†” cible, features â†” features)...\")\n",
    "# Appel avec paramÃ¨tres personnalisÃ©s\n",
    "## ğŸ“Œ SynthÃ¨se de l'analyse des corrÃ©lations <a id=\"synthese-correlations\"></a>\n",
    "### ğŸ” CorrÃ©lations avec la variable cible (`y`)\n",
    "- âœ… **Meilleure variable prÃ©dictive continue** : `X2` avec une corrÃ©lation de **0.573**\n",
    "- ğŸ“‰ Les autres variables (continues ou binaires) ont une corrÃ©lation **faible Ã  modÃ©rÃ©e** avec `y` (souvent < 0.2)\n",
    "- â„¹ï¸ Cela suggÃ¨re que la **modÃ©lisation devra combiner plusieurs variables** pour Ãªtre efficace\n",
    "### ğŸ”— CorrÃ©lations entre variables\n",
    "- âš ï¸ **1 paire** de variables (binaires ou continues) prÃ©sente une **corrÃ©lation > 0.8**\n",
    "- âœ… **MulticolinÃ©aritÃ© faible** â†’ pas de besoin urgent de supprimer des variables continues\n",
    "- ğŸ“Š **3 506 paires** de variables binaires prÃ©sentent une corrÃ©lation **> 0.95**\n",
    "- ğŸ” Ces paires impliquent **de nombreuses variables dupliquÃ©es** ou trÃ¨s similaires\n",
    "- ğŸ§  Certaines variables sont impliquÃ©es dans **15+ paires corrÃ©lÃ©es**, suggÃ©rant des motifs de duplication\n",
    "### ğŸ§­ Recommandations\n",
    "- ğŸ§¹ Appliquer une **rÃ©duction de dimension** avant la modÃ©lisation :\n",
    "  - Utilisation de **PCA**, **autoencoders** ou sÃ©lection par importance (e.g. **Random Forest**)\n",
    "- ğŸ¯ Se concentrer sur `X2` et les variables binaires les plus corrÃ©lÃ©es Ã  `y` comme features de base\n",
   "execution_count": null,
   "outputs": [],
    "print(\"ğŸ“Š Visualisations exploratoires\")\n",
    "# Imports des fonctions refactorisÃ©es\n",
    "print(\"\\nğŸ“ˆ Distribution des variables continues par classe...\")\n",
    "# 2. Visualisation de la sparsitÃ©\n",
    "print(\"\\nğŸ“‰ Visualisation de la sparsitÃ© des donnÃ©es binaires...\")\n",
    "# 3. CorrÃ©lations des variables continues avec la cible\n",
    "print(\"\\nğŸ”— CorrÃ©lations des variables continues avec la cible...\")\n",
    "# 4. RÃ©duction de dimension avec UMAP / t-SNE / PCA\n",
    "print(\"\\nğŸ“Š Visualisation multidimensionnelle (PCA / t-SNE / UMAP)...\")\n",
    "df_study_viz['outcome'] = df_study_viz['y'].map({0: 'noad.', 1: 'ad.'})  # âœ… temporaire\n",
    "# ğŸ” Recalcul des corrÃ©lations si besoin\n",
   "execution_count": null,
   "outputs": []
    "print(\"\\nğŸŒ² Analyse de lâ€™importance des features...\")\n",
    "    df_importance = df_sample.copy()  # contient outcome dÃ©jÃ  transformÃ©e\n",
    "    print(f\"âš ï¸ Erreur lors de lâ€™analyse dâ€™importance des features : {e}\")\n",
    "# 6. RÃ©sumÃ© visuel global\n",
    "print(\"\\nğŸ“Š CrÃ©ation du rÃ©sumÃ© visuel de lâ€™EDA...\")\n",
    "print(\"\\nâœ… Visualisations exploratoires terminÃ©es avec succÃ¨s !\")"
   "execution_count": null,
   "outputs": []
    "## ğŸ§­ InterprÃ©tations synthÃ©tiques des rÃ©sultats de l'EDA <a id=\"interpretations-eda\"></a>\n",
    "### ğŸ¯ 1. Distribution des variables continues par classe\n",
    "- **X1, X2, X3** prÃ©sentent des distributions trÃ¨s diffÃ©rentes entre les deux classes (`ad.` vs `noad.`).\n",
    "- **X2** se distingue particuliÃ¨rement avec une sÃ©paration marquÃ©e entre les classes.\n",
    "- Les distributions sont asymÃ©triques, avec la prÃ©sence dâ€™**outliers** visibles dans chaque classe.\n",
    "### ğŸ§ª 2. CorrÃ©lations avec la variable cible\n",
    "- **X2** est la variable la plus corrÃ©lÃ©e avec la cible (`corr = 0.573`), ce qui en fait une **feature clÃ©**.\n",
    "- **X1** (`corr = 0.034`) et **X3** (`corr = 0.130`) ont des corrÃ©lations faibles mais non nÃ©gligeables.\n",
    "- Cela suggÃ¨re lâ€™utilitÃ© de **modÃ¨les non linÃ©aires** ou **ensemble methods** (e.g. Random Forest, Gradient Boosting).\n",
    "### ğŸ§¬ 3. Visualisation de la sparsitÃ© des variables binaires\n",
    "- Le dataset est **extrÃªmement sparse**, avec **99.2% de zÃ©ros** dans les variables binaires.\n",
    "  - Risque de surapprentissage Ã©levÃ© si toutes les variables sont conservÃ©es.\n",
    "  - NÃ©cessitÃ© de sÃ©lection de variables ou de techniques de rÃ©duction (PCA, autoencoders).\n",
    "  - Attention aux mÃ©thodes sensibles Ã  la densitÃ© (ex : k-NN).\n",
    "### ğŸ—ºï¸ 4. RÃ©sumÃ© visuel global\n",
    "- **DÃ©sÃ©quilibre important** : 86% `noad.` vs 14% `ad.` â†’ nÃ©cessite des stratÃ©gies adaptÃ©es :\n",
    "  - MÃ©triques robustes (F1-score, recall).\n",
    "  - RÃ©Ã©chantillonnage ou `class_weight='balanced'`.\n",
    "- **Valeurs manquantes** (~27%) dans X1, X2, X3 : Ã  imputer avec mÃ©thode robuste (KNN, MICE).\n",
    "- **Top corrÃ©lations** concentrÃ©es sur peu de variables â†’ importance dâ€™une **bonne sÃ©lection de features**.\n",
    "### âœ… Recommandations clÃ©s\n",
    "- **PrÃ©traitement renforcÃ©** :\n",
    "  - Transformation des variables continues (Yeo-Johnson recommandÃ©e).\n",
    "  - Suppression ou gestion des outliers extrÃªmes.\n",
    "- **RÃ©duction de dimension** :\n",
    "  - Visualisation UMAP/t-SNE utile pour vÃ©rifier la structure.\n",
    "  - SÃ©lection de features importante avant modÃ©lisation (selon importance ou redondance).\n",
    "- **RÃ©Ã©quilibrage des classes** indispensable pour Ã©viter un biais fort du modÃ¨le vers la classe majoritaire.\n",
    "# 5. PrÃ©traitement avancÃ© <a id=\"pretraitement-avance\"></a>\n"
    "#### ğŸ” Transformation des variables continues\n",
    "Les variables `X1`, `X2` et `X3` prÃ©sentent une forte asymÃ©trie positive ainsi que des valeurs extrÃªmes dÃ©tectÃ©es via la rÃ¨gle de lâ€™IQR.\n",
    "#### ğŸ“Œ Objectif :\n",
    "- RÃ©duire lâ€™impact des outliers\n",
    "- AmÃ©liorer la distribution pour les modÃ¨les sensibles Ã  la normalitÃ© (rÃ©gression logistique, kNNâ€¦)\n",
    "#### âš™ï¸ MÃ©thode :\n",
    "> ğŸ”§ Les colonnes transformÃ©es seront ajoutÃ©es en tant que `X1_trans`, `X2_trans` et `X3_trans`."
    "# VÃ©rification visuelle rapide des variables transformÃ©es\n",
   "execution_count": null,
   "outputs": []
    "# âœ… Liste des variables transformÃ©es\n",
    "# ğŸ“ Dossier de sauvegarde\n",
    "# ğŸ” GÃ©nÃ©ration et sauvegarde des figures\n",
    "    # ğŸ’¾ Sauvegarde\n",
    "    print(f\"âœ… Figure sauvegardÃ©e : {fig_path}\")\n"
   "execution_count": null,
   "outputs": []
    "### ğŸ” Transformation Yeo-Johnson des variables continues <a id=\"yeojohnson-interprÃ©tation\"></a>\n",
    "### RÃ©sultats visuels\n",
    "- âœ… **Meilleure symÃ©trie** des distributions.\n",
    "- âœ… **RÃ©duction de l'effet des outliers** (mÃªme si certains persistent, notamment sur `X2`).\n",
    "- âœ… **Concentration des valeurs** autour de la mÃ©diane, utile pour les modÃ¨les sensibles aux Ã©chelles et Ã  la normalitÃ©.\n",
    "### InterprÃ©tation\n",
    "| Variable   | RÃ©sultat aprÃ¨s transformation                             | Commentaire                                                                 |\n",
    "| `X1_trans` | Distribution plus centrÃ©e et symÃ©trique                   | Forte amÃ©lioration visuelle, outliers encore prÃ©sents mais moins extrÃªmes   |\n",
    "| `X2_trans` | Distribution toujours multimodale avec quelques extrÃªmes  | Transformation partiellement efficace â€“ normalisation partielle             |\n",
    "| `X3_trans` | Distribution globalement normalisÃ©e                       | TrÃ¨s bon rÃ©sultat â€“ faible asymÃ©trie et Ã©tendue rÃ©duite                     |\n",
    "### ğŸ“Œ Conclusion\n",
    "- La transformation **Yeo-Johnson** est efficace pour rÃ©duire l'asymÃ©trie des variables `X1`, `X2` et `X3`.\n",
    "- Elle **prÃ©pare les donnÃ©es Ã  des modÃ¨les linÃ©aires** ou sensibles aux distances (kNN, rÃ©gression).\n",
    "- Un **traitement complÃ©mentaire des outliers** peut Ãªtre envisagÃ©, surtout pour `X2`.\n"
    "## 5.2 DÃ©tection et suppression des outliers <a id=\"detection-et-suppression-des-outliers\"></a>\n",
    "### ğŸ¯ Objectifs :\n",
    "- Identifier les observations extrÃªmes susceptibles de perturber la modÃ©lisation.\n",
    "- Appliquer une stratÃ©gie de suppression uniquement sur les variables continues (`X1`, `X2`, `X3`), aprÃ¨s transformation.\n",
    "### ğŸ› ï¸ MÃ©thode :\n",
    "- Utilisation de la rÃ¨gle de lâ€™IQR (Interquartile Range).\n",
    "- Application sur les colonnes transformÃ©es : `X1_trans`, `X2_trans`, `X3_trans`.\n",
    "### ğŸ“‰ Impact attendu :\n",
    "- RÃ©duction de lâ€™effet des valeurs extrÃªmes sur les modÃ¨les sensibles.\n",
    "- Meilleure normalitÃ© aprÃ¨s transformation.\n",
    "- Perte contrÃ´lÃ©e dâ€™observations (gÃ©nÃ©ralement < 5%).\n",
    "### âœ… Ã‰tapes suivantes :\n",
    "1. DÃ©tection via IQR (Q1 - 1.5Ã—IQR, Q3 + 1.5Ã—IQR)\n",
    "2. Comptage des lignes extrÃªmes par variable\n",
    "4. Affichage du pourcentage de donnÃ©es supprimÃ©es\n",
    "> ğŸ” Cette Ã©tape ne sera appliquÃ©e que sur `df_study` (jeu d'entraÃ®nement).\n"
    "## 5.2 DÃ©tection et suppression des outliers <a id=\"detection-et-suppression-des-outliers\"></a>\n",
    "print(\"ğŸ” DÃ©tection et suppression des outliers (mÃ©thode IQR)\")\n",
    "# âœ… Variables Ã  traiter (transformÃ©es)\n",
    "# âœ… Sauvegarde de la version avant suppression\n",
    "# âœ… Chemin de sauvegarde aprÃ¨s nettoyage\n",
    "# âœ… Suppression des outliers avec export CSV\n",
    "# âœ… AperÃ§u statistique post-nettoyage\n",
    "print(\"\\nğŸ“Š Statistiques descriptives aprÃ¨s suppression des outliers :\")\n",
   "execution_count": null,
   "outputs": []
    "## ğŸ“Š Visualisation comparative avant/aprÃ¨s suppression des outliers\n",
    "# âœ… Comparaison visuelle avant / aprÃ¨s (X1_trans, X2_trans, X3_trans)\n",
   "execution_count": null,
   "outputs": []
    "## ğŸ“‰ Analyse des effets de la suppression des outliers <a id=\"effet-suppression-outliers\"></a>\n",
    "La dÃ©tection des outliers est effectuÃ©e sur les variables transformÃ©es (`X1_trans`, `X2_trans`, `X3_trans`) via la mÃ©thode de lâ€™IQR (Interquartile Range), afin de rÃ©duire lâ€™influence des valeurs extrÃªmes sur les modÃ¨les.\n",
    "### ğŸ” RÃ©sultats :\n",
    "#### âœ… **X1_trans**\n",
    "- **Avant** : prÃ©sence de plusieurs outliers extrÃªmes Ã  gauche et Ã  droite.\n",
    "- **AprÃ¨s** : distribution recentrÃ©e, disparition des extrÃªmes anormaux.\n",
    "- **Effet attendu** : meilleure stabilitÃ© pour les modÃ¨les linÃ©aires sensibles Ã  la variance.\n",
    "#### âœ… **X2_trans**\n",
    "- **Avant** : distribution asymÃ©trique avec une concentration importante dâ€™outliers Ã  gauche (valeurs faibles).\n",
    "- **AprÃ¨s** : distribution plus compacte, rÃ©duction de lâ€™asymÃ©trie, moins dâ€™observations extrÃªmes.\n",
    "- **Effet attendu** : amÃ©lioration de la normalitÃ© et du comportement statistique de la variable.\n",
    "#### âœ… **X3_trans**\n",
    "- **Avant** : trÃ¨s peu dâ€™outliers dÃ©tectÃ©s, distribution relativement homogÃ¨ne.\n",
    "- **AprÃ¨s** : suppression minimale, confirmant que X3_trans Ã©tait dÃ©jÃ  bien normalisÃ©e.\n",
    "- **Effet attendu** : impact marginal, mais bÃ©nÃ©fique pour les modÃ¨les robustes.\n",
    "### ğŸ¯ Conclusion :\n",
    "- La suppression des outliers permet dâ€™obtenir des distributions plus resserrÃ©es et symÃ©triques.\n",
    "- Elle amÃ©liore la qualitÃ© des donnÃ©es, tout en prÃ©servant la majoritÃ© des observations informatives.\n",
    "- Deux versions du dataset sont conservÃ©es :\n",
    "  - **Avec outliers** : pour tester la robustesse des modÃ¨les.\n",
    "  - **Sans outliers** : pour Ã©valuer les gains en stabilitÃ© et performance.\n"
    "La gestion des valeurs manquantes est cruciale pour garantir la qualitÃ© des analyses et des modÃ¨les.\n",
    "### ğŸ” Objectifs :\n",
    "- PrÃ©server la structure statistique du dataset\n",
    "### âš™ï¸ MÃ©thodologie adoptÃ©e :\n",
    "- Imputation simple (mÃ©diane) pour certaines variables\n",
    "- Sauvegarde des jeux de donnÃ©es imputÃ©s pour modÃ©lisation\n"
    "### âœ… 5.3.1 Imputation de X4 par la mÃ©diane <a id=\"imputation-x4-mediane\"></a>\n",
    "La variable `X4`, de type discrÃ¨te (0/1), a Ã©tÃ© imputÃ©e **prÃ©cocement par la mÃ©diane**, ce qui est adaptÃ© Ã  une variable binaire avec peu de valeurs manquantes.  \n",
    "â†’ Aucun traitement supplÃ©mentaire nâ€™est nÃ©cessaire ici.\n",
    "### ğŸš§ Prochaine Ã©tape : **imputation multiple** sur les variables continues `X1`, `X2`, `X3` via des mÃ©thodes plus robustes (KNN ou MICE).\n"
    "### 5.3.2 PrÃ©paration pour l'imputation multivariÃ©e <a id=\"preparation-imputation-multivariee\"></a>"
    "## 5.3.2 PrÃ©paration pour l'imputation multivariÃ©e <a id=\"preparation-imputation-multivariee\"></a>\n",
    "print(\"ğŸ”§ PrÃ©paration Ã  l'imputation multiple (KNN / MICE)\")\n",
    "# ğŸ“ Analyse sur les donnÃ©es AVEC outliers\n",
    "print(\"\\nğŸ“Š Analyse (donnÃ©es avec outliers)\")\n",
    "# âœ… Colonnes Ã  imputer (si moins de 30 % de valeurs manquantes)\n",
    "print(\"\\nğŸ“Œ Colonnes retenues (avec outliers) :\")\n",
    "# ğŸ“ Analyse sur les donnÃ©es SANS outliers\n",
    "print(\"\\nğŸ“Š Analyse (donnÃ©es sans outliers)\")\n",
    "print(\"\\nğŸ“Œ Colonnes retenues (sans outliers) :\")\n",
   "execution_count": null,
   "outputs": []
    "### 5.3.3 Imputation multivariÃ©e (MICE) <a id=\"imputation-multivariee-mice\"></a>"
    "#### Imputation MICE - donnÃ©es avec outliers"
    "#### Imputation multivariÃ©e (MICE) - donnÃ©es avec outliers\n",
    "print(\"ğŸ§© Imputation multivariÃ©e (donnÃ©es avec outliers)\")\n",
    "# ğŸ“Œ Colonnes concernÃ©es\n",
    "# ğŸ“ Chemin de sauvegarde du rÃ©sultat\n",
    "# âœ… Lancer l'imputation multiple sur les donnÃ©es avec outliers\n",
    "    mcar_cols=[],                      # X4 dÃ©jÃ  traitÃ©\n",
    "# ğŸ” AperÃ§u\n",
   "execution_count": null,
   "outputs": []
    "#### Imputation Mice - donnÃ©es avec outliers"
    "#### Imputation multivariÃ©e (MICE) - donnÃ©es sans outliers\n",
    "print(\"ğŸ§© Imputation multivariÃ©e (donnÃ©es sans outliers)\")\n",
    "# ğŸ“ Chemin de sauvegarde\n",
    "# âœ… Imputation sur les donnÃ©es nettoyÃ©es (sans outliers)\n",
    "    df=df_study,  # Ce DataFrame a les outliers supprimÃ©s\n",
    "    custom_filename=save_path_no_outliers.name  # âœ… Permet d'utiliser un nom de fichier personnalisÃ©\n",
    "# ğŸ” AperÃ§u des donnÃ©es imputÃ©es\n",
   "execution_count": null,
   "outputs": []
    "#### Coparaison imputation sur les donnÃ©es avec et sans outliers\n",
    "# Chargement des deux versions imputÃ©es\n",
    "# Variables Ã  comparer\n",
    "# CrÃ©ation des graphiques\n",
   "execution_count": null,
   "outputs": []
    "# ğŸ“ Chemins de sauvegarde\n",
    "# ğŸ” Recherche du k optimal pour KNN (avec outliers)\n",
    "print(\"ğŸ” Recherche du k optimal pour KNN Imputer (avec outliers)\")\n",
    "print(f\"âœ… k optimal dÃ©terminÃ© (avec outliers) : {optimal_k}\")\n",
    "# âœ… Imputation avec outliers\n",
    "# ğŸ” Recherche du k optimal pour KNN (sans outliers)\n",
    "print(\"\\nğŸ” Recherche du k optimal pour KNN Imputer (sans outliers)\")\n",
    "print(f\"âœ… k optimal dÃ©terminÃ© (sans outliers) : {optimal_k_no_outliers}\")\n",
    "# âœ… Imputation sans outliers\n",
   "execution_count": null,
   "outputs": []
    "## 5.4 DÃ©tection et traitement des variables collinÃ©aires <a id=\"detection-et-traitement-des-variables-collineaires\"></a>"
    "## 5.4 DÃ©tection et traitement des variables collinÃ©aires <a id=\"detection-et-traitement-des-variables-collineaires\"></a>\n",
    "print(f\"ğŸ”— {len(correlated_info['groups'])} groupes dÃ©tectÃ©s\")\n",
    "print(f\"âŒ {len(correlated_info['to_drop'])} variables Ã  supprimer\")\n",
   "execution_count": null,
   "outputs": []
    "### 5.4.1 Suppression des variables collinÃ©aires <a id=\"suppression-collineaires\"></a>"
    "print(\"ğŸ§¹ Suppression des variables fortement corrÃ©lÃ©es\")\n",
    "# Suppression pour les donnÃ©es imputÃ©es par MICE\n",
    "# Suppression pour les donnÃ©es imputÃ©es par KNN\n",
    "# VÃ©rification des dimensions\n",
    "print(f\"\\nğŸ“Š Dimensions aprÃ¨s suppression (MICE - avec outliers)     : {df_with_outliers_filtered.shape}\")\n",
    "print(f\"ğŸ“Š Dimensions aprÃ¨s suppression (MICE - sans outliers)     : {df_no_outliers_filtered.shape}\")\n",
    "print(f\"ğŸ“Š Dimensions aprÃ¨s suppression (KNN  - avec outliers)     : {df_with_outliers_filtered_knn.shape}\")\n",
    "print(f\"ğŸ“Š Dimensions aprÃ¨s suppression (KNN  - sans outliers)     : {df_no_outliers_filtered_knn.shape}\")\n"
   "execution_count": null,
   "outputs": []
    "### 5.4.2 Sauvegarde des datasets filtrÃ©s <a id=\"sauvegarde-datasets-filtres\"></a>\n"
    "### 5.4.2 Sauvegarde des datasets filtrÃ©s <a id=\"sauvegarde-datasets-filtres\"></a>\n",
    "print(\"ğŸ’¾ Sauvegarde des jeux de donnÃ©es filtrÃ©s\")\n",
    "# âœ… DÃ©finition du dossier de sauvegarde\n",
    "# === Sauvegarde des versions imputÃ©es par MICE ===\n",
    "print(f\"âœ… Fichier sauvegardÃ© : {mice_with_path}\")\n",
    "print(f\"âœ… Fichier sauvegardÃ© : {mice_no_path}\")\n",
    "# === Sauvegarde des versions imputÃ©es par KNN ===\n",
    "print(f\"âœ… Fichier sauvegardÃ© : {knn_with_path}\")\n",
    "print(f\"âœ… Fichier sauvegardÃ© : {knn_no_path}\")\n",
   "execution_count": null,
   "outputs": []
    "# ğŸ“ Chemins configurÃ©s automatiquement\n",
   "execution_count": null,
    "## 6.1 Application du pipeline de prÃ©traitement (KNN) <a id=\"pipeline-knn\"></a>"
    "# Imputation KNN â€“ sans outliers\n",
   "execution_count": null,
   "outputs": []
    "#Imputation KNN â€“ avec outliers\n",
    "# Appel du pipeline pour les donnÃ©es imputÃ©es par knn, avec outliers\n",
   "execution_count": null,
   "outputs": []
    "#Imputation KNN â€“ sans outliers\n",
    "# Appel du pipeline pour les donnÃ©es imputÃ©es par knn, sans outliers\n",
    "    save_transformer=False,  # dÃ©jÃ  sauvegardÃ© prÃ©cÃ©demment\n",
   "execution_count": null,
   "outputs": []
    "## 6.2 Application du pipeline de prÃ©traitement (MICE) <a id=\"pipeline-mice\"></a>"
    "    mar_method=\"mice\",                # MÃ©thode dâ€™imputation : MICE\n",
    "    correlation_threshold=0.95,       # Seuil pour corrÃ©lation\n",
    "    save_transformer=False,            # dÃ©jÃ  sauvegardÃ© prÃ©cÃ©demment\n",
    "    display_info=True                 # Affichage dÃ©taillÃ©\n",
   "execution_count": null,
   "outputs": []
    "    save_transformer=False,  # dÃ©jÃ  sauvegardÃ© prÃ©cÃ©demment\n",
   "execution_count": null,
   "outputs": []
    "## 6.3 Comparaison des mÃ©thodes d'imputation <a id=\"comparaison-methodes\"></a>"
    "# 7. Validation du prÃ©traitement <a id=\"validation-pretraitement\"></a>\n"
    "## 7.1 VÃ©rification de la qualitÃ© des donnÃ©es <a id=\"verification-qualite\"></a>"
    "# 9. Annexes / Visualisations complÃ©mentaires <a id=\"annexes\"></a>"
