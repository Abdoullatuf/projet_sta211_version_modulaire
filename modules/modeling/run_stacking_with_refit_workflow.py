# modules/modeling/run_stacking_with_refit_workflow.py

import logging
from pathlib import Path
import numpy as np
import joblib
import json
from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix

# Supposons que ces imports proviennent de vos modules ou sont d√©finis localement
# from modules.modeling.stacking_models_creator import create_stacking_models
# from modules.evaluation.evaluate_predictions import evaluate_from_probabilities

logger = logging.getLogger(__name__)

def run_stacking_with_refit(X_train, y_train, X_val, y_val, X_test, y_test,
                            imputation_method, models_dir, output_dir=None,
                            model_name_suffix="", create_stacking_func=None,
                            threshold_optimization_func=None,
                            stacking_model_key=None, context_name="notebook3"):
    """
    Ex√©cute le processus complet de stacking avec refit : cr√©ation, entra√Ænement,
    optimisation du seuil, √©valuation et sauvegarde.

    Args:
        X_train, y_train, X_val, y_val, X_test, y_test: Donn√©es d'entra√Ænement, validation et test.
        imputation_method (str): 'knn' ou 'mice'.
        models_dir (Path): Chemin du r√©pertoire de sauvegarde des mod√®les.
        output_dir (Path, optional): Chemin du r√©pertoire de sauvegarde des r√©sultats.
        model_name_suffix (str): Suffixe pour le nom du mod√®le (ex: '_reduced').
        create_stacking_func (callable, optional):
            Fonction pour cr√©er le mod√®le de stacking.
            Doit prendre `imputation_method` et `verbose` comme arguments.
            Si None, utilise `create_stacking_models` par d√©faut.
        threshold_optimization_func (callable, optional):
            Fonction personnalis√©e pour optimiser le seuil.
        stacking_model_key (str, optional):
            Cl√© pour extraire le mod√®le de stacking du dictionnaire retourn√© par create_stacking_func.
            N√©cessaire si create_stacking_func retourne un dict.
            Ex: 'stacking_classifier_knn' ou 'stacking_classifier_mice'.
        context_name (str, optional): Nom du contexte (par exemple, 'notebook2') pour organiser les sorties.
                                      La valeur par d√©faut est 'notebook3'.

    Returns:
        dict: Dictionnaire contenant le mod√®le, les m√©triques, le seuil et les chemins de sauvegarde.
              Retourne None en cas d'erreur.
    """
    logger.info(f"üîÑ D√©marrage du Stacking avec Refit - {imputation_method.upper()} {model_name_suffix}...")

    if output_dir is None:
        stacking_dir = Path(models_dir) / context_name / "stacking"
    else:
        stacking_dir = Path(output_dir)
    stacking_dir.mkdir(parents=True, exist_ok=True)

    results = {
        'model': None,
        'metrics': {},
        'threshold': None,
        'paths': {}
    }

    try:
        # --- 1. Cr√©ation du mod√®le ---
        if create_stacking_func is None:
            from modules.modeling.stacking_models_creator import create_stacking_models
            models_output = create_stacking_models(imputation_method=imputation_method, verbose=True)
        else:
            models_output = create_stacking_func(imputation_method=imputation_method, verbose=True)

        # Gestion du retour de la fonction de cr√©ation
        if isinstance(models_output, dict):
            # Cas o√π la fonction retourne un dictionnaire
            if stacking_model_key is None:
                 # Essayer de d√©duire la cl√© si elle n'est pas fournie
                 # Cela d√©pend de la convention de nommage de votre fonction create_stacking_models
                 default_key = f"stacking_classifier_{imputation_method}"
                 if default_key in models_output:
                     stacking_model_key = default_key
                 else:
                     # Si impossible de d√©duire, prendre la premi√®re cl√© ou lever une erreur
                     available_keys = list(models_output.keys())
                     if available_keys:
                         stacking_model_key = available_keys[0] # Prendre la premi√®re par d√©faut
                         logger.warning(f"Cl√© de mod√®le non sp√©cifi√©e. Utilisation de '{stacking_model_key}' parmi {available_keys}.")
                     else:
                         raise ValueError("La fonction create_stacking_func a retourn√© un dictionnaire vide.")

            if stacking_model_key not in models_output:
                raise KeyError(f"Cl√© '{stacking_model_key}' non trouv√©e dans le dictionnaire retourn√© par create_stacking_func. Cl√©s disponibles: {list(models_output.keys())}")

            stacking_model = models_output[stacking_model_key]
            logger.debug(f"‚úÖ Mod√®le extrait du dictionnaire avec la cl√© '{stacking_model_key}'.")
        else:
            # Cas o√π la fonction retourne directement le mod√®le
            stacking_model = models_output
            logger.debug("‚úÖ Mod√®le retourn√© directement par la fonction de cr√©ation.")

        if stacking_model is None:
            error_msg = f"√âchec de la cr√©ation du mod√®le Stacking pour {imputation_method}"
            logger.error(f"‚ùå {error_msg}")
            raise ValueError(error_msg)

        logger.info(f"‚úÖ Mod√®le Stacking {imputation_method.upper()} cr√©√©.")

        # --- 2. Entra√Ænement du mod√®le ---
        stacking_model.fit(X_train, y_train)
        logger.info(f"‚úÖ Mod√®le Stacking {imputation_method.upper()} entra√Æn√©.")

        # --- 3. Pr√©dictions sur Validation (pour optimisation du seuil) ---
        y_proba_val = stacking_model.predict_proba(X_val)[:, 1]

        # --- 4. Optimisation du seuil ---
        logger.info(f"üîç Optimisation du seuil pour {imputation_method.upper()}...")
        if threshold_optimization_func is None:
            best_threshold, best_f1_val = _optimize_threshold_internal(y_val, y_proba_val)
        else:
            best_threshold, best_f1_val = threshold_optimization_func(y_val, y_proba_val)

        logger.info(f"‚úÖ Seuil optimal {imputation_method.upper()}: {best_threshold:.3f} (F1-val: {best_f1_val:.4f})")
        results['threshold'] = best_threshold

        # --- 5. √âvaluation sur Test ---
        y_proba_test = stacking_model.predict_proba(X_test)[:, 1]
        y_pred_test = (y_proba_test >= best_threshold).astype(int)

        f1_test = f1_score(y_test, y_pred_test)
        precision_test = precision_score(y_test, y_pred_test)
        recall_test = recall_score(y_test, y_pred_test)
        cm_test = confusion_matrix(y_test, y_pred_test)

        logger.info(f"üìä R√©sultats sur Test - {imputation_method.upper()}{model_name_suffix}:")
        logger.info(f"   F1-score: {f1_test:.4f}")
        logger.info(f"   Pr√©cision: {precision_test:.4f}")
        logger.info(f"   Rappel: {recall_test:.4f}")

        results['model'] = stacking_model
        # Calcul des m√©triques de validation au seuil optimal
        y_pred_val_opt = (y_proba_val >= best_threshold).astype(int)
        results['metrics'] = {
            'f1_score_val': float(best_f1_val), # D√©j√† calcul√©
            'precision_val': float(precision_score(y_val, y_pred_val_opt)),
            'recall_val': float(recall_score(y_val, y_pred_val_opt)),
            'f1_score_test': float(f1_test),
            'precision_test': float(precision_test),
            'recall_test': float(recall_test),
            'confusion_matrix_test': cm_test.tolist()
        }

        # --- 6. Sauvegarde du mod√®le ---
        model_filename = f"stacking_{imputation_method}_with_refit{model_name_suffix}.joblib"
        model_path = stacking_dir / model_filename
        joblib.dump(stacking_model, model_path)
        logger.info(f"üíæ Mod√®le sauvegard√©: {model_path}")
        results['paths']['model'] = model_path

        # --- 7. Sauvegarde des r√©sultats (JSON) ---
        results_filename = f"stacking_with_refit_{imputation_method}{model_name_suffix}.json"
        results_path = stacking_dir / results_filename
        results_to_save = {
            "method": f"stacking_with_refit_{imputation_method}{model_name_suffix}",
            "threshold": float(best_threshold),
            "performance": results['metrics'],
            "predictions": {
                "test_proba": y_proba_test.tolist(),
                "test_pred": y_pred_test.tolist()
            }
        }
        with open(results_path, 'w') as f:
            json.dump(results_to_save, f, indent=4)
        logger.info(f"üíæ R√©sultats sauvegard√©s: {results_path}")
        results['paths']['results'] = results_path

    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution du Stacking avec Refit - {imputation_method.upper()}: {e}", exc_info=True)
        return None

    logger.info(f"üéâ Stacking avec Refit - {imputation_method.upper()} {model_name_suffix} termin√©.")
    return results

def _optimize_threshold_internal(y_true, y_proba, metric='f1', thresholds=None):
    """Optimise un seuil de classification pour une m√©trique donn√©e (fonction interne)."""
    if thresholds is None:
        thresholds = np.linspace(0.2, 0.8, 61)

    best_score = -np.inf
    best_threshold = 0.5

    metric_funcs = {
        'f1': f1_score,
        'precision': precision_score,
        'recall': recall_score
    }

    if metric not in metric_funcs:
        raise ValueError(f"M√©trique '{metric}' non support√©e.")

    metric_func = metric_funcs[metric]

    for thr in thresholds:
        y_pred = (y_proba >= thr).astype(int)
        try:
            score = metric_func(y_true, y_pred)
            if np.isfinite(score) and score > best_score:
                best_score = score
                best_threshold = thr
        except Exception:
            pass # Ignore les erreurs de calcul

    return best_threshold, best_score

# --- Exemple d'utilisation ---
# 1. Si create_stacking_models retourne un dict et que vous connaissez la cl√©:
# results_knn = run_stacking_with_refit(
#     X_train_knn, y_train_knn, X_val_knn, y_val_knn, X_test_knn, y_test_knn,
#     imputation_method='knn',
#     models_dir=MODELS_DIR,
#     output_dir=Path("outputs/modeling/results"),
#     stacking_model_key='stacking_classifier_knn' # <-- Cl√© sp√©cifi√©e
# )
