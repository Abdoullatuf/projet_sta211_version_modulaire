{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# üìä STA211 - EDA & Pr√©traitement des Donn√©es"
   ],
   "metadata": {
    "id": "h4QEYEUsjVJi"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "-rzRNCNxx3Ph",
    "tags": []
   },
   "source": [
    "# 1. Introdcution <a id=\"1-introduction\"></a>\n",
    "\n",
    "Ce notebook r√©alise l‚Äôanalyse exploratoire des donn√©es (EDA) et le pr√©traitement du dataset **Internet Advertisements** dans le cadre du module **STA211**. L‚Äôobjectif est de pr√©dire si une image est une publicit√© (`ad.`) ou non (`noad.`), en optimisant le **score F1** sur un jeu de test.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Objectifs :\n",
    "- **Explorer les caract√©ristiques du dataset**\n",
    "  - Dimensions des donn√©es (2459 lignes d‚Äôentra√Ænement, 820 lignes de test, 1558 variables explicatives).\n",
    "  - Types de variables : 3 quantitatives (g√©om√©trie des images) et 1555 binaires (mots-cl√©s, URL, etc.).\n",
    "  - Distribution des classes : analyse du d√©s√©quilibre (13.99% `ad.` vs 86.01% `noad.`).\n",
    "\n",
    "- **Analyser la qualit√© des donn√©es**\n",
    "  - Identifier et imputer les valeurs manquantes (MCAR, MAR, MNAR).\n",
    "  - D√©tecter et traiter les valeurs aberrantes (outliers).\n",
    "  - V√©rifier la coh√©rence des donn√©es (types, valeurs inattendues).\n",
    "\n",
    "- **Analyser les relations entre variables**\n",
    "  - Distributions univari√©es (histogrammes, box-plots, QQ-plots).\n",
    "  - Corr√©lations bivari√©es et multivari√©es (ACP, AFM, cartes de Kohonen).\n",
    "  - Identification des mots-cl√©s les plus discriminants pour la classe `ad.`.\n",
    "\n",
    "- **Pr√©traiter les donn√©es pour la mod√©lisation**\n",
    "  - Encodage de la variable cible (`ad.`/`noad.` ‚Üí 1/0).\n",
    "  - Transformation des variables quantitatives (Yeo-Johnson, discr√©tisation).\n",
    "  - Gestion du d√©s√©quilibre via SMOTE ou pond√©ration des classes.\n",
    "  - S√©paration train/test stratifi√©e (80-20) pour validation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExogOKdqMpjt"
   },
   "source": [
    "# D√©finition des m√©tadonn√©es du projet\n",
    "\n",
    "**Objectif** : D√©finir les m√©tadonn√©es du projet pour assurer la tra√ßabilit√© et la reproductibilit√© du notebook. Ces informations identifient le projet, l‚Äôauteur, la version, et la p√©riode de r√©alisation.\n",
    "\n",
    "**Contexte** : Dans le cadre du challenge *Internet Advertisements*, ces m√©tadonn√©es servent √† documenter le travail r√©alis√© pour la classification binaire (`ad.` vs `noad.`) et √† faciliter l‚Äô√©valuation p√©dagogique.\n",
    "\n",
    "**M√©thodologie** : Les m√©tadonn√©es sont stock√©es dans des variables globales et affich√©es pour confirmation. Une date dynamique est utilis√©e pour refl√©ter le moment de l‚Äôex√©cution.\n",
    "\n",
    "**Prochaines √©tapes** : Configurer l‚Äôenvironnement et charger les donn√©es (section suivante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umWo1Adux9f4",
    "outputId": "b34234c9-dbf3-4afb-b11d-d7df2c2a0470",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319594419,
     "user_tz": -120,
     "elapsed": 13,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    }
   },
   "outputs": [],
   "source": [
    "## D√©finition des m√©tadonn√©es du projet\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# M√©tadonn√©es du projet\n",
    "PROJECT_NAME = \"Projet STA 211: Internet Advertisements Classification\"\n",
    "DATASET_NAME = \"Internet Advertisements Dataset\"\n",
    "AUTHOR = \"Abdoullatuf\"\n",
    "DATE = datetime.now().strftime(\"%Y-%m-%d\")  # Date dynamique\n",
    "VERSION = \"1.0\"\n",
    "\n",
    "# V√©rification des m√©tadonn√©es\n",
    "metadata = {\n",
    "    \"Projet\": PROJECT_NAME,\n",
    "    \"Dataset\": DATASET_NAME,\n",
    "    \"Auteur\": AUTHOR,\n",
    "    \"Date\": DATE,\n",
    "    \"Version\": VERSION\n",
    "}\n",
    "\n",
    "# Affichage des informations\n",
    "print(\"üìã M√©tadonn√©es du projet\")\n",
    "print(\"=\"*60)\n",
    "for key, value in metadata.items():\n",
    "    if not isinstance(value, str):\n",
    "        raise TypeError(f\"La m√©tadonn√©e '{key}' doit √™tre une cha√Æne de caract√®res, re√ßu {type(value)}\")\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Sauvegarde des m√©tadonn√©es dans un fichier (optionnel)\n",
    "METADATA_DIR = Path(\"metadata\")\n",
    "METADATA_DIR.mkdir(exist_ok=True)\n",
    "metadata_file = METADATA_DIR / f\"metadata_v{VERSION}.txt\"\n",
    "with open(metadata_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for key, value in metadata.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "print(f\"‚úÖ M√©tadonn√©es sauvegard√©es dans : {metadata_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table des mati√®res\n",
    "1. [Introduction](#introduction)\n",
    "2. [Configuration de l'environnement et imports](#configuration-environnement-imports)\n",
    "    - 2.1 [Configuration de l'environnement](#configuration-environnement)\n",
    "    - 2.2 [Import des biblioth√®ques](#import-des-bibliotheques)\n",
    "    - 2.3 [Configuration des param√®tres du projet](#configuration-parametres-projet)\n",
    "3. [Chargement et aper√ßu des donn√©es](#chargement-et-apercu-des-donnees)\n",
    "    - 3.1 [Chargement des jeux de donn√©es bruts](#chargement-des-jeux-de-donnees-bruts)\n",
    "    - 3.2 [Inspection des colonnes et types](#inspection-des-colonnes-et-types)\n",
    "    - 3.3 [Distribution de la variable cible](#distribution-variable-cible)\n",
    "4. [Analyse exploratoire](#analyse-exploratoire)\n",
    "    - 4.1 [Analyse des valeurs manquantes](#analyse-des-valeurs-manquantes)\n",
    "    - 4.2 [Analyse statistique des variables quantitatives](#analyse-statistique-des-variables-quantitatives)\n",
    "    - 4.3 [Distribution des variables binaires](#distribution-des-variables-binaires)\n",
    "    - 4.4 [Analyse des corr√©lations](#analyse-des-correlations)\n",
    "    - 4.5 [Visualisations exploratoires](#visualisations-exploratoires)\n",
    "5. [Pr√©traitement avanc√©](#pretraitement-avance)\n",
    "    - 5.1 [Transformation Yeo-Johnson sur X1, X2, X3](#transformation-yeo-johnson)\n",
    "    - 5.2 [D√©tection et suppression des outliers](#detection-et-suppression-des-outliers)\n",
    "    - 5.3 [Gestion des valeurs manquantes](#gestion-des-valeurs-manquantes)\n",
    "        - 5.3.1 [Imputation de X4 par la m√©diane](#imputation-x4-mediane)\n",
    "        - 5.3.2 [Pr√©paration pour l'imputation multivari√©e](#preparation-imputation-multivariee)\n",
    "        - 5.3.3 [Imputation MICE](#imputation-mice)\n",
    "        - 5.3.4 [Imputation par KNN](#imputation-knn)\n",
    "    - 5.4 [D√©tection et traitement des variables collin√©aires](#detection-et-traitement-des-variables-collineaires)\n",
    "6. [Construction des datasets finaux](#construction-des-datasets-finaux)\n",
    "    - 6.1 [Application du pipeline de pr√©traitement (KNN)](#pipeline-knn)\n",
    "    - 6.2 [Application du pipeline de pr√©traitement (MICE)](#pipeline-mice)\n",
    "    - 6.3 [Comparaison des m√©thodes d'imputation](#comparaison-methodes)\n",
    "    - 6.4 [G√©n√©ration des fichiers pour la mod√©lisation](#generation-des-fichiers-pour-la-modelisation)\n",
    "7. [Validation du pr√©traitement](#validation-pretraitement)\n",
    "    - 7.1 [V√©rification de la qualit√© des donn√©es](#verification-qualite)\n",
    "    - 7.2 [Statistiques finales](#statistiques-finales)\n",
    "8. [Conclusion](#conclusion)\n",
    "9. [Annexes / Visualisations compl√©mentaires](#annexes)"
   ],
   "metadata": {
    "id": "SgODm9LW8ADx"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkYOO1d03THK"
   },
   "source": [
    "# 2. Configuration de l'environnement et imports <a id=\"2-configuration-de-lenvironnement-et-imports\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 2.1 Configuration de l'environnement <a id=\"21-configuration-de-lenvironnement\"></a>"
   ],
   "metadata": {
    "id": "7kII8oGxi-fe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "_K4u8hOu3jqA",
    "outputId": "c86d02ae-2eeb-4c60-e30a-6e4018df9bcc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319609864,
     "user_tz": -120,
     "elapsed": 15442,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    }
   },
   "outputs": [],
   "source": [
    "## 2.1 Configuration de l'environnement <a id=\"configuration-environnement\"></a>\n",
    "\n",
    "# Installation des packages (d√©commenter si n√©cessaire)\n",
    "# !pip install -q scikit-learn xgboost lightgbm imbalanced-learn umap-learn prince\n",
    "!pip install -q scikit-learn imbalanced-learn umap-learn prince\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "\n",
    "# Configuration des warnings et de pandas\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# üîç D√©tection de l'environnement\n",
    "def detect_environment():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return \"colab\"\n",
    "    except ImportError:\n",
    "        return \"local\"\n",
    "\n",
    "ENV = detect_environment()\n",
    "print(f\"üîß Environnement d√©tect√© : {ENV}\")\n",
    "\n",
    "# üöó Montage de Google Drive si n√©cessaire\n",
    "if ENV == \"colab\":\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    print(\"‚úÖ Google Drive mont√© avec succ√®s\")\n",
    "\n",
    "# üìÅ D√©finir les chemins selon l‚Äôenvironnement\n",
    "if ENV == \"colab\":\n",
    "    module_path = Path(\"/content/drive/MyDrive/projet_sta211/modules\")\n",
    "else:\n",
    "    module_path = Path(\"G:/Mon Drive/projet_sta211/modules\")\n",
    "\n",
    "if str(module_path) not in sys.path:\n",
    "    sys.path.insert(0, str(module_path))\n",
    "    print(f\"‚úÖ Module path ajout√© : {module_path}\")\n",
    "\n",
    "# üì¶ Chargement des chemins\n",
    "try:\n",
    "    if ENV == \"colab\":\n",
    "        from config.paths_config import setup_project_paths\n",
    "    else:\n",
    "        from modules.config.paths_config import setup_project_paths\n",
    "\n",
    "    paths = setup_project_paths()\n",
    "    print(\"‚úÖ Configuration des chemins r√©ussie\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erreur : impossible d'importer setup_project_paths\")\n",
    "    raise\n",
    "\n",
    "# üîß Ajout manuel OUTPUTS_DIR si absent\n",
    "if \"OUTPUTS_DIR\" not in paths:\n",
    "    paths[\"OUTPUTS_DIR\"] = paths[\"ROOT_DIR\"] / \"outputs\"\n",
    "\n",
    "# üìã Affichage Markdown des chemins\n",
    "def display_paths():\n",
    "    status_icons = {\n",
    "        key: \"‚úÖ\" if Path(path).exists() else \"‚ùå\"\n",
    "        for key, path in paths.items()\n",
    "    }\n",
    "    paths_str = {k: str(v) for k, v in paths.items()}\n",
    "\n",
    "    md = f\"\"\"\n",
    "### üìÇ **Chemins configur√©s pour le projet**\n",
    "\n",
    "| Status | Nom du dossier      | Chemin                                        |\n",
    "|--------|---------------------|-----------------------------------------------|\n",
    "| {status_icons.get(\"ROOT_DIR\", \"?\")} | `ROOT_DIR`          | `{paths_str.get(\"ROOT_DIR\", \"\")}`             |\n",
    "| {status_icons.get(\"MODULE_DIR\", \"?\")} | `MODULE_DIR`        | `{paths_str.get(\"MODULE_DIR\", \"\")}`           |\n",
    "| {status_icons.get(\"RAW_DATA_DIR\", \"?\")} | `RAW_DATA_DIR`      | `{paths_str.get(\"RAW_DATA_DIR\", \"\")}`         |\n",
    "| {status_icons.get(\"DATA_PROCESSED\", \"?\")} | `DATA_PROCESSED`    | `{paths_str.get(\"DATA_PROCESSED\", \"\")}`       |\n",
    "| {status_icons.get(\"MODELS_DIR\", \"?\")} | `MODELS_DIR`        | `{paths_str.get(\"MODELS_DIR\", \"\")}`           |\n",
    "| {status_icons.get(\"FIGURES_DIR\", \"?\")} | `FIGURES_DIR`       | `{paths_str.get(\"FIGURES_DIR\", \"\")}`          |\n",
    "| {status_icons.get(\"OUTPUTS_DIR\", \"?\")} | `OUTPUTS_DIR`       | `{paths_str.get(\"OUTPUTS_DIR\", \"\")}`          |\n",
    "\n",
    "**L√©gende :** ‚úÖ = Existe | ‚ùå = N'existe pas\n",
    "\"\"\"\n",
    "    display(Markdown(md))\n",
    "\n",
    "display_paths()\n",
    "\n",
    "# üîß Infos syst√®me\n",
    "print(f\"\\nüêç Python version : {sys.version.split()[0]}\")\n",
    "print(f\"üìç Working directory : {os.getcwd()}\")\n",
    "\n",
    "# üìå Variables globales\n",
    "ROOT_DIR = paths[\"ROOT_DIR\"]\n",
    "MODULE_DIR = paths[\"MODULE_DIR\"]\n",
    "RAW_DATA_DIR = paths[\"RAW_DATA_DIR\"]\n",
    "DATA_PROCESSED = paths[\"DATA_PROCESSED\"]\n",
    "MODELS_DIR = paths[\"MODELS_DIR\"]\n",
    "FIGURES_DIR = paths[\"FIGURES_DIR\"]\n",
    "OUTPUTS_DIR = paths[\"OUTPUTS_DIR\"]\n",
    "\n",
    "\n",
    "# üìå Fichiers finaux filtr√©s (MICE)\n",
    "filtered_with_outliers_path = DATA_PROCESSED / \"df_imputed_mice_filtered.csv\"\n",
    "filtered_no_outliers_path = DATA_PROCESSED / \"df_imputed_no_outliers_mice_filtered.csv\"\n",
    "\n",
    "# (optionnel) Fichiers finaux filtr√©s (KNN)\n",
    "filtered_with_outliers_knn_path = DATA_PROCESSED / \"df_imputed_knn_filtered.csv\"\n",
    "filtered_no_outliers_knn_path = DATA_PROCESSED / \"df_imputed_no_outliers_knn_filtered.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9VPOgX1352s"
   },
   "source": [
    "## 2.2 Import des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjIeUeVx6Bhm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319635334,
     "user_tz": -120,
     "elapsed": 25463,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8f7ca106-2a7c-4437-b7f9-bf00e662333e"
   },
   "outputs": [],
   "source": [
    "## 2.2 Import des biblioth√®ques <a id=\"import-des-bibliotheques\"></a>\n",
    "\n",
    "# üì¶ Modules standards\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# üßÆ Manipulation des donn√©es\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# üìä Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ‚öôÔ∏è Pr√©traitement & Mod√®les\n",
    "from sklearn.experimental import enable_iterative_imputer  # ‚¨ÖÔ∏è N√©cessaire pour IterativeImputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "\n",
    "\n",
    "# üìà Statistiques\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "# üîÅ Optionnel : UMAP\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    UMAP_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è UMAP non disponible. Certaines visualisations seront d√©sactiv√©es.\")\n",
    "\n",
    "# üé≤ Configuration globale\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.float_format\", '{:.4f}'.format)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# D√©finition de RANDOM_STATE\n",
    "if \"RANDOM_STATE\" not in globals():\n",
    "    RANDOM_STATE = 42\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# üîç V√©rification des modules critiques\n",
    "print(\"\\nüîç V√©rification des modules critiques :\")\n",
    "import sklearn  # Ajout explicite\n",
    "\n",
    "required_modules = {\n",
    "    \"pandas\": pd,\n",
    "    \"numpy\": np,\n",
    "    \"scikit-learn\": sklearn,\n",
    "    \"matplotlib\": plt,\n",
    "    \"seaborn\": sns\n",
    "}\n",
    "\n",
    "for name, alias in required_modules.items():\n",
    "    try:\n",
    "        _ = eval(alias) if isinstance(alias, str) else alias\n",
    "        print(f\"  ‚úÖ {name}\")\n",
    "    except Exception:\n",
    "        print(f\"  ‚ùå {name} - probl√®me lors de l'import\")\n",
    "\n",
    "# ‚öôÔ∏è R√©sum√© de configuration\n",
    "print(f\"\\n‚öôÔ∏è Configuration :\")\n",
    "print(f\"  - Random State : {RANDOM_STATE}\")\n",
    "print(f\"  - Style matplotlib : seaborn-whitegrid\")\n",
    "print(f\"  - Palette seaborn : husl\")\n",
    "print(f\"  - UMAP disponible : {UMAP_AVAILABLE}\")\n",
    "print(f\"  - Python : {sys.version.split()[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izxedrQ239md"
   },
   "source": [
    "## 2.3 Configuration des param√®tres du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOduQSS76WyV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319635335,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e3551776-05b5-4e49-e615-8d9addc1d139"
   },
   "outputs": [],
   "source": [
    "## 2.3 Configuration des param√®tres du projet <a id=\"configuration-parametres-projet\"></a>\n",
    "\n",
    "# üì¶ Import de la classe ProjectConfig et de la fonction de cr√©ation\n",
    "try:\n",
    "    from config.project_config import ProjectConfig, create_config\n",
    "except ImportError as e:\n",
    "    print(\"‚ùå Erreur : impossible d'importer depuis 'config.project_config'\")\n",
    "    raise\n",
    "\n",
    "# üõ†Ô∏è Cr√©ation de la configuration avec les m√©tadonn√©es + chemins\n",
    "config = create_config(\n",
    "    project_name=PROJECT_NAME,\n",
    "    version=VERSION,\n",
    "    author=AUTHOR,\n",
    "    paths=paths\n",
    ")\n",
    "\n",
    "# üéØ Ciblage de la m√©trique F1 pour le challenge\n",
    "config.update(\"PROJECT_CONFIG.SCORING\", \"f1\")\n",
    "config.update(\"PROJECT_CONFIG.SCORING_METRICS\", [\"f1\", \"roc_auc\", \"precision\", \"recall\"])\n",
    "config.update(\"PROJECT_CONFIG.PRIMARY_METRIC\", \"f1\")\n",
    "\n",
    "# üëÅÔ∏è Affichage de la configuration\n",
    "config.display_config()\n",
    "\n",
    "# üìå Exemples d'acc√®s √† des valeurs cl√©s\n",
    "print(\"\\nüìå Exemples d'acc√®s √† la configuration :\")\n",
    "print(f\"  - Test size : {config.get('PROJECT_CONFIG.TEST_SIZE')}\")\n",
    "print(f\"  - M√©thode d'imputation X4 : {config.get('PROJECT_CONFIG.IMPUTATION_METHODS.X4')}\")\n",
    "print(f\"  - Taille des figures : {config.get('VIZ_CONFIG.figure_size')}\")\n",
    "\n",
    "# üíæ Sauvegarde de la configuration dans le dossier 'config'\n",
    "config_file = Path(paths[\"ROOT_DIR\"]) / \"config\" / f\"project_config_v{VERSION}.json\"\n",
    "config.save_config(config_file)\n",
    "\n",
    "# üåç Rendre la configuration disponible globalement\n",
    "PROJECT_CONFIG = config.PROJECT_CONFIG\n",
    "COLUMN_CONFIG = config.COLUMN_CONFIG\n",
    "VIZ_CONFIG = config.VIZ_CONFIG\n",
    "MODEL_CONFIG = config.MODEL_CONFIG\n",
    "PIPELINE_CONFIG = config.PIPELINE_CONFIG\n",
    "SAVE_PATHS = config.SAVE_PATHS\n",
    "F1_OPTIMIZATION = config.F1_OPTIMIZATION\n",
    "\n",
    "print(\"\\n‚úÖ Configuration charg√©e et disponible globalement\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQsM02yU4D56"
   },
   "source": [
    "# 3. Chargement et aper√ßu des donn√©es <a id=\"chargement-et-apercu-des-donnees\"></a>\n",
    "## 3.1 Chargement des jeux de donn√©es bruts <a id=\"chargement-des-jeux-de-donnees-bruts\"></a>\n",
    "\n",
    "**Objectif** : Charger les datasets d‚Äôentra√Ænement (`data_train.csv`) et de test (`data_test.csv`), v√©rifier leur structure, et pr√©parer la variable cible pour l‚Äôanalyse exploratoire.\n",
    "\n",
    "**Th√©orie** : Un chargement correct des donn√©es est essentiel pour garantir la reproductibilit√© et la validit√© des analyses. La v√©rification des dimensions et des types de donn√©es permet de d√©tecter les erreurs t√¥t dans le processus.\n",
    "\n",
    "**M√©thodologie** : Nous utilisons la fonction `load_data` pour charger les fichiers CSV, nettoyons les donn√©es (suppression des guillemets, gestion des doublons), encodons la variable cible (`ad.` ‚Üí 1, `noad.` ‚Üí 0), et affichons un r√©sum√© des dimensions et types.\n",
    "\n",
    "**Prochaines √©tapes** : Inspecter les colonnes et types (section 3.2) et analyser la distribution de la variable cible (section 3.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2QRC-c26i4y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319638135,
     "user_tz": -120,
     "elapsed": 2799,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "18ec2284-eb23-4acf-a4be-f0470f072066"
   },
   "outputs": [],
   "source": [
    "## 3.1 Chargement des jeux de donn√©es bruts <a id=\"chargement-des-jeux-de-donnees-bruts\"></a>\n",
    "\n",
    "from preprocessing.data_loader import load_data\n",
    "#from modules.preprocessing.data_loader import load_data  # en local si jamais ne fonctionne pas, d√©coche ce si.\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# üìÅ V√©rification de l‚Äôexistence du dossier RAW_DATA_DIR\n",
    "if 'RAW_DATA_DIR' not in globals():\n",
    "    raise NameError(\"‚ùå RAW_DATA_DIR n‚Äôest pas d√©fini. V√©rifiez la configuration dans la section 2.1.\")\n",
    "\n",
    "raw_data_dir = Path(RAW_DATA_DIR)\n",
    "if not raw_data_dir.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Dossier RAW_DATA_DIR introuvable : {raw_data_dir}\")\n",
    "\n",
    "# üìÇ Chargement des fichiers CSV\n",
    "print(\"üìÇ Chargement des jeux de donn√©es...\")\n",
    "\n",
    "df_study = load_data(\n",
    "    file_path=\"data_train.csv\",\n",
    "    require_outcome=True,\n",
    "    display_info=True,\n",
    "    raw_data_dir=RAW_DATA_DIR,\n",
    "    encode_target=True\n",
    ")\n",
    "\n",
    "df_eval = load_data(\n",
    "    file_path=\"data_test.csv\",\n",
    "    require_outcome=False,\n",
    "    display_info=True,\n",
    "    raw_data_dir=RAW_DATA_DIR,\n",
    "    encode_target=False\n",
    ")\n",
    "\n",
    "# üè∑Ô∏è Renommer 'outcome' en 'y' si n√©cessaire\n",
    "if 'outcome' in df_study.columns:\n",
    "    df_study = df_study.rename(columns={'outcome': 'y'})\n",
    "    print(\"‚úÖ Colonne 'outcome' renomm√©e en 'y'\")\n",
    "elif 'y' not in df_study.columns:\n",
    "    raise ValueError(\"‚ùå Colonne 'y' ou 'outcome' manquante dans df_study\")\n",
    "\n",
    "# üî¢ V√©rification des dimensions attendues\n",
    "expected_train_shape = (2459, 1559)\n",
    "expected_test_shape = (820, 1558)\n",
    "\n",
    "if df_study.shape != expected_train_shape:\n",
    "    print(f\"‚ö†Ô∏è Dimensions inattendues pour df_study : {df_study.shape} (attendu : {expected_train_shape})\")\n",
    "if df_eval.shape != expected_test_shape:\n",
    "    print(f\"‚ö†Ô∏è Dimensions inattendues pour df_eval : {df_eval.shape} (attendu : {expected_test_shape})\")\n",
    "\n",
    "# üîç V√©rification de la variable cible\n",
    "print(\"\\nüîé Valeurs uniques de y :\", df_study['y'].unique())\n",
    "print(\"üîé Type de y :\", df_study['y'].dtype)\n",
    "\n",
    "# üìä R√©sum√©\n",
    "print(f\"\\nüìä R√©sum√© :\")\n",
    "print(f\"  - Fichier d‚Äô√©tude     : {df_study.shape}\")\n",
    "print(f\"  - Fichier d‚Äô√©valuation : {df_eval.shape}\")\n",
    "print(\"\\n‚úÖ Chargement termin√© avec succ√®s !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qkz2-URf4KDn"
   },
   "source": [
    "## 3.2 Inspection des colonnes et types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HissG8dE6yC4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319638652,
     "user_tz": -120,
     "elapsed": 513,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "657a4305-08c6-437b-9544-a89ce6ca5c53"
   },
   "outputs": [],
   "source": [
    "## 3.2 Inspection des colonnes et types <a id=\"inspection-des-colonnes-et-types\"></a>\n",
    "\n",
    "print(\"üîç Inspection des types de donn√©es\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# üîé R√©sum√© des types dans df_study\n",
    "print(\"\\nüìä Types de donn√©es dans df_study :\")\n",
    "type_counts = df_study.dtypes.value_counts()\n",
    "for dtype, count in type_counts.items():\n",
    "    print(f\"  - {dtype}: {count} colonnes\")\n",
    "\n",
    "# üìå Identification des colonnes par type\n",
    "continuous_cols = df_study.select_dtypes(include=['float64']).columns.tolist()\n",
    "int_cols = df_study.select_dtypes(include=['int64']).columns.tolist()\n",
    "categorical_cols = df_study.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# üîÅ V√©rification binaire r√©elle parmi les colonnes int\n",
    "binary_cols = []\n",
    "non_binary_cols = []\n",
    "\n",
    "for col in int_cols:\n",
    "    unique_vals = df_study[col].dropna().unique()\n",
    "    if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1}):\n",
    "        binary_cols.append(col)\n",
    "    else:\n",
    "        non_binary_cols.append(col)\n",
    "\n",
    "print(f\"\\nüìà Colonnes continues : {len(continuous_cols)}\")\n",
    "print(f\"üî¢ Colonnes binaires : {len(binary_cols)}\")\n",
    "print(f\"üì¶ Colonnes cat√©gorielles : {len(categorical_cols)}\")\n",
    "\n",
    "if non_binary_cols:\n",
    "    print(f\"‚ö†Ô∏è Colonnes int64 non binaires d√©tect√©es (extrait) : {non_binary_cols[:5]}\")\n",
    "\n",
    "# üéØ Variable cible 'y'\n",
    "if 'y' in df_study.columns:\n",
    "    print(\"\\nüéØ Variable cible 'y' :\")\n",
    "    print(f\"  - Type : {df_study['y'].dtype}\")\n",
    "    print(f\"  - Valeurs uniques : {sorted(df_study['y'].dropna().unique())}\")\n",
    "    print(f\"  - Distribution :\\n{df_study['y'].value_counts().sort_index()}\")\n",
    "else:\n",
    "    print(\"‚ùå La colonne cible 'y' est manquante\")\n",
    "\n",
    "# üîÑ Comparaison avec df_eval\n",
    "print(\"\\nüîÑ Comparaison avec df_eval :\")\n",
    "eval_type_counts = df_eval.dtypes.value_counts()\n",
    "for dtype, count in eval_type_counts.items():\n",
    "    print(f\"  - {dtype}: {count} colonnes\")\n",
    "\n",
    "# ‚öñÔ∏è V√©rification des types entre df_study et df_eval\n",
    "print(\"\\nüîç V√©rification de la coh√©rence des types entre fichiers :\")\n",
    "type_mismatches = [\n",
    "    (col, df_study[col].dtype, df_eval[col].dtype)\n",
    "    for col in df_eval.columns if col in df_study.columns and df_study[col].dtype != df_eval[col].dtype\n",
    "]\n",
    "\n",
    "if type_mismatches:\n",
    "    print(\"‚ö†Ô∏è Incoh√©rences de type d√©tect√©es :\")\n",
    "    for col, t1, t2 in type_mismatches:\n",
    "        print(f\"  - {col}: {t1} (√©tude) vs {t2} (√©val)\")\n",
    "else:\n",
    "    print(\"‚úÖ Types coh√©rents entre df_study et df_eval\")\n",
    "\n",
    "# üíæ Mise √† jour de la configuration\n",
    "print(\"\\nüíæ Mise √† jour de la configuration...\")\n",
    "config.update(\"COLUMN_CONFIG.CONTINUOUS_COLS\", continuous_cols)\n",
    "config.update(\"COLUMN_CONFIG.BINARY_COLS\", binary_cols)\n",
    "config.update(\"COLUMN_CONFIG.CATEGORICAL_COLS\", categorical_cols)\n",
    "\n",
    "# üìã R√©sum√© final\n",
    "print(\"\\nüìä R√©sum√© des colonnes (hors 'y') :\")\n",
    "print(f\"  - Colonnes continues   : {len(continuous_cols)}\")\n",
    "print(f\"  - Colonnes binaires    : {len(binary_cols)}\")\n",
    "print(f\"  - Colonnes cat√©gorielles : {len(categorical_cols)}\")\n",
    "print(f\"  - Total features (hors cible) : {df_study.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YkyGNfK4Npb"
   },
   "source": [
    "## 3.3 Distribution de la variable cible <a id=\"distribution-variable-cible\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faSgrP2v7D-w",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319639979,
     "user_tz": -120,
     "elapsed": 1325,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "outputId": "53a714a0-3024-40fd-fedb-5141f7c40fb5"
   },
   "outputs": [],
   "source": [
    "## 3.3 Distribution de la variable cible <a id=\"distribution-variable-cible\"></a>\n",
    "\n",
    "print(\"\\nüéØ Analyse de la distribution de la variable cible\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# V√©rification de la pr√©sence de 'y'\n",
    "if 'y' not in df_study.columns:\n",
    "    raise ValueError(\"‚ùå Colonne cible 'y' introuvable dans df_study\")\n",
    "\n",
    "# Distribution brute et en %\n",
    "target_counts = df_study['y'].value_counts().sort_index()\n",
    "target_pct = df_study['y'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "# Affichage des proportions\n",
    "print(\"\\nüìä Distribution de la variable cible (y) :\")\n",
    "for label in target_counts.index:\n",
    "    label_str = \"Classe 1 (ad.)\" if label == 1 else \"Classe 0 (noad.)\"\n",
    "    print(f\"  - {label_str:<20}: {target_counts[label]:,} ({target_pct[label]:.1f}%)\")\n",
    "\n",
    "# Ratio de d√©s√©quilibre\n",
    "imbalance_ratio = target_counts[0] / target_counts[1]\n",
    "print(f\"\\nüìà Ratio de d√©s√©quilibre : {imbalance_ratio:.2f}:1\")\n",
    "print(f\"   ‚Üí Pour chaque publicit√©, il y a {imbalance_ratio:.1f} non-publicit√©s\")\n",
    "\n",
    "# Visualisation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Bar plot\n",
    "target_counts.plot(kind='bar', ax=ax1, color=['#3498db', '#e74c3c'])\n",
    "ax1.set_title('Distribution des classes', fontsize=14)\n",
    "ax1.set_xlabel('Classe')\n",
    "ax1.set_ylabel('Nombre d\\'√©chantillons')\n",
    "ax1.set_xticklabels(['Non-publicit√© (0)', 'Publicit√© (1)'], rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "target_pct.plot(kind='pie', ax=ax2, colors=['#3498db', '#e74c3c'],\n",
    "                autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Proportion des classes', fontsize=14)\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Sauvegarde s√©curis√©e dans un sous-dossier\n",
    "eda_dir = FIGURES_DIR / 'eda'\n",
    "eda_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(eda_dir / 'target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Impact pour la mod√©lisation\n",
    "print(\"\\nüí° Implications pour la mod√©lisation :\")\n",
    "print(f\"  - Dataset fortement d√©s√©quilibr√© ({imbalance_ratio:.1f}:1)\")\n",
    "print(\"  - Strat√©gies recommand√©es :\")\n",
    "print(\"    ‚Ä¢ Utiliser stratify=True lors du train/test split\")\n",
    "print(\"    ‚Ä¢ Appliquer SMOTE ou class_weight='balanced'\")\n",
    "print(\"    ‚Ä¢ Optimiser pour F1-score (m√©trique du challenge)\")\n",
    "print(\"    ‚Ä¢ Envisager un stacking ou un mod√®le robuste aux d√©s√©quilibres\")\n",
    "\n",
    "# Calcul du F1-score baseline\n",
    "p = target_pct[1] / 100  # Pr√©cision et recall identiques si on pr√©dit toujours 1\n",
    "baseline_f1 = 2 * p / (1 + p)\n",
    "print(f\"\\nüìä F1-score baseline (pr√©dire toujours 'ad.') : {baseline_f1:.3f}\")\n",
    "print(\"   ‚Üí Les mod√®les devront d√©passer ce seuil pour √™tre utiles\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Analyse exploratoire <a id=\"analyse-exploratoire\"></a>"
   ],
   "metadata": {
    "id": "Gw9B31kJkfVO"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiocpr334VXb"
   },
   "source": [
    "## 4.1 Analyse des valeurs manquantes <a id=\"analyse-des-valeurs-manquantes\"></a>\n",
    "\n",
    "**Objectif** : Identifier les valeurs manquantes dans le dataset d‚Äôentra√Ænement et d‚Äô√©valuation, analyser leur pattern (MCAR, MAR, MNAR), et proposer une strat√©gie d‚Äôimputation adapt√©e.\n",
    "\n",
    "**Th√©orie** : Les valeurs manquantes peuvent √™tre MCAR (al√©atoires), MAR (li√©es √† d‚Äôautres variables observ√©es), ou MNAR (li√©es √† la variable elle-m√™me). Une corr√©lation significative entre l‚Äôindicateur de valeurs manquantes et la variable cible sugg√®re un pattern MAR, n√©cessitant une imputation sophistiqu√©e (k-NN, MICE).\n",
    "\n",
    "**M√©thodologie** : Nous calculons le pourcentage de valeurs manquantes par colonne, visualisons leur pattern via une heatmap, et analysons la corr√©lation entre les indicateurs de valeurs manquantes et la variable cible encod√©e. Une strat√©gie d‚Äôimputation est propos√©e en fonction des r√©sultats.\n",
    "\n",
    "**Prochaines √©tapes** : Si un pattern MAR est confirm√©, pr√©parer une imputation multivari√©e (section 5.3). V√©rifier l‚Äôimpact des imputations sur les performances des mod√®les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3uxwTBQ7UXy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319643060,
     "user_tz": -120,
     "elapsed": 3079,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "edfb75a8-5b55-4c39-acad-02979270d1c4"
   },
   "outputs": [],
   "source": [
    "# 4. Analyse exploratoire <a id=\"analyse-exploratoire\"></a>\n",
    "## 4.1 Analyse des valeurs manquantes <a id=\"analyse-des-valeurs-manquantes\"></a>\n",
    "\n",
    "print(\"üîç Analyse des valeurs manquantes\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Utilisation de la fonction du module\n",
    "from preprocessing.missing_values import (\n",
    "    analyze_missing_values,\n",
    "    handle_missing_values,\n",
    "    find_optimal_k\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nüìä Analyse globale des valeurs manquantes :\")\n",
    "missing_stats = analyze_missing_values(df_study)\n",
    "\n",
    "# Analyse d√©taill√©e pour les colonnes continues\n",
    "print(\"\\nüìà D√©tail des valeurs manquantes pour les variables continues :\")\n",
    "for col in continuous_cols:\n",
    "    missing_count = df_study[col].isnull().sum()\n",
    "    missing_pct = (missing_count / len(df_study)) * 100\n",
    "    print(f\"  - {col}: {missing_count} ({missing_pct:.2f}%)\")\n",
    "\n",
    "# Visualisation des patterns de valeurs manquantes\n",
    "if missing_stats['total_missing'] > 0:\n",
    "    # Heatmap des valeurs manquantes pour les colonnes avec des NaN\n",
    "    cols_with_missing = [col for col in df_study.columns if df_study[col].isnull().sum() > 0]\n",
    "\n",
    "    if len(cols_with_missing) > 0:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Cr√©er une matrice binaire des valeurs manquantes\n",
    "        missing_matrix = df_study[cols_with_missing].isnull().astype(int)\n",
    "\n",
    "        # Heatmap\n",
    "        sns.heatmap(missing_matrix.T, cmap='RdYlBu', cbar_kws={'label': 'Manquant (1) / Pr√©sent (0)'})\n",
    "        plt.title('Pattern des valeurs manquantes', fontsize=14)\n",
    "        plt.xlabel('√âchantillons')\n",
    "        plt.ylabel('Variables')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIGURES_DIR / 'eda' / 'missing_values_pattern.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        # Analyse du pattern MAR vs MCAR\n",
    "        print(\"\\nüîç Analyse du type de valeurs manquantes (MAR vs MCAR) :\")\n",
    "\n",
    "        # Corr√©lation entre les valeurs manquantes et la cible\n",
    "        for col in cols_with_missing:\n",
    "            missing_indicator = df_study[col].isnull().astype(int)\n",
    "            correlation_with_target = missing_indicator.corr(df_study['y'])\n",
    "            print(f\"  - {col}: corr√©lation avec y = {correlation_with_target:.3f}\")\n",
    "\n",
    "            if abs(correlation_with_target) > 0.1:\n",
    "                print(f\"    ‚Üí Potentiellement MAR (Missing At Random)\")\n",
    "            else:\n",
    "                print(f\"    ‚Üí Potentiellement MCAR (Missing Completely At Random)\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Aucune valeur manquante d√©tect√©e dans le dataset !\")\n",
    "\n",
    "# Analyse pour le fichier d'√©valuation aussi\n",
    "print(\"\\nüìä Analyse des valeurs manquantes dans le fichier d'√©valuation :\")\n",
    "missing_stats_eval = analyze_missing_values(df_eval)\n",
    "\n",
    "# Comparaison des patterns\n",
    "if missing_stats['total_missing'] > 0 or missing_stats_eval['total_missing'] > 0:\n",
    "    print(\"\\nüîÑ Comparaison des patterns de valeurs manquantes :\")\n",
    "    print(f\"  - Fichier d'√©tude : {missing_stats['percent_missing']:.2f}% manquant\")\n",
    "    print(f\"  - Fichier d'√©valuation : {missing_stats_eval['percent_missing']:.2f}% manquant\")\n",
    "\n",
    "    # Strat√©gie d'imputation recommand√©e\n",
    "    print(\"\\nüí° Strat√©gie d'imputation recommand√©e :\")\n",
    "    if 'X4' in missing_stats['cols_missing']:\n",
    "        x4_missing_pct = missing_stats['percent_per_col'].get('X4', 0)\n",
    "        if x4_missing_pct < 5:\n",
    "            print(f\"  - X4 ({x4_missing_pct:.1f}% manquant) : Imputation par la m√©diane\")\n",
    "\n",
    "    mar_cols = ['X1', 'X2', 'X3']\n",
    "    mar_missing = any(col in missing_stats['cols_missing'] for col in mar_cols)\n",
    "    if mar_missing:\n",
    "        print(f\"  - X1, X2, X3 (variables continues) : KNN ou MICE (imputation multivari√©e)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIdk0q8n7f0Q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319643106,
     "user_tz": -120,
     "elapsed": 32,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fdfb3372-73ae-4c0b-9d12-ff0cd6a86c41"
   },
   "outputs": [],
   "source": [
    "# Correction du type et imputation de X4\n",
    "print(\"\\nüîß Correction du type de X4...\")\n",
    "print(f\"Valeurs uniques de X4 (avant correction) : {sorted(df_study['X4'].dropna().unique())}\")\n",
    "print(f\"Type actuel : {df_study['X4'].dtype}\")\n",
    "\n",
    "# V√©rifier que X4 ne contient que 0 et 1\n",
    "unique_values = df_study['X4'].dropna().unique()\n",
    "if set(unique_values).issubset({0.0, 1.0}):\n",
    "    # Imputer d'abord les valeurs manquantes par la m√©diane\n",
    "    X4_median = df_study['X4'].median()\n",
    "    df_study['X4'] = df_study['X4'].fillna(X4_median)\n",
    "    df_eval['X4'] = df_eval['X4'].fillna(X4_median)\n",
    "\n",
    "    # Convertir en int\n",
    "    df_study['X4'] = df_study['X4'].astype(int)\n",
    "    df_eval['X4'] = df_eval['X4'].astype(int)\n",
    "\n",
    "    print(f\"‚úÖ X4 converti en int64 apr√®s imputation par la m√©diane ({X4_median})\")\n",
    "    print(f\"Nouveau type : {df_study['X4'].dtype}\")\n",
    "\n",
    "    # Mettre √† jour la configuration\n",
    "    config.update(\"COLUMN_CONFIG.CONTINUOUS_COLS\", ['X1', 'X2', 'X3'])\n",
    "    config.update(\"COLUMN_CONFIG.BINARY_COLS\", ['X4'] + binary_cols)\n",
    "    continuous_cols = ['X1', 'X2', 'X3']  # Mise √† jour locale\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è X4 contient des valeurs autres que 0 et 1, conservation en float64\")\n",
    "\n",
    "# R√©sum√© final\n",
    "print(\"\\nüìä R√©sum√© des valeurs manquantes apr√®s traitement de X4 :\")\n",
    "print(f\"  - X1, X2, X3 : ~27% manquant ‚Üí √Ä traiter avec KNN/MICE\")\n",
    "print(f\"  - X4 : Imput√© et converti en binaire\")\n",
    "print(f\"  - Pattern MAR d√©tect√© pour X1, X2, X3 (corr√©lation avec y ‚âà -0.10)\")\n",
    "print(f\"  - Les patterns sont coh√©rents entre fichiers d'√©tude et d'√©valuation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqL4vDo_4ZsM"
   },
   "source": [
    "\n",
    "## 4.2 Analyse statistique des variables quantitatives\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "## 4.2 Analyse statistique des variables quantitatives <a id=\"analyse-statistique-des-variables-quantitatives\"></a>\n",
    "\n",
    "print(\"üìä Analyse statistique des variables quantitatives\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from exploration.statistics import analyze_continuous_variables\n",
    "#from modules.exploration.statistics import analyze_continuous_variables\n",
    "\n",
    "\n",
    "# Lancement de l‚Äôanalyse compl√®te\n",
    "results_stats = analyze_continuous_variables(\n",
    "    df=df_study,\n",
    "    continuous_cols=continuous_cols,\n",
    "    target_col='y',\n",
    "    save_figures_path=str(FIGURES_DIR / \"eda\")  # Assure-toi que ce dossier existe\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "id": "Si3zn8ciTAZy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319644441,
     "user_tz": -120,
     "elapsed": 1310,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "96108392-a50a-476e-bb0a-2d5c55a65e7b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 Visualisation des distributions et des boxplots <a id=\"distributions-et-boxplots\"></a>"
   ],
   "metadata": {
    "id": "TKVyCu_1dUNx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## 4.3 Visualisation des distributions et des boxplots <a id=\"distributions-et-boxplots\"></a>\n",
    "\n",
    "print(\"üìä Visualisation des distributions et des boxplots\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from exploration.visualization import visualize_distributions_and_boxplots\n",
    "# Appel de la fonction\n",
    "visualize_distributions_and_boxplots(\n",
    "    df=df_study,\n",
    "    continuous_cols=continuous_cols,\n",
    "    output_dir=FIGURES_DIR / \"eda\"\n",
    ")"
   ],
   "metadata": {
    "id": "12iv6KJgb7xe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319653736,
     "user_tz": -120,
     "elapsed": 9285,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "outputId": "18f3a8f9-e9a4-4c66-95e5-a731d0f3565f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MuuIaHqWZwB"
   },
   "source": [
    "## üìä Synth√®se de l'analyse statistique\n",
    "\n",
    "### Variables analys√©es : X1, X2, X3 (~1780 observations chacune)\n",
    "\n",
    "**üîç Principales observations :**\n",
    "- **Distributions non-normales** : Toutes variables fortement asym√©triques (skewness : 1.6 √† 7.1)\n",
    "- **293 outliers** d√©tect√©s (~16% des donn√©es)\n",
    "- **Corr√©lations notables** : X2-X3 (r=0.53), X1-X3 (r=-0.29)\n",
    "\n",
    "**‚ö†Ô∏è Points d'attention :**\n",
    "- √âcart important moyenne/m√©diane pour toutes variables\n",
    "- X3 particuli√®rement probl√©matique (skewness=7.06, kurtosis=63.4)\n",
    "- Tests de Shapiro-Wilk : p<0.001 (rejet normalit√©)\n",
    "\n",
    "**üîÑ Actions requises :**\n",
    "- **Transformation Yeo-Johnson** recommand√©e avant analyse param√©trique\n",
    "- Consid√©rer m√©thodes robustes/non-param√©triques\n",
    "- Investigation des valeurs aberrantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGRaPjfb4kjp"
   },
   "source": [
    "\n",
    "## 4.4 Distribution des variables binaires <a id=\"distribution-des-variables-binaires\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOmnt6cOZVt4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319654582,
     "user_tz": -120,
     "elapsed": 844,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "outputId": "31440b76-7f51-46b2-98c5-88a4a232234c"
   },
   "outputs": [],
   "source": [
    "## 4.4 Distribution des variables binaires <a id=\"distribution-des-variables-binaires\"></a>\n",
    "\n",
    "print(\"üî¢ Analyse de la distribution des variables binaires\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from exploration.visualization import save_fig\n",
    "\n",
    "# Variables binaires (exclut les variables continues)\n",
    "binary_cols = [col for col in df_study.columns if col.startswith('X') and col not in continuous_cols]\n",
    "print(f\"\\nüìä Nombre total de variables binaires : {len(binary_cols)}\")\n",
    "\n",
    "# Taux de pr√©sence (valeurs √† 1)\n",
    "presence_rates = {\n",
    "    col: (df_study[col] == 1).sum() / len(df_study) * 100 for col in binary_cols\n",
    "}\n",
    "presence_series = pd.Series(presence_rates)\n",
    "\n",
    "# Statistiques globales\n",
    "print(f\"\\nüìä Statistiques des taux de pr√©sence :\")\n",
    "print(f\"  - Moyenne : {presence_series.mean():.2f}%\")\n",
    "print(f\"  - M√©diane : {presence_series.median():.2f}%\")\n",
    "print(f\"  - Min : {presence_series.min():.2f}%\")\n",
    "print(f\"  - Max : {presence_series.max():.2f}%\")\n",
    "\n",
    "# Sparsit√© globale\n",
    "total_values = len(df_study) * len(binary_cols)\n",
    "total_ones = df_study[binary_cols].sum().sum()\n",
    "sparsity = (1 - total_ones / total_values) * 100\n",
    "print(f\"\\nüìä Sparsit√© globale : {sparsity:.2f}% de z√©ros\")\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(8, 4))\n",
    "presence_series.hist(bins=50, color='skyblue', edgecolor='black')\n",
    "plt.axvline(presence_series.mean(), color='red', linestyle='--', label=f'Moyenne: {presence_series.mean():.1f}%')\n",
    "plt.xlabel('Taux de pr√©sence (%)')\n",
    "plt.ylabel('Nombre de variables')\n",
    "plt.title('Distribution des taux de pr√©sence des variables binaires')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "save_fig(\"binary_presence_distribution.png\", directory=FIGURES_DIR / \"eda\", dpi=300, show=True)\n",
    "\n",
    "print(\"\\n‚úÖ Analyse des variables binaires termin√©e\")\n",
    "print(\"   ‚Üí Dataset tr√®s sparse, adapt√© pour des m√©thodes de s√©lection de features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pY8MQrqS4oeF"
   },
   "source": [
    "## 4.5 Analyse des corr√©lations combin√©es <a id=\"analyse-correlations-combinees\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJhlPtkebR_J",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319699016,
     "user_tz": -120,
     "elapsed": 44432,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "7db3aa37-03f9-40ea-89d8-0b565718c2b6"
   },
   "outputs": [],
   "source": [
    "## 4.5 Analyse des corr√©lations combin√©es <a id=\"analyse-correlations-combinees\"></a>\n",
    "\n",
    "print(\"üîó Lancement de l'analyse combin√©e des corr√©lations (features ‚Üî cible, features ‚Üî features)...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from exploration.eda_analysis import full_correlation_analysis\n",
    "\n",
    "# Appel avec param√®tres personnalis√©s\n",
    "full_correlation_analysis(\n",
    "    df_study=df_study,\n",
    "    continuous_cols=continuous_cols,\n",
    "    presence_rates=presence_rates,\n",
    "    FIGURES_DIR=FIGURES_DIR,\n",
    "    ROOT_DIR=ROOT_DIR,\n",
    "    figsize_corr_matrix=(7, 5),\n",
    "    figsize_binary=(8, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAKep5FT4rI8"
   },
   "source": [
    "## üìå Synth√®se de l'analyse des corr√©lations <a id=\"synthese-correlations\"></a>\n",
    "\n",
    "### üîç Corr√©lations avec la variable cible (`y`)\n",
    "\n",
    "- ‚úÖ **Meilleure variable pr√©dictive continue** : `X2` avec une corr√©lation de **0.573**\n",
    "- üìâ Les autres variables (continues ou binaires) ont une corr√©lation **faible √† mod√©r√©e** avec `y` (souvent < 0.2)\n",
    "- ‚ÑπÔ∏è Cela sugg√®re que la **mod√©lisation devra combiner plusieurs variables** pour √™tre efficace\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Corr√©lations entre variables\n",
    "\n",
    "- ‚ö†Ô∏è **1 paire** de variables (binaires ou continues) pr√©sente une **corr√©lation > 0.8**\n",
    "- ‚úÖ **Multicolin√©arit√© faible** ‚Üí pas de besoin urgent de supprimer des variables continues\n",
    "\n",
    "---\n",
    "\n",
    "### Redondance dans les variables binaires\n",
    "\n",
    "- üìä **3 506 paires** de variables binaires pr√©sentent une corr√©lation **> 0.95**\n",
    "- üîÅ Ces paires impliquent **de nombreuses variables dupliqu√©es** ou tr√®s similaires\n",
    "- üß† Certaines variables sont impliqu√©es dans **15+ paires corr√©l√©es**, sugg√©rant des motifs de duplication\n",
    "\n",
    "---\n",
    "\n",
    "### üß≠ Recommandations\n",
    "\n",
    "- üßπ Appliquer une **r√©duction de dimension** avant la mod√©lisation :\n",
    "  - Suppression de variables binaires fortement redondantes\n",
    "  - Utilisation de **PCA**, **autoencoders** ou s√©lection par importance (e.g. **Random Forest**)\n",
    "- üéØ Se concentrer sur `X2` et les variables binaires les plus corr√©l√©es √† `y` comme features de base\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.6 Visualisations globales de l'EDA <a id=\"visualisation-globale\"></a>\n"
   ],
   "metadata": {
    "id": "rKNm3dPr3Fbz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J02P5fpcP1fH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319700379,
     "user_tz": -120,
     "elapsed": 1360,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "57208792-6a9f-4679-b4ce-6380981070a3"
   },
   "outputs": [],
   "source": [
    "## 4.6 Visualisations globales de l'EDA <a id=\"visualisation-globale\"></a>\n",
    "\n",
    "print(\"üìä Visualisations exploratoires\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Imports des fonctions refactoris√©es\n",
    "from exploration.visualization import (\n",
    "    compare_visualization_methods,\n",
    "    plot_continuous_by_class,\n",
    "    plot_binary_sparsity,\n",
    "    plot_continuous_target_corr,\n",
    "    plot_eda_summary,\n",
    "    save_fig\n",
    ")\n",
    "from exploration.statistics import optimized_feature_importance\n",
    "\n",
    "# 1. Distribution des variables continues par classe\n",
    "print(\"\\nüìà Distribution des variables continues par classe...\")\n",
    "plot_continuous_by_class(\n",
    "    df=df_study,\n",
    "    continuous_cols=continuous_cols,\n",
    "    output_dir=FIGURES_DIR / 'eda'\n",
    ")\n",
    "\n",
    "# 2. Visualisation de la sparsit√©\n",
    "print(\"\\nüìâ Visualisation de la sparsit√© des donn√©es binaires...\")\n",
    "plot_binary_sparsity(\n",
    "    df=df_study,\n",
    "    binary_cols=binary_cols,\n",
    "    output_dir=FIGURES_DIR / 'eda'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# 3. Corr√©lations des variables continues avec la cible\n",
    "print(\"\\nüîó Corr√©lations des variables continues avec la cible...\")\n",
    "plot_continuous_target_corr(\n",
    "    df=df_study,\n",
    "    continuous_cols=continuous_cols,\n",
    "    output_dir=FIGURES_DIR / 'eda'\n",
    ")\n",
    "\n",
    "# 4. R√©duction de dimension avec UMAP / t-SNE / PCA\n",
    "print(\"\\nüìä Visualisation multidimensionnelle (PCA / t-SNE / UMAP)...\")\n",
    "\n",
    "df_study_viz = df_study.copy()\n",
    "df_study_viz['outcome'] = df_study_viz['y'].map({0: 'noad.', 1: 'ad.'})  # ‚úÖ temporaire\n",
    "\n",
    "# üîÅ Recalcul des corr√©lations si besoin\n",
    "target_corr = df_study[continuous_cols + ['y']].corr()['y'].drop('y')\n",
    "\n",
    "important_features = continuous_cols + list(target_corr.abs().nlargest(30).index)\n",
    "df_sample = df_study_viz[important_features + ['outcome']].dropna()\n",
    "\n"
   ],
   "metadata": {
    "id": "R0cRtXSfTIcZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319700747,
     "user_tz": -120,
     "elapsed": 356,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "outputId": "3505386d-bf1e-4597-b3f7-159b23daebad"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# 5. Importance des variables\n",
    "print(\"\\nüå≤ Analyse de l‚Äôimportance des features...\")\n",
    "try:\n",
    "    df_importance = df_sample.copy()  # contient outcome d√©j√† transform√©e\n",
    "    importance_results = optimized_feature_importance(\n",
    "        df=df_importance,\n",
    "        target_col='outcome',\n",
    "        method='all',\n",
    "        top_n=10,\n",
    "        figsize=(8, 4),\n",
    "        save_path=FIGURES_DIR / 'eda' / 'feature_importance.png',\n",
    "        show=True\n",
    "    )\n",
    "    if not importance_results.empty:\n",
    "        print(\"\\nTop 10 features les plus importantes :\")\n",
    "        print(importance_results[['feature', 'Combined_Score']].head(10))\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erreur lors de l‚Äôanalyse d‚Äôimportance des features : {e}\")\n",
    "\n",
    "# 6. R√©sum√© visuel global\n",
    "print(\"\\nüìä Cr√©ation du r√©sum√© visuel de l‚ÄôEDA...\")\n",
    "plot_eda_summary(\n",
    "    df=df_study,\n",
    "    continuous_cols=continuous_cols,\n",
    "    binary_cols=binary_cols,\n",
    "    target_corr=target_corr,\n",
    "    sparsity=sparsity,\n",
    "    imbalance_ratio=imbalance_ratio,\n",
    "    output_dir=FIGURES_DIR / 'eda',\n",
    "    presence_series=presence_series\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Visualisations exploratoires termin√©es avec succ√®s !\")"
   ],
   "metadata": {
    "id": "HM--uSx-TYSV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319701906,
     "user_tz": -120,
     "elapsed": 1156,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "outputId": "131b1718-9100-4d18-a07c-76fcdc83f4ef"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üß≠ Interpr√©tations synth√©tiques des r√©sultats de l'EDA <a id=\"interpretations-eda\"></a>\n",
    "\n",
    "### üéØ 1. Distribution des variables continues par classe\n",
    "- **X1, X2, X3** pr√©sentent des distributions tr√®s diff√©rentes entre les deux classes (`ad.` vs `noad.`).\n",
    "- **X2** se distingue particuli√®rement avec une s√©paration marqu√©e entre les classes.\n",
    "- Les distributions sont asym√©triques, avec la pr√©sence d‚Äô**outliers** visibles dans chaque classe.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ 2. Corr√©lations avec la variable cible\n",
    "- **X2** est la variable la plus corr√©l√©e avec la cible (`corr = 0.573`), ce qui en fait une **feature cl√©**.\n",
    "- **X1** (`corr = 0.034`) et **X3** (`corr = 0.130`) ont des corr√©lations faibles mais non n√©gligeables.\n",
    "- Cela sugg√®re l‚Äôutilit√© de **mod√®les non lin√©aires** ou **ensemble methods** (e.g. Random Forest, Gradient Boosting).\n",
    "\n",
    "---\n",
    "\n",
    "### üß¨ 3. Visualisation de la sparsit√© des variables binaires\n",
    "- Le dataset est **extr√™mement sparse**, avec **99.2% de z√©ros** dans les variables binaires.\n",
    "- Implications :\n",
    "  - Risque de surapprentissage √©lev√© si toutes les variables sont conserv√©es.\n",
    "  - N√©cessit√© de s√©lection de variables ou de techniques de r√©duction (PCA, autoencoders).\n",
    "  - Attention aux m√©thodes sensibles √† la densit√© (ex : k-NN).\n",
    "\n",
    "---\n",
    "\n",
    "### üó∫Ô∏è 4. R√©sum√© visuel global\n",
    "- **D√©s√©quilibre important** : 86% `noad.` vs 14% `ad.` ‚Üí n√©cessite des strat√©gies adapt√©es :\n",
    "  - M√©triques robustes (F1-score, recall).\n",
    "  - R√©√©chantillonnage ou `class_weight='balanced'`.\n",
    "- **Valeurs manquantes** (~27%) dans X1, X2, X3 : √† imputer avec m√©thode robuste (KNN, MICE).\n",
    "- **Top corr√©lations** concentr√©es sur peu de variables ‚Üí importance d‚Äôune **bonne s√©lection de features**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Recommandations cl√©s\n",
    "- **Pr√©traitement renforc√©** :\n",
    "  - Transformation des variables continues (Yeo-Johnson recommand√©e).\n",
    "  - Suppression ou gestion des outliers extr√™mes.\n",
    "- **R√©duction de dimension** :\n",
    "  - Visualisation UMAP/t-SNE utile pour v√©rifier la structure.\n",
    "  - S√©lection de features importante avant mod√©lisation (selon importance ou redondance).\n",
    "- **R√©√©quilibrage des classes** indispensable pour √©viter un biais fort du mod√®le vers la classe majoritaire.\n",
    "\n",
    "---\n"
   ],
   "metadata": {
    "id": "WfkNz2VhV2Qd"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A43_iODb4v4e"
   },
   "source": [
    "# 5. Pr√©traitement avanc√© <a id=\"pretraitement-avance\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1 Transformation Yeo-Johnson sur X1, X2, X3 <a id=\"transformation-yeo-johnson\"></a>\n",
    "\n",
    "#### üîÅ Transformation des variables continues\n",
    "\n",
    "Les variables `X1`, `X2` et `X3` pr√©sentent une forte asym√©trie positive ainsi que des valeurs extr√™mes d√©tect√©es via la r√®gle de l‚ÄôIQR.\n",
    "\n",
    "#### üìå Objectif :\n",
    "- Stabiliser la variance\n",
    "- R√©duire l‚Äôimpact des outliers\n",
    "- Am√©liorer la distribution pour les mod√®les sensibles √† la normalit√© (r√©gression logistique, kNN‚Ä¶)\n",
    "\n",
    "#### ‚öôÔ∏è M√©thode :\n",
    "Nous utilisons la transformation **Yeo-Johnson** via `PowerTransformer`, qui accepte les valeurs nulles ou strictement positives.\n",
    "\n",
    "> üîß Les colonnes transform√©es seront ajout√©es en tant que `X1_trans`, `X2_trans` et `X3_trans`."
   ],
   "metadata": {
    "id": "8L0og4jMi0AL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from preprocessing.final_preprocessing import apply_yeojohnson\n",
    "\n",
    "\n",
    "# Appliquer Yeo-Johnson aux variables continues\n",
    "df_study = apply_yeojohnson(df_study, columns=[\"X1\", \"X2\", \"X3\"])\n",
    "\n",
    "# V√©rification visuelle rapide des variables transform√©es\n",
    "df_study[[\"X1_trans\", \"X2_trans\", \"X3_trans\"]].describe()\n",
    "\n",
    "\n",
    "\n",
    "# # Utiliser ceci si on veut aussi le transformer tout en le sauvegardant\n",
    "# # Appliquer Yeo-Johnson aux variables continues\n",
    "\n",
    "# df_study, pt = apply_yeojohnson(\n",
    "#     df=df_study,\n",
    "#     columns=[\"X1\", \"X2\", \"X3\"],\n",
    "#     save_model=True,\n",
    "#     model_path=MODELS_DIR / \"yeojohnson_transformer.pkl\",\n",
    "#     return_transformer=True\n",
    "# )\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "AjRtCcTKXklK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319702285,
     "user_tz": -120,
     "elapsed": 378,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "outputId": "b1e8eacf-c68a-40f7-842c-03c0290bbdeb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚úÖ Liste des variables transform√©es\n",
    "transformed_vars = [\"X1_trans\", \"X2_trans\", \"X3_trans\"]\n",
    "\n",
    "# üìÅ Dossier de sauvegarde\n",
    "output_dir = FIGURES_DIR / 'preprocessing'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# üîÅ G√©n√©ration et sauvegarde des figures\n",
    "for col in transformed_vars:\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6, 2))\n",
    "\n",
    "    # Histogramme + KDE\n",
    "    sns.histplot(df_study[col], bins=30, kde=True, ax=ax[0], color=\"mediumseagreen\")\n",
    "    ax[0].set_title(f\"{col} - Histogramme\")\n",
    "    ax[0].set_xlabel(col)\n",
    "\n",
    "    # Boxplot\n",
    "    sns.boxplot(x=df_study[col], ax=ax[1], color=\"salmon\")\n",
    "    ax[1].set_title(f\"{col} - Boxplot\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # üíæ Sauvegarde\n",
    "    fig_path = output_dir / f\"{col}_distribution_boxplot.png\"\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"‚úÖ Figure sauvegard√©e : {fig_path}\")\n"
   ],
   "metadata": {
    "id": "-6ao8uIFbrq3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319704235,
     "user_tz": -120,
     "elapsed": 1952,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "outputId": "43b3932f-9b4f-4667-9afc-12a87e38084a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### üîÅ Transformation Yeo-Johnson des variables continues <a id=\"yeojohnson-interpr√©tation\"></a>\n",
    "\n",
    "### R√©sultats visuels\n",
    "\n",
    "Les histogrammes et boxplots suivants montrent l'effet de la transformation Yeo-Johnson sur les variables `X1`, `X2` et `X3` :\n",
    "\n",
    "- ‚úÖ **Meilleure sym√©trie** des distributions.\n",
    "- ‚úÖ **R√©duction de l'effet des outliers** (m√™me si certains persistent, notamment sur `X2`).\n",
    "- ‚úÖ **Concentration des valeurs** autour de la m√©diane, utile pour les mod√®les sensibles aux √©chelles et √† la normalit√©.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpr√©tation\n",
    "\n",
    "| Variable   | R√©sultat apr√®s transformation                             | Commentaire                                                                 |\n",
    "|------------|------------------------------------------------------------|------------------------------------------------------------------------------|\n",
    "| `X1_trans` | Distribution plus centr√©e et sym√©trique                   | Forte am√©lioration visuelle, outliers encore pr√©sents mais moins extr√™mes   |\n",
    "| `X2_trans` | Distribution toujours multimodale avec quelques extr√™mes  | Transformation partiellement efficace ‚Äì normalisation partielle             |\n",
    "| `X3_trans` | Distribution globalement normalis√©e                       | Tr√®s bon r√©sultat ‚Äì faible asym√©trie et √©tendue r√©duite                     |\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Conclusion\n",
    "\n",
    "- La transformation **Yeo-Johnson** est efficace pour r√©duire l'asym√©trie des variables `X1`, `X2` et `X3`.\n",
    "- Elle **pr√©pare les donn√©es √† des mod√®les lin√©aires** ou sensibles aux distances (kNN, r√©gression).\n",
    "- Un **traitement compl√©mentaire des outliers** peut √™tre envisag√©, surtout pour `X2`.\n"
   ],
   "metadata": {
    "id": "pki8mhftdoJY"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5vkSDM340qL"
   },
   "source": [
    "## 5.2 D√©tection et suppression des outliers <a id=\"detection-et-suppression-des-outliers\"></a>\n",
    "\n",
    "### üéØ Objectifs :\n",
    "- Identifier les observations extr√™mes susceptibles de perturber la mod√©lisation.\n",
    "- Appliquer une strat√©gie de suppression uniquement sur les variables continues (`X1`, `X2`, `X3`), apr√®s transformation.\n",
    "\n",
    "### üõ†Ô∏è M√©thode :\n",
    "- Utilisation de la r√®gle de l‚ÄôIQR (Interquartile Range).\n",
    "- Application sur les colonnes transform√©es : `X1_trans`, `X2_trans`, `X3_trans`.\n",
    "- Suppression des lignes contenant au moins un outlier dans ces colonnes.\n",
    "\n",
    "### üìâ Impact attendu :\n",
    "- R√©duction de l‚Äôeffet des valeurs extr√™mes sur les mod√®les sensibles.\n",
    "- Meilleure normalit√© apr√®s transformation.\n",
    "- Perte contr√¥l√©e d‚Äôobservations (g√©n√©ralement < 5%).\n",
    "\n",
    "### ‚úÖ √âtapes suivantes :\n",
    "1. D√©tection via IQR (Q1 - 1.5√óIQR, Q3 + 1.5√óIQR)\n",
    "2. Comptage des lignes extr√™mes par variable\n",
    "3. Suppression des lignes avec outliers dans au moins une variable\n",
    "4. Affichage du pourcentage de donn√©es supprim√©es\n",
    "\n",
    "> üîç Cette √©tape ne sera appliqu√©e que sur `df_study` (jeu d'entra√Ænement).\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## 5.2 D√©tection et suppression des outliers <a id=\"detection-et-suppression-des-outliers\"></a>\n",
    "\n",
    "print(\"üîç D√©tection et suppression des outliers (m√©thode IQR)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from preprocessing.outliers import detect_and_remove_outliers\n",
    "\n",
    "# ‚úÖ Variables √† traiter (transform√©es)\n",
    "transformed_cols = [\"X1_trans\", \"X2_trans\", \"X3_trans\"]\n",
    "\n",
    "# ‚úÖ Sauvegarde de la version avant suppression\n",
    "df_with_outliers = df_study.copy()\n",
    "\n",
    "# ‚úÖ Chemin de sauvegarde apr√®s nettoyage\n",
    "output_path = OUTPUTS_DIR / \"data\" / \"df_after_outliers.csv\"\n",
    "\n",
    "# ‚úÖ Suppression des outliers avec export CSV\n",
    "df_study = detect_and_remove_outliers(\n",
    "    df=df_study,\n",
    "    columns=transformed_cols,\n",
    "    method='iqr',\n",
    "    iqr_multiplier=1.5,\n",
    "    verbose=True,\n",
    "    save_path=output_path\n",
    ")\n",
    "\n",
    "# ‚úÖ Aper√ßu statistique post-nettoyage\n",
    "print(\"\\nüìä Statistiques descriptives apr√®s suppression des outliers :\")\n",
    "display(df_study[transformed_cols].describe())\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "f7Zd-bRguFgz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319705456,
     "user_tz": -120,
     "elapsed": 1215,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "outputId": "198b0cce-9d1a-408b-daf7-7bfc710dd32e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "## üìä Visualisation comparative avant/apr√®s suppression des outliers\n",
    "\n",
    "from exploration.visualization import plot_outlier_comparison\n",
    "\n",
    "# ‚úÖ Comparaison visuelle avant / apr√®s (X1_trans, X2_trans, X3_trans)\n",
    "plot_outlier_comparison(\n",
    "    df_before=df_with_outliers,\n",
    "    df_after=df_study,\n",
    "    cols=transformed_cols,\n",
    "    output_dir=FIGURES_DIR / \"eda\",\n",
    "    show=True\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "qTB2uTbn4Ywv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319707041,
     "user_tz": -120,
     "elapsed": 1583,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "174e4bf8-8c56-4a97-abf6-8242a6fe27aa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## üìâ Analyse des effets de la suppression des outliers <a id=\"effet-suppression-outliers\"></a>\n",
    "\n",
    "### Objectif :\n",
    "La d√©tection des outliers est effectu√©e sur les variables transform√©es (`X1_trans`, `X2_trans`, `X3_trans`) via la m√©thode de l‚ÄôIQR (Interquartile Range), afin de r√©duire l‚Äôinfluence des valeurs extr√™mes sur les mod√®les.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç R√©sultats :\n",
    "\n",
    "#### ‚úÖ **X1_trans**\n",
    "- **Avant** : pr√©sence de plusieurs outliers extr√™mes √† gauche et √† droite.\n",
    "- **Apr√®s** : distribution recentr√©e, disparition des extr√™mes anormaux.\n",
    "- **Effet attendu** : meilleure stabilit√© pour les mod√®les lin√©aires sensibles √† la variance.\n",
    "\n",
    "#### ‚úÖ **X2_trans**\n",
    "- **Avant** : distribution asym√©trique avec une concentration importante d‚Äôoutliers √† gauche (valeurs faibles).\n",
    "- **Apr√®s** : distribution plus compacte, r√©duction de l‚Äôasym√©trie, moins d‚Äôobservations extr√™mes.\n",
    "- **Effet attendu** : am√©lioration de la normalit√© et du comportement statistique de la variable.\n",
    "\n",
    "#### ‚úÖ **X3_trans**\n",
    "- **Avant** : tr√®s peu d‚Äôoutliers d√©tect√©s, distribution relativement homog√®ne.\n",
    "- **Apr√®s** : suppression minimale, confirmant que X3_trans √©tait d√©j√† bien normalis√©e.\n",
    "- **Effet attendu** : impact marginal, mais b√©n√©fique pour les mod√®les robustes.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Conclusion :\n",
    "- La suppression des outliers permet d‚Äôobtenir des distributions plus resserr√©es et sym√©triques.\n",
    "- Elle am√©liore la qualit√© des donn√©es, tout en pr√©servant la majorit√© des observations informatives.\n",
    "- Deux versions du dataset sont conserv√©es :\n",
    "  - **Avec outliers** : pour tester la robustesse des mod√®les.\n",
    "  - **Sans outliers** : pour √©valuer les gains en stabilit√© et performance.\n"
   ],
   "metadata": {
    "id": "htSIHT-1KVZg"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjS1MqQo46fS"
   },
   "source": [
    "## 5.3 Gestion des valeurs manquantes <a id=\"gestion-des-valeurs-manquantes\"></a>\n",
    "\n",
    "La gestion des valeurs manquantes est cruciale pour garantir la qualit√© des analyses et des mod√®les.\n",
    "\n",
    "### üîé Objectifs :\n",
    "- Imputer intelligemment les valeurs manquantes\n",
    "- Pr√©server la structure statistique du dataset\n",
    "- Minimiser la distorsion induite par les imputations\n",
    "\n",
    "### ‚öôÔ∏è M√©thodologie adopt√©e :\n",
    "- Analyse de la structure des valeurs manquantes (`MCAR`, `MAR`)\n",
    "- Imputation simple (m√©diane) pour certaines variables\n",
    "- Imputation multiple (MICE ou KNN) pour les autres\n",
    "- Sauvegarde des jeux de donn√©es imput√©s pour mod√©lisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBmBDwu_4-HH"
   },
   "source": [
    "### ‚úÖ 5.3.1 Imputation de X4 par la m√©diane <a id=\"imputation-x4-mediane\"></a>\n",
    "\n",
    "La variable `X4`, de type discr√®te (0/1), a √©t√© imput√©e **pr√©cocement par la m√©diane**, ce qui est adapt√© √† une variable binaire avec peu de valeurs manquantes.  \n",
    "‚Üí Aucun traitement suppl√©mentaire n‚Äôest n√©cessaire ici.\n",
    "\n",
    "---\n",
    "\n",
    "### üöß Prochaine √©tape : **imputation multiple** sur les variables continues `X1`, `X2`, `X3` via des m√©thodes plus robustes (KNN ou MICE).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3.2 Pr√©paration pour l'imputation multivari√©e <a id=\"preparation-imputation-multivariee\"></a>"
   ],
   "metadata": {
    "id": "NLspOrs2NHDo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## 5.3.2 Pr√©paration pour l'imputation multivari√©e <a id=\"preparation-imputation-multivariee\"></a>\n",
    "\n",
    "print(\"üîß Pr√©paration √† l'imputation multiple (KNN / MICE)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from preprocessing.missing_values import analyze_missing_values\n",
    "\n",
    "cols_to_check = [\"X1_trans\", \"X2_trans\", \"X3_trans\"]\n",
    "\n",
    "# üìÅ Analyse sur les donn√©es AVEC outliers\n",
    "print(\"\\nüìä Analyse (donn√©es avec outliers)\")\n",
    "analyze_missing_values(df=df_with_outliers, columns=cols_to_check, plot=True)\n",
    "\n",
    "# ‚úÖ Colonnes √† imputer (si moins de 30 % de valeurs manquantes)\n",
    "cols_impute_with_outliers = [col for col in cols_to_check\n",
    "                             if df_with_outliers[col].isna().mean() < 0.30]\n",
    "\n",
    "print(\"\\nüìå Colonnes retenues (avec outliers) :\")\n",
    "print(cols_impute_with_outliers)\n",
    "\n",
    "\n",
    "# üìÅ Analyse sur les donn√©es SANS outliers\n",
    "print(\"\\nüìä Analyse (donn√©es sans outliers)\")\n",
    "analyze_missing_values(df=df_study, columns=cols_to_check, plot=True)\n",
    "\n",
    "cols_impute_no_outliers = [col for col in cols_to_check\n",
    "                           if df_study[col].isna().mean() < 0.30]\n",
    "\n",
    "print(\"\\nüìå Colonnes retenues (sans outliers) :\")\n",
    "print(cols_impute_no_outliers)\n",
    "\n"
   ],
   "metadata": {
    "id": "9t1nUArVNLhX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319707272,
     "user_tz": -120,
     "elapsed": 222,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "outputId": "3c6f9991-75fb-4f49-abbd-729f83a4c370"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3.3 Imputation multivari√©e (MICE) <a id=\"imputation-multivariee-mice\"></a>"
   ],
   "metadata": {
    "id": "yXQkjZcAuQ3z"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Imputation MICE - donn√©es avec outliers"
   ],
   "metadata": {
    "id": "w-JRdrDpK_2K"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#### Imputation multivari√©e (MICE) - donn√©es avec outliers\n",
    "\n",
    "print(\"üß© Imputation multivari√©e (donn√©es avec outliers)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from preprocessing.missing_values import handle_missing_values\n",
    "\n",
    "# üìå Colonnes concern√©es\n",
    "cols_to_impute = [\"X1_trans\", \"X2_trans\", \"X3_trans\"]\n",
    "\n",
    "# üìÅ Chemin de sauvegarde du r√©sultat\n",
    "save_path_outliers = OUTPUTS_DIR / \"data\" / \"df_imputed_with_outliers.csv\"\n",
    "\n",
    "# ‚úÖ Lancer l'imputation multiple sur les donn√©es avec outliers\n",
    "df_with_outliers_imputed_mice = handle_missing_values(\n",
    "    df=df_with_outliers,\n",
    "    strategy=\"mixed_mar_mcar\",\n",
    "    mar_method='mice',                  # ou 'knn'\n",
    "    mar_cols=cols_to_impute,\n",
    "    mcar_cols=[],                      # X4 d√©j√† trait√©\n",
    "    processed_data_dir=DATA_PROCESSED,\n",
    "    models_dir=MODELS_DIR,\n",
    "    save_results=True,\n",
    "    display_info=True\n",
    ")\n",
    "\n",
    "# üîç Aper√ßu\n",
    "df_with_outliers_imputed_mice[cols_to_impute].describe()\n",
    "\n"
   ],
   "metadata": {
    "id": "R6XTMF7suL7m",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319708321,
     "user_tz": -120,
     "elapsed": 1048,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "outputId": "85453912-0283-4c16-84a1-1db1155e779b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Imputation Mice - donn√©es avec outliers"
   ],
   "metadata": {
    "id": "WrTAmUN71FkV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#### Imputation multivari√©e (MICE) - donn√©es sans outliers\n",
    "\n",
    "print(\"üß© Imputation multivari√©e (donn√©es sans outliers)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# üìÅ Chemin de sauvegarde\n",
    "save_path_no_outliers = DATA_PROCESSED / \"df_imputed_mice_no_outliers.csv\"\n",
    "\n",
    "# ‚úÖ Imputation sur les donn√©es nettoy√©es (sans outliers)\n",
    "df_no_outliers_imputed_mice = handle_missing_values(\n",
    "    df=df_study,  # Ce DataFrame a les outliers supprim√©s\n",
    "    strategy=\"mixed_mar_mcar\",\n",
    "    mar_method='mice',\n",
    "    mar_cols=[\"X1_trans\", \"X2_trans\", \"X3_trans\"],\n",
    "    mcar_cols=[],\n",
    "    processed_data_dir=DATA_PROCESSED,\n",
    "    models_dir=MODELS_DIR,\n",
    "    save_results=True,\n",
    "    display_info=True,\n",
    "    custom_filename=save_path_no_outliers.name  # ‚úÖ Permet d'utiliser un nom de fichier personnalis√©\n",
    ")\n",
    "\n",
    "# üîç Aper√ßu des donn√©es imput√©es\n",
    "df_no_outliers_imputed_mice[[\"X1_trans\", \"X2_trans\", \"X3_trans\"]].describe()\n"
   ],
   "metadata": {
    "id": "2a7BxLPT1CNg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319709034,
     "user_tz": -120,
     "elapsed": 709,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "outputId": "dd013b10-71fc-4609-c0ab-ac022da82214"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#### Coparaison imputation sur les donn√©es avec et sans outliers\n",
    "\n",
    "# Chargement des deux versions imput√©es\n",
    "path_with_outliers = Path(\"/content/drive/MyDrive/projet_sta211/data/processed/df_imputed_mice.csv\")\n",
    "path_no_outliers = Path(\"/content/drive/MyDrive/projet_sta211/data/processed/df_imputed_mice_no_outliers.csv\")\n",
    "\n",
    "df_with_outliers = pd.read_csv(path_with_outliers)\n",
    "df_no_outliers = pd.read_csv(path_no_outliers)\n",
    "\n",
    "# Variables √† comparer\n",
    "cols_to_plot = [\"X1_trans\", \"X2_trans\", \"X3_trans\"]\n",
    "\n",
    "# Cr√©ation des graphiques\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 8))\n",
    "\n",
    "for i, col in enumerate(cols_to_plot):\n",
    "    sns.kdeplot(df_with_outliers[col], ax=axes[i, 0], fill=True, color=\"teal\")\n",
    "    axes[i, 0].set_title(f\"{col} - Avec outliers (MICE)\")\n",
    "\n",
    "    sns.kdeplot(df_no_outliers[col], ax=axes[i, 1], fill=True, color=\"coral\")\n",
    "    axes[i, 1].set_title(f\"{col} - Sans outliers (MICE)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "LDEWx3k821uu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319710598,
     "user_tz": -120,
     "elapsed": 1563,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "outputId": "fc1de20f-87bf-4ba7-f8bc-3885a0656ba9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3.4 Imputation par KNN"
   ],
   "metadata": {
    "id": "GBewDH9hKGfz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "### 5.3.4 Imputation par KNN <a id=\"imputation-knn\"></a>\n",
    "\n",
    "from pathlib import Path\n",
    "from preprocessing.missing_values import handle_missing_values, find_optimal_k\n",
    "\n",
    "# üìÅ Chemins de sauvegarde\n",
    "save_path_knn_with = Path(OUTPUTS_DIR) / \"data\" / \"df_imputed_with_outliers_knn.csv\"\n",
    "save_path_knn_no = Path(OUTPUTS_DIR) / \"data\" / \"df_imputed_no_outliers_knn.csv\"\n",
    "\n",
    "# üîç Recherche du k optimal pour KNN (avec outliers)\n",
    "print(\"üîç Recherche du k optimal pour KNN Imputer (avec outliers)\")\n",
    "features = ['X1_trans', 'X2_trans', 'X3_trans']\n",
    "df_knn_sample = df_with_outliers[features].copy()\n",
    "\n",
    "optimal_k = find_optimal_k(\n",
    "    df=df_knn_sample,\n",
    "    continuous_cols=features,\n",
    "    k_range=range(2, 21),\n",
    "    cv_folds=5,\n",
    "    sample_size=50000\n",
    ")\n",
    "print(f\"‚úÖ k optimal d√©termin√© (avec outliers) : {optimal_k}\")\n",
    "\n",
    "# ‚úÖ Imputation avec outliers\n",
    "df_with_outliers_imputed_knn = handle_missing_values(\n",
    "    df=df_with_outliers,\n",
    "    strategy=\"mixed_mar_mcar\",\n",
    "    mar_method='knn',\n",
    "    knn_k=optimal_k,\n",
    "    mar_cols=features,\n",
    "    mcar_cols=[],\n",
    "    processed_data_dir=save_path_knn_with.parent,\n",
    "    save_results=True,\n",
    "    display_info=True\n",
    ")\n",
    "\n",
    "# üîç Recherche du k optimal pour KNN (sans outliers)\n",
    "print(\"\\nüîç Recherche du k optimal pour KNN Imputer (sans outliers)\")\n",
    "df_knn_no_outliers = df_study[features].copy()\n",
    "\n",
    "optimal_k_no_outliers = find_optimal_k(\n",
    "    df=df_knn_no_outliers,\n",
    "    continuous_cols=features,\n",
    "    k_range=range(2, 21),\n",
    "    cv_folds=5,\n",
    "    sample_size=50000\n",
    ")\n",
    "print(f\"‚úÖ k optimal d√©termin√© (sans outliers) : {optimal_k_no_outliers}\")\n",
    "\n",
    "# ‚úÖ Imputation sans outliers\n",
    "df_no_outliers_imputed_knn = handle_missing_values(\n",
    "    df=df_study,\n",
    "    strategy=\"mixed_mar_mcar\",\n",
    "    mar_method='knn',\n",
    "    knn_k=optimal_k_no_outliers,\n",
    "    mar_cols=features,\n",
    "    mcar_cols=[],\n",
    "    processed_data_dir=save_path_knn_no.parent,\n",
    "    save_results=True,\n",
    "    display_info=True\n",
    ")\n"
   ],
   "metadata": {
    "id": "6_NiUYoQALcE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319720940,
     "user_tz": -120,
     "elapsed": 10340,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "05f71cdd-381f-48fc-f0b7-3c387f59269d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGKYDbzN5Hpj"
   },
   "source": [
    "## 5.4 D√©tection et traitement des variables collin√©aires <a id=\"detection-et-traitement-des-variables-collineaires\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## 5.4 D√©tection et traitement des variables collin√©aires <a id=\"detection-et-traitement-des-variables-collineaires\"></a>\n",
    "\n",
    "from preprocessing.final_preprocessing import find_highly_correlated_groups\n",
    "\n",
    "correlated_info = find_highly_correlated_groups(\n",
    "    df=df_study,  # ou df_with_outliers_imputed_mice / df_no_outliers_imputed_knn\n",
    "    threshold=0.95,\n",
    "    exclude_cols=['y'],\n",
    "    show_plot=True,\n",
    "    save_path=FIGURES_DIR / \"eda\" / \"correlation_heatmap_collinearity.png\"\n",
    ")\n",
    "\n",
    "print(f\"üîó {len(correlated_info['groups'])} groupes d√©tect√©s\")\n",
    "print(f\"‚ùå {len(correlated_info['to_drop'])} variables √† supprimer\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "Z3zQHyzyBIm7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319742397,
     "user_tz": -120,
     "elapsed": 21455,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "outputId": "05da48bb-0e86-41b5-c149-cee018fdfa4b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.4.1 Suppression des variables collin√©aires <a id=\"suppression-collineaires\"></a>"
   ],
   "metadata": {
    "id": "7LSH0mlbZP5A"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"üßπ Suppression des variables fortement corr√©l√©es\")\n",
    "print('=' * 60)\n",
    "\n",
    "from preprocessing.final_preprocessing import drop_correlated_duplicates\n",
    "\n",
    "# Suppression pour les donn√©es imput√©es par MICE\n",
    "df_with_outliers_filtered, _, _ = drop_correlated_duplicates(\n",
    "    df=df_with_outliers_imputed_mice,\n",
    "    groups=correlated_info['groups'],\n",
    "    target_col='y',\n",
    "    summary=True\n",
    ")\n",
    "df_no_outliers_filtered, _, _ = drop_correlated_duplicates(\n",
    "    df=df_no_outliers_imputed_mice,\n",
    "    groups=correlated_info['groups'],\n",
    "    target_col='y',\n",
    "    summary=True\n",
    ")\n",
    "\n",
    "# Suppression pour les donn√©es imput√©es par KNN\n",
    "df_with_outliers_filtered_knn, _, _ = drop_correlated_duplicates(\n",
    "    df=df_with_outliers_imputed_knn,\n",
    "    groups=correlated_info['groups'],\n",
    "    target_col='y',\n",
    "    summary=True\n",
    ")\n",
    "df_no_outliers_filtered_knn, _, _ = drop_correlated_duplicates(\n",
    "    df=df_no_outliers_imputed_knn,\n",
    "    groups=correlated_info['groups'],\n",
    "    target_col='y',\n",
    "    summary=True\n",
    ")\n",
    "\n",
    "# V√©rification des dimensions\n",
    "print(f\"\\nüìä Dimensions apr√®s suppression (MICE - avec outliers)     : {df_with_outliers_filtered.shape}\")\n",
    "print(f\"üìä Dimensions apr√®s suppression (MICE - sans outliers)     : {df_no_outliers_filtered.shape}\")\n",
    "print(f\"üìä Dimensions apr√®s suppression (KNN  - avec outliers)     : {df_with_outliers_filtered_knn.shape}\")\n",
    "print(f\"üìä Dimensions apr√®s suppression (KNN  - sans outliers)     : {df_no_outliers_filtered_knn.shape}\")\n"
   ],
   "metadata": {
    "id": "h0EwF8c3ZH37",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319742409,
     "user_tz": -120,
     "elapsed": 8,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8f14474b-5b55-4191-aaec-4e14ddf9230c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.4.2 Sauvegarde des datasets filtr√©s <a id=\"sauvegarde-datasets-filtres\"></a>\n"
   ],
   "metadata": {
    "id": "WqcWA_AhbaTn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "### 5.4.2 Sauvegarde des datasets filtr√©s <a id=\"sauvegarde-datasets-filtres\"></a>\n",
    "print(\"üíæ Sauvegarde des jeux de donn√©es filtr√©s\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# ‚úÖ D√©finition du dossier de sauvegarde\n",
    "filtered_dir = DATA_PROCESSED\n",
    "filtered_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Sauvegarde des versions imput√©es par MICE ===\n",
    "mice_with_path = filtered_dir / \"df_filtered_with_outliers_mice.csv\"\n",
    "mice_no_path   = filtered_dir / \"df_filtered_no_outliers_mice.csv\"\n",
    "\n",
    "df_with_outliers_filtered.to_csv(mice_with_path, index=False)\n",
    "df_no_outliers_filtered.to_csv(mice_no_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Fichier sauvegard√© : {mice_with_path}\")\n",
    "print(f\"‚úÖ Fichier sauvegard√© : {mice_no_path}\")\n",
    "\n",
    "# === Sauvegarde des versions imput√©es par KNN ===\n",
    "knn_with_path = filtered_dir / \"df_filtered_with_outliers_knn.csv\"\n",
    "knn_no_path   = filtered_dir / \"df_filtered_no_outliers_knn.csv\"\n",
    "\n",
    "df_with_outliers_filtered_knn.to_csv(knn_with_path, index=False)\n",
    "df_no_outliers_filtered_knn.to_csv(knn_no_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Fichier sauvegard√© : {knn_with_path}\")\n",
    "print(f\"‚úÖ Fichier sauvegard√© : {knn_no_path}\")\n",
    "\n"
   ],
   "metadata": {
    "id": "PClDN7HGeKi6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319743798,
     "user_tz": -120,
     "elapsed": 1388,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a0b5b4d5-4c7f-4832-86dd-f500198d9dc1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNcyV2Ag5LaY"
   },
   "source": [
    "# 6. Construction des datasets finaux <a id=\"construction-des-datasets-finaux\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from preprocessing.final_preprocessing import prepare_final_dataset\n",
    "# from config.paths_config import setup_project_paths\n",
    "\n",
    "# üìÅ Chemins configur√©s automatiquement\n",
    "# paths = setup_project_paths()\n"
   ],
   "metadata": {
    "id": "TFUmtf3q7TBE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319743817,
     "user_tz": -120,
     "elapsed": 15,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.1 Application du pipeline de pr√©traitement (KNN) <a id=\"pipeline-knn\"></a>"
   ],
   "metadata": {
    "id": "7YZzyaC-ikyk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Imputation KNN ‚Äì sans outliers\n",
    "df_final_knn_with_outliers = prepare_final_dataset(\n",
    "    file_path=RAW_DATA_DIR / \"data_train.csv\",\n",
    "    strategy=\"mixed_mar_mcar\",\n",
    "    mar_method=\"knn\",\n",
    "    knn_k=optimal_k_no_outliers,\n",
    "    mar_cols=[\"X1_trans\", \"X2_trans\", \"X3_trans\"],\n",
    "    mcar_cols=[\"X4\"],\n",
    "    drop_outliers=True,\n",
    "    correlation_threshold=0.95,\n",
    "    save_transformer=True,\n",
    "    processed_data_dir=DATA_PROCESSED,\n",
    "    models_dir=MODELS_DIR,\n",
    "    display_info=True\n",
    ")\n",
    "\n",
    "# Sauvegarde explicite si besoin\n",
    "df_final_knn_with_outliers.to_parquet(\n",
    "    DATA_PROCESSED / \"final_dataset_knn_with_outliers.parquet\", index=False\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "id": "f2bYlK4EGagd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319766730,
     "user_tz": -120,
     "elapsed": 22912,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "outputId": "e1d4c52d-1c50-4d0a-caf4-83392cc11f53"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Imputation KNN ‚Äì avec outliers\n",
    "# Appel du pipeline pour les donn√©es imput√©es par knn, avec outliers\n",
    "\n",
    "df_final_knn_with_outliers = prepare_final_dataset(\n",
    "    file_path= RAW_DATA_DIR / \"data_train.csv\",\n",
    "    strategy=\"mixed_mar_mcar\",\n",
    "    mar_method=\"knn\",\n",
    "    knn_k=optimal_k,\n",
    "    drop_outliers=False,\n",
    "    correlation_threshold=0.95,\n",
    "    save_transformer=True,\n",
    "    processed_data_dir= DATA_PROCESSED,\n",
    "    models_dir= MODELS_DIR,\n",
    "    display_info=True\n",
    ")\n",
    "df_final_knn_with_outliers.to_csv(DATA_PROCESSED / \"final_dataset_knn_with_outliers.csv\", index=False)\n"
   ],
   "metadata": {
    "id": "0iz146Zb_tGX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749320222650,
     "user_tz": -120,
     "elapsed": 23176,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "outputId": "0555d62d-37e0-4675-d80c-2312d1ea285f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Imputation KNN ‚Äì sans outliers\n",
    "# Appel du pipeline pour les donn√©es imput√©es par knn, sans outliers\n",
    "\n",
    "df_final_mice_with_outliers = prepare_final_dataset(\n",
    "    file_path=RAW_DATA_DIR / \"data_train.csv\",\n",
    "    strategy=\"mixed_mar_mcar\",\n",
    "    mar_method=\"mice\",\n",
    "    drop_outliers=False,\n",
    "    correlation_threshold=0.95,\n",
    "    save_transformer=False,  # d√©j√† sauvegard√© pr√©c√©demment\n",
    "    processed_data_dir= DATA_PROCESSED,\n",
    "    models_dir=paths[\"MODELS_DIR\"],\n",
    "    display_info=True\n",
    ")\n",
    "df_final_mice_with_outliers.to_csv(DATA_PROCESSED / \"final_dataset_mice_with_outliers.csv\", index=False)\n"
   ],
   "metadata": {
    "id": "xxKahqMVAcqL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749320199461,
     "user_tz": -120,
     "elapsed": 24379,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "outputId": "d21757c3-c3a0-4eef-eb33-17cf2e3fccbb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z09-01M55Vli"
   },
   "source": [
    "## 6.2 Application du pipeline de pr√©traitement (MICE) <a id=\"pipeline-mice\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# appel du pipeline MICE sans outliers\n",
    "df_final_mice_no_outliers = prepare_final_dataset(\n",
    "    file_path= RAW_DATA_DIR / \"data_train.csv\",\n",
    "    strategy=\"mixed_mar_mcar\",        # Imputation mixte\n",
    "    mar_method=\"mice\",                # M√©thode d‚Äôimputation : MICE\n",
    "    drop_outliers=True,               # Suppression des outliers\n",
    "    correlation_threshold=0.95,       # Seuil pour corr√©lation\n",
    "    save_transformer=False,            # d√©j√† sauvegard√© pr√©c√©demment\n",
    "    processed_data_dir=DATA_PROCESSED,  # Sauvegarde parquet ici\n",
    "    models_dir= MODELS_DIR,   # Pour sauvegarde du transformateur\n",
    "    display_info=True                 # Affichage d√©taill√©\n",
    ")\n"
   ],
   "metadata": {
    "id": "oG96WeId7Zr6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319829783,
     "user_tz": -120,
     "elapsed": 20340,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "outputId": "abfbb0ec-6ece-4ebd-ef74-7a63c9673eb9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# appel du pipeline MICE avec outliers\n",
    "\n",
    "df_final_mice_with_outliers = prepare_final_dataset(\n",
    "    file_path=RAW_DATA_DIR / \"data_train.csv\",\n",
    "    strategy=\"mixed_mar_mcar\",\n",
    "    mar_method=\"mice\",\n",
    "    drop_outliers=False,\n",
    "    correlation_threshold=0.95,\n",
    "    save_transformer=False,  # d√©j√† sauvegard√© pr√©c√©demment\n",
    "    processed_data_dir=DATA_PROCESSED,\n",
    "    models_dir=MODELS_DIR,\n",
    "    display_info=True\n",
    ")\n",
    "df_final_mice_with_outliers.to_parquet(DATA_PROCESSED / \"final_dataset_mice_with_outliers.parquet\", index=False)\n"
   ],
   "metadata": {
    "id": "qimMPp_h96VG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749319851126,
     "user_tz": -120,
     "elapsed": 21348,
     "user": {
      "displayName": "maoulida abdoullatuf",
      "userId": "05790302460507444417"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "outputId": "2f932818-af74-4c7a-b0a9-f2571480c1ab"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nS-G_w15bGb"
   },
   "source": [
    "## 6.3 Comparaison des m√©thodes d'imputation <a id=\"comparaison-methodes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rltHbTyg5l0s"
   },
   "source": [
    "# 7. Validation du pr√©traitement <a id=\"validation-pretraitement\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.1 V√©rification de la qualit√© des donn√©es <a id=\"verification-qualite\"></a>"
   ],
   "metadata": {
    "id": "EB3j89bAmLuD"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fxXdY-p5rUt"
   },
   "source": [
    "## 7.2 Statistiques finales <a id=\"statistiques-finales\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfJQ5V_H5xoy"
   },
   "source": [
    "# 8. Conclusion <a id=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOkQo_tSvTCZ"
   },
   "source": [
    "# 9. Annexes / Visualisations compl√©mentaires <a id=\"annexes\"></a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
