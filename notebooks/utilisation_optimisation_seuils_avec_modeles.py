# =============================================================================
# UTILISATION DU MODULE D'OPTIMISATION DES SEUILS AVEC MOD√àLES EXISTANTS
# =============================================================================

# Import du module d'optimisation
from modules.modeling.stacking_threshold_optimizer import (
    optimize_stacking_thresholds_with_models, 
    plot_threshold_optimization, 
    save_optimization_results,
    get_optimal_predictions
)

# =============================================================================
# √âTAPE 1 : OPTIMISATION DES SEUILS AVEC MOD√àLES EXISTANTS
# =============================================================================

print("üéØ √âTAPE 1 : Optimisation des seuils avec mod√®les existants")
print("=" * 70)

# Utiliser les mod√®les d√©j√† cr√©√©s (stacking_knn et stacking_mice)
# Optimiser les seuils pour KNN et MICE
results = optimize_stacking_thresholds_with_models(
    stacking_knn=stacking_knn,  # Mod√®le d√©j√† cr√©√©
    stacking_mice=stacking_mice, # Mod√®le d√©j√† cr√©√©
    X_train_knn=X_train_knn, 
    X_val_knn=X_val_knn, 
    y_train_knn=y_train_knn, 
    y_val_knn=y_val_knn,
    X_train_mice=X_train_mice, 
    X_val_mice=X_val_mice, 
    y_train_mice=y_train_mice, 
    y_val_mice=y_val_mice,
    optimization_method="f1",  # Optimiser sur F1-score
    verbose=True
)

# =============================================================================
# √âTAPE 2 : VISUALISATION DES R√âSULTATS
# =============================================================================

print("\nüéØ √âTAPE 2 : Visualisation des r√©sultats")
print("=" * 70)

# Cr√©er les visualisations (graphiques plus petits maintenant)
plot_threshold_optimization(
    results, 
    y_val_knn=y_val_knn,
    y_val_mice=y_val_mice,
    save_path="outputs/figures/figures_notebook3/stacking_threshold_optimization.png"
)

# =============================================================================
# √âTAPE 3 : SAUVEGARDE DES R√âSULTATS
# =============================================================================

print("\nüéØ √âTAPE 3 : Sauvegarde des r√©sultats")
print("=" * 70)

# Sauvegarder les r√©sultats
json_file, csv_file = save_optimization_results(results)

# =============================================================================
# √âTAPE 4 : UTILISATION DES SEUILS OPTIMAUX
# =============================================================================

print("\nüéØ √âTAPE 4 : Utilisation des seuils optimaux")
print("=" * 70)

# G√©n√©rer les pr√©dictions avec seuils optimaux
predictions = get_optimal_predictions(
    results, 
    X_test_knn, 
    X_test_mice, 
    stacking_knn, 
    stacking_mice
)

# =============================================================================
# √âTAPE 5 : √âVALUATION DES PERFORMANCES
# =============================================================================

print("\nüéØ √âTAPE 5 : √âvaluation des performances")
print("=" * 70)

from sklearn.metrics import f1_score, classification_report

# √âvaluer les performances avec seuils optimaux
for method, pred_data in predictions.items():
    print(f"\nüìä PERFORMANCES {method.upper()} AVEC SEUIL OPTIMAL:")
    print(f"   Seuil optimal: {pred_data['threshold']:.3f}")
    
    # Calculer F1-score (si y_test disponible)
    if f'y_test_{method.lower()}' in globals():
        y_test = globals()[f'y_test_{method.lower()}']
        f1_optimal = f1_score(y_test, pred_data['predictions'])
        print(f"   F1-score: {f1_optimal:.4f}")
        
        print(f"\n   üìã Rapport de classification:")
        print(classification_report(y_test, pred_data['predictions']))

# =============================================================================
# R√âSUM√â FINAL
# =============================================================================

print("\n" + "=" * 70)
print("üéØ R√âSUM√â DE L'OPTIMISATION DES SEUILS")
print("=" * 70)

print("\nüìä SEUILS OPTIMAUX TROUV√âS:")
for method, result in results.items():
    print(f"   üîπ {method}: {result['optimal_threshold']:.3f}")
    print(f"      F1 par d√©faut: {result['default_f1']:.4f}")
    print(f"      F1 optimis√©: {result['optimized_f1']:.4f}")
    print(f"      Am√©lioration: {result['improvement']:+.4f} ({result['improvement_pct']:+.1f}%)")

# Identifier le meilleur mod√®le
best_method = max(results.keys(), key=lambda x: results[x]['optimized_f1'])
best_result = results[best_method]

print(f"\nüèÜ MEILLEUR MOD√àLE:")
print(f"   {best_method.upper()} - F1: {best_result['optimized_f1']:.4f}")
print(f"   Seuil optimal: {best_result['optimal_threshold']:.3f}")

print("\n‚úÖ OPTIMISATION TERMIN√âE !")
print("=" * 70)

print("\nüìã Variables disponibles :")
print("   - results : R√©sultats d'optimisation")
print("   - predictions : Pr√©dictions avec seuils optimaux")
print("   - stacking_knn, stacking_mice : Mod√®les entra√Æn√©s")

print("\nüéØ Prochaines √©tapes :")
print("   1. Utiliser les pr√©dictions optimales pour la soumission")
print("   2. Sauvegarder les mod√®les avec leurs seuils optimaux")
print("   3. Comparer avec d'autres m√©thodes") 