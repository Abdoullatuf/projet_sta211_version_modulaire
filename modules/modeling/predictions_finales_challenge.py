# modules/modeling/generate_final_predictions.py
"""
üéØ MODULE DE PR√âDICTIONS FINALES POUR LE CHALLENGE STA211
========================================================

Module simplifi√© bas√© sur l'analyse des notebooks 01, 02 et 03.
Encapsule toute la logique de pr√©diction finale pour le challenge.

Pipeline complet :
1. Notebook 01 : Transformations optimales (Yeo-Johnson + Box-Cox)
2. Notebook 02 : Imputation KNN, standardisation, mod√©lisation
3. Notebook 03 : Stacking, optimisation des seuils, pr√©dictions finales

Auteur : Analyse des notebooks STA211 - Challenge 2025
"""

import logging
import warnings
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union

import joblib
import numpy as np
import pandas as pd
from sklearn.preprocessing import PowerTransformer, StandardScaler
from sklearn.impute import KNNImputer
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score
from xgboost import XGBClassifier

# Configuration
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Constantes du projet
RANDOM_STATE = 42
OPTIMAL_K_KNN = 19
DEFAULT_THRESHOLD = 0.340

# =============================================================================
# 1. CONFIGURATION ET CHEMINS
# =============================================================================

def setup_project_paths(root_dir: Optional[str] = None) -> Dict[str, Path]:
    """
    Configure les chemins du projet STA211.
    
    Args:
        root_dir: R√©pertoire racine du projet (optionnel)
        
    Returns:
        Dictionnaire des chemins configur√©s
    """
    if root_dir is None:
        # D√©tection automatique du r√©pertoire racine
        current_path = Path(__file__).resolve()
        for parent in [current_path.parent.parent.parent, *current_path.parents]:
            if (parent / "modules").exists():
                root_dir = parent
                break
        
        if root_dir is None:
            raise FileNotFoundError("Impossible de localiser le r√©pertoire racine du projet")
    
    root = Path(root_dir)
    
    paths = {
        "ROOT_DIR": root,
        "DATA_RAW": root / "data" / "raw",
        "DATA_PROCESSED": root / "data" / "processed",
        "MODELS_DIR": root / "models",
        "NOTEBOOKS_MODELS": root / "notebooks" / "models",
        "OUTPUTS_DIR": root / "outputs",
        "OUTPUTS_PREDICTIONS": root / "outputs" / "predictions"
    }
    
    # Cr√©er les r√©pertoires s'ils n'existent pas
    for path in paths.values():
        path.mkdir(parents=True, exist_ok=True)
    
    return paths

# =============================================================================
# 2. CHARGEMENT DES DONN√âES
# =============================================================================

def load_test_data(test_file: Optional[str] = None) -> pd.DataFrame:
    """
    Charge les donn√©es de test pour les pr√©dictions finales.
    
    Args:
        test_file: Chemin vers le fichier de test (optionnel)
        
    Returns:
        DataFrame des donn√©es de test
    """
    if test_file is None:
        # Chemins par d√©faut
        paths = setup_project_paths()
        test_candidates = [
            paths["DATA_RAW"] / "data_test.csv",
            paths["ROOT_DIR"] / "data" / "raw" / "data_test.csv",
            paths["ROOT_DIR"] / "SOUMISSION_STA211_2025" / "data" / "raw" / "data_test.csv"
        ]
        
        for candidate in test_candidates:
            if candidate.exists():
                test_file = candidate
                break
        
        if test_file is None:
            raise FileNotFoundError("Fichier data_test.csv introuvable dans les emplacements standards")
    
    logger.info(f"üìä Chargement des donn√©es de test : {test_file}")
    df_test = pd.read_csv(test_file)
    logger.info(f"‚úÖ Donn√©es charg√©es : {df_test.shape}")
    
    return df_test

# =============================================================================
# 3. PREPROCESSING - TRANSFORMATIONS OPTIMALES (NOTEBOOK 01)
# =============================================================================

def load_optimal_transformers(paths: Dict[str, Path]) -> Tuple[Optional[PowerTransformer], Optional[PowerTransformer]]:
    """
    Charge les transformateurs optimaux depuis le notebook 01.
    
    Args:
        paths: Dictionnaire des chemins
        
    Returns:
        Tuple (transformer_yeo_johnson, transformer_box_cox)
    """
    yj_transformer = None
    bc_transformer = None
    
    # Chargement Yeo-Johnson (X1, X2)
    yj_path = paths["NOTEBOOKS_MODELS"] / "yeo_johnson_X1_X2.pkl"
    if yj_path.exists():
        yj_transformer = joblib.load(yj_path)
        logger.info("‚úÖ Transformateur Yeo-Johnson (X1, X2) charg√©")
    else:
        logger.warning(f"‚ö†Ô∏è Transformateur Yeo-Johnson manquant : {yj_path}")
    
    # Chargement Box-Cox (X3)
    bc_path = paths["NOTEBOOKS_MODELS"] / "box_cox_X3.pkl"
    if bc_path.exists():
        bc_transformer = joblib.load(bc_path)
        logger.info("‚úÖ Transformateur Box-Cox (X3) charg√©")
    else:
        logger.warning(f"‚ö†Ô∏è Transformateur Box-Cox manquant : {bc_path}")
    
    return yj_transformer, bc_transformer

def apply_optimal_transformations(df: pd.DataFrame, yj_transformer: Optional[PowerTransformer], 
                                bc_transformer: Optional[PowerTransformer]) -> pd.DataFrame:
    """
    Applique les transformations optimales (Notebook 01).
    
    Args:
        df: DataFrame original
        yj_transformer: Transformateur Yeo-Johnson pour X1, X2
        bc_transformer: Transformateur Box-Cox pour X3
        
    Returns:
        DataFrame avec variables transform√©es
    """
    logger.info("üîÑ Application des transformations optimales...")
    df_transformed = df.copy()
    
    # V√©rifier la pr√©sence des variables continues
    continuous_vars = ['X1', 'X2', 'X3']
    missing_vars = [var for var in continuous_vars if var not in df.columns]
    if missing_vars:
        logger.warning(f"‚ö†Ô∏è Variables continues manquantes : {missing_vars}")
        return df_transformed
    
    # Transformation Yeo-Johnson pour X1, X2
    if yj_transformer is not None:
        logger.info("üìä Application Yeo-Johnson sur X1, X2...")
        X1_X2_data = df[['X1', 'X2']].values
        X1_X2_transformed = yj_transformer.transform(X1_X2_data)
        df_transformed['X1_trans'] = X1_X2_transformed[:, 0]
        df_transformed['X2_trans'] = X1_X2_transformed[:, 1]
        logger.info("‚úÖ Transformation Yeo-Johnson appliqu√©e")
    else:
        logger.warning("‚ö†Ô∏è Transformateur Yeo-Johnson manquant - utilisation valeurs originales")
        df_transformed['X1_trans'] = df['X1']
        df_transformed['X2_trans'] = df['X2']
    
    # Transformation Box-Cox pour X3
    if bc_transformer is not None:
        logger.info("üìä Application Box-Cox sur X3...")
        X3_data = df[['X3']].values
        X3_transformed = bc_transformer.transform(X3_data)
        df_transformed['X3_trans'] = X3_transformed.ravel()
        logger.info("‚úÖ Transformation Box-Cox appliqu√©e")
    else:
        logger.warning("‚ö†Ô∏è Transformateur Box-Cox manquant - utilisation valeur originale")
        df_transformed['X3_trans'] = df['X3']
    
    return df_transformed

# =============================================================================
# 4. PREPROCESSING - IMPUTATION ET STANDARDISATION (NOTEBOOK 02)
# =============================================================================

def load_preprocessing_pipeline(paths: Dict[str, Path]) -> Tuple[Optional[List[str]], Optional[object]]:
    """
    Charge le pipeline de preprocessing (colonnes + standardiser).
    
    Args:
        paths: Dictionnaire des chemins
        
    Returns:
        Tuple (feature_columns, preprocessor)
    """
    feature_columns = None
    preprocessor = None
    
    # Chargement des colonnes utilis√©es
    columns_path = paths["MODELS_DIR"] / "columns_knn_used.pkl"
    if columns_path.exists():
        feature_columns = joblib.load(columns_path)
        logger.info(f"‚úÖ Colonnes charg√©es : {len(feature_columns)} features")
    else:
        logger.warning(f"‚ö†Ô∏è Colonnes manquantes : {columns_path}")
    
    # Chargement du preprocesseur
    preproc_path = paths["MODELS_DIR"] / "preproc_knn.joblib"
    if preproc_path.exists():
        preprocessor = joblib.load(preproc_path)
        logger.info("‚úÖ Preprocesseur charg√©")
    else:
        logger.warning(f"‚ö†Ô∏è Preprocesseur manquant : {preproc_path}")
    
    return feature_columns, preprocessor

def apply_preprocessing_pipeline(df: pd.DataFrame, feature_columns: Optional[List[str]], 
                               preprocessor: Optional[object]) -> pd.DataFrame:
    """
    Applique le pipeline de preprocessing complet.
    
    Args:
        df: DataFrame avec transformations appliqu√©es
        feature_columns: Liste des colonnes √† utiliser
        preprocessor: Pipeline de preprocessing
        
    Returns:
        DataFrame preprocess√©
    """
    logger.info("üîÑ Application du pipeline de preprocessing...")
    
    # Alignement des colonnes
    if feature_columns is not None:
        available_cols = set(df.columns)
        required_cols = set(feature_columns)
        missing_cols = required_cols - available_cols
        
        if missing_cols:
            logger.warning(f"‚ö†Ô∏è Colonnes manquantes : {len(missing_cols)} colonnes")
            # Ajouter les colonnes manquantes avec des valeurs par d√©faut
            for col in missing_cols:
                df[col] = 0
        
        # S√©lectionner les colonnes requises
        df_aligned = df[feature_columns]
        logger.info(f"‚úÖ Colonnes align√©es : {df_aligned.shape}")
    else:
        df_aligned = df
        logger.warning("‚ö†Ô∏è Pas de colonnes de r√©f√©rence - utilisation de toutes les colonnes")
    
    # Application du preprocesseur
    if preprocessor is not None:
        X_processed = preprocessor.transform(df_aligned)
        
        # Conversion en DataFrame
        if hasattr(X_processed, 'toarray'):
            X_processed = X_processed.toarray()
        
        df_processed = pd.DataFrame(
            X_processed,
            columns=feature_columns if feature_columns else df_aligned.columns,
            index=df_aligned.index
        )
        
        # V√©rifications de qualit√©
        nan_count = df_processed.isnull().sum().sum()
        if nan_count > 0:
            logger.warning(f"‚ö†Ô∏è {nan_count} valeurs NaN d√©tect√©es apr√®s preprocessing")
            df_processed = df_processed.fillna(0)
        
        inf_count = np.isinf(df_processed.values).sum()
        if inf_count > 0:
            logger.warning(f"‚ö†Ô∏è {inf_count} valeurs infinies d√©tect√©es")
            df_processed = df_processed.replace([np.inf, -np.inf], np.nan).fillna(0)
        
        logger.info(f"‚úÖ Preprocessing termin√© : {df_processed.shape}")
        return df_processed
    
    else:
        logger.warning("‚ö†Ô∏è Pas de preprocesseur - retour des donn√©es align√©es")
        return df_aligned

# =============================================================================
# 5. CHARGEMENT DU MOD√àLE FINAL (NOTEBOOK 03)
# =============================================================================

def load_final_model(paths: Dict[str, Path]) -> Optional[object]:
    """
    Charge le mod√®le final optimis√©.
    
    Args:
        paths: Dictionnaire des chemins
        
    Returns:
        Mod√®le final charg√©
    """
    model_candidates = [
        paths["MODELS_DIR"] / "final_model_optimized.pkl",
        paths["MODELS_DIR"] / "model_final_knn_stacking_best_model.joblib",
        paths["MODELS_DIR"] / "rf_knn_best_model_seuil_optimise.joblib",
        paths["MODELS_DIR"] / "best_rf_knn.joblib"
    ]
    
    for model_path in model_candidates:
        if model_path.exists():
            model = joblib.load(model_path)
            logger.info(f"‚úÖ Mod√®le final charg√© : {model_path.name}")
            return model
    
    logger.error("‚ùå Aucun mod√®le final trouv√©")
    return None

# =============================================================================
# 6. OPTIMISATION DES SEUILS
# =============================================================================

def optimize_prediction_threshold(y_proba: np.ndarray, default_threshold: float = DEFAULT_THRESHOLD) -> float:
    """
    Optimise le seuil de pr√©diction (version simplifi√©e).
    
    Args:
        y_proba: Probabilit√©s pr√©dites
        default_threshold: Seuil par d√©faut
        
    Returns:
        Seuil optimal
    """
    # Pour les pr√©dictions finales, on utilise le seuil optimis√© dans les notebooks
    # Cette fonction pourrait √™tre √©tendue pour une optimisation dynamique
    return default_threshold

# =============================================================================
# 7. G√âN√âRATION DES PR√âDICTIONS FINALES
# =============================================================================

def generate_final_predictions(model: object, X_test: pd.DataFrame, 
                             optimal_threshold: float = DEFAULT_THRESHOLD) -> Dict[str, np.ndarray]:
    """
    G√©n√®re les pr√©dictions finales.
    
    Args:
        model: Mod√®le entra√Æn√©
        X_test: Donn√©es de test preprocess√©es
        optimal_threshold: Seuil optimal
        
    Returns:
        Dictionnaire avec pr√©dictions et probabilit√©s
    """
    logger.info("üéØ G√©n√©ration des pr√©dictions finales...")
    
    # Pr√©dictions probabilistes
    y_proba = model.predict_proba(X_test)
    probabilities = y_proba[:, 1] if y_proba.shape[1] == 2 else y_proba.ravel()
    
    # Pr√©dictions binaires avec seuil optimal
    predictions_binary = (probabilities >= optimal_threshold).astype(int)
    
    # Conversion en labels textuels
    label_mapping = {0: 'noad.', 1: 'ad.'}
    predictions_labels = np.array([label_mapping[pred] for pred in predictions_binary])
    
    # Statistiques
    n_positive = np.sum(predictions_binary)
    n_total = len(predictions_binary)
    positive_rate = n_positive / n_total * 100
    
    logger.info(f"üìà R√©sultats des pr√©dictions :")
    logger.info(f"   ‚Ä¢ Total √©chantillons : {n_total}")
    logger.info(f"   ‚Ä¢ Publicit√©s (ad.) : {n_positive} ({positive_rate:.1f}%)")
    logger.info(f"   ‚Ä¢ Non-publicit√©s (noad.) : {n_total - n_positive} ({100 - positive_rate:.1f}%)")
    logger.info(f"   ‚Ä¢ Probabilit√© moyenne : {probabilities.mean():.3f}")
    logger.info(f"   ‚Ä¢ Seuil utilis√© : {optimal_threshold:.3f}")
    
    return {
        'predictions_labels': predictions_labels,
        'predictions_binary': predictions_binary,
        'probabilities': probabilities,
        'threshold': optimal_threshold,
        'n_positive': n_positive,
        'n_total': n_total,
        'positive_rate': positive_rate
    }

# =============================================================================
# 8. SAUVEGARDE DES R√âSULTATS
# =============================================================================

def save_predictions(predictions: Dict[str, np.ndarray], paths: Dict[str, Path]) -> List[str]:
    """
    Sauvegarde les pr√©dictions dans diff√©rents formats.
    
    Args:
        predictions: Dictionnaire des pr√©dictions
        paths: Dictionnaire des chemins
        
    Returns:
        Liste des fichiers cr√©√©s
    """
    logger.info("üíæ Sauvegarde des pr√©dictions...")
    
    output_dir = paths["OUTPUTS_PREDICTIONS"]
    output_dir.mkdir(parents=True, exist_ok=True)
    
    files_created = []
    
    # 1. Fichier principal de soumission
    submission_df = pd.DataFrame({'prediction': predictions['predictions_labels']})
    submission_file = output_dir / "submission.csv"
    submission_df.to_csv(submission_file, index=False)
    files_created.append(str(submission_file))
    
    # 2. Fichier d√©taill√© avec probabilit√©s
    detailed_df = pd.DataFrame({
        'prediction': predictions['predictions_labels'],
        'prediction_binary': predictions['predictions_binary'],
        'probability': predictions['probabilities']
    })
    detailed_file = output_dir / "predictions_detaillees.csv"
    detailed_df.to_csv(detailed_file, index=False)
    files_created.append(str(detailed_file))
    
    # 3. Fichier de m√©tadonn√©es
    metadata = {
        'threshold': predictions['threshold'],
        'n_positive': predictions['n_positive'],
        'n_total': predictions['n_total'],
        'positive_rate': predictions['positive_rate'],
        'mean_probability': predictions['probabilities'].mean()
    }
    
    metadata_df = pd.DataFrame([metadata])
    metadata_file = output_dir / "predictions_metadata.csv"
    metadata_df.to_csv(metadata_file, index=False)
    files_created.append(str(metadata_file))
    
    logger.info(f"‚úÖ Fichiers cr√©√©s :")
    for file in files_created:
        file_path = Path(file)
        size_kb = file_path.stat().st_size / 1024
        logger.info(f"   ‚Ä¢ {file_path.name} ({size_kb:.1f} KB)")
    
    return files_created

# =============================================================================
# 9. PIPELINE COMPLET
# =============================================================================

def run_complete_prediction_pipeline(test_file: Optional[str] = None, 
                                   output_dir: Optional[str] = None,
                                   threshold: float = DEFAULT_THRESHOLD,
                                   verbose: bool = True) -> Dict[str, Union[bool, str, List[str]]]:
    """
    Ex√©cute le pipeline complet de pr√©dictions finales.
    
    Args:
        test_file: Chemin vers le fichier de test (optionnel)
        output_dir: R√©pertoire de sortie (optionnel)
        threshold: Seuil de pr√©diction
        verbose: Affichage d√©taill√©
        
    Returns:
        Dictionnaire avec le statut et les r√©sultats
    """
    try:
        if verbose:
            logger.info("üöÄ D√âMARRAGE DU PIPELINE DE PR√âDICTIONS FINALES")
            logger.info("=" * 60)
        
        # 1. Configuration des chemins
        paths = setup_project_paths()
        if output_dir:
            paths["OUTPUTS_PREDICTIONS"] = Path(output_dir)
        
        # 2. Chargement des donn√©es de test
        df_test = load_test_data(test_file)
        
        # 3. Chargement des transformateurs (Notebook 01)
        yj_transformer, bc_transformer = load_optimal_transformers(paths)
        
        # 4. Application des transformations optimales
        df_transformed = apply_optimal_transformations(df_test, yj_transformer, bc_transformer)
        
        # 5. Chargement du pipeline de preprocessing (Notebook 02)
        feature_columns, preprocessor = load_preprocessing_pipeline(paths)
        
        # 6. Application du preprocessing
        X_test_processed = apply_preprocessing_pipeline(df_transformed, feature_columns, preprocessor)
        
        # 7. Chargement du mod√®le final (Notebook 03)
        final_model = load_final_model(paths)
        if final_model is None:
            raise ValueError("Mod√®le final non trouv√©")
        
        # 8. G√©n√©ration des pr√©dictions
        predictions = generate_final_predictions(final_model, X_test_processed, threshold)
        
        # 9. Sauvegarde des r√©sultats
        files_created = save_predictions(predictions, paths)
        
        if verbose:
            logger.info("=" * 60)
            logger.info("üèÜ PIPELINE TERMIN√â AVEC SUCC√àS !")
            logger.info(f"üìä R√©sultats : {predictions['n_positive']}/{predictions['n_total']} publicit√©s pr√©dites")
            logger.info(f"üìÅ Fichiers cr√©√©s : {len(files_created)}")
        
        return {
            'success': True,
            'n_predictions': predictions['n_total'],
            'n_positive': predictions['n_positive'],
            'positive_rate': predictions['positive_rate'],
            'threshold': threshold,
            'files_created': files_created
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur dans le pipeline : {e}")
        return {
            'success': False,
            'error': str(e),
            'files_created': []
        }

# =============================================================================
# 10. FONCTION PRINCIPALE
# =============================================================================

def main():
    """
    Fonction principale pour ex√©cuter les pr√©dictions finales.
    """
    print("üéØ PR√âDICTIONS FINALES - CHALLENGE STA211 2025")
    print("=" * 50)
    print("üìã Pipeline bas√© sur l'analyse des notebooks 01, 02, 03")
    print("üîß Transformations optimales + Imputation KNN + Mod√®le final")
    print("=" * 50)
    
    # Ex√©cution du pipeline complet
    results = run_complete_prediction_pipeline()
    
    if results['success']:
        print("\n‚úÖ SUCC√àS - Pr√©dictions g√©n√©r√©es !")
        print(f"üìä {results['n_positive']}/{results['n_predictions']} publicit√©s pr√©dites")
        print(f"üéØ Taux de publicit√©s : {results['positive_rate']:.1f}%")
        print(f"üìÅ Fichiers cr√©√©s : {len(results['files_created'])}")
        
        for file in results['files_created']:
            print(f"   ‚Ä¢ {Path(file).name}")
    else:
        print(f"\n‚ùå √âCHEC - Erreur : {results['error']}")
    
    return results

# =============================================================================
# POINT D'ENTR√âE
# =============================================================================

if __name__ == "__main__":
    main()