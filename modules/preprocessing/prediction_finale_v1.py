#!/usr/bin/env python3
#modules/preprocessing/prediction_finale.py
"""
üö® FONCTION CORRIG√âE POUR PR√âDICTIONS FINALES - Projet STA211
Corrige l'incoh√©rence identifi√©e entre les notebooks 01, 02 et 03

PROBL√àME IDENTIFI√â:
- Notebook 01: Transformation optimale mixte (Yeo-Johnson + Box-Cox)
- Notebook 02/03: Seulement StandardScaler (TRANSFORMATIONS MANQUANTES!)

SOLUTION IMPLEMENT√âE:
1. Application des transformations Box-Cox/Yeo-Johnson (Notebook 01)
2. Imputation KNN (k=19)
3. Standardisation (Notebook 02)
4. Pr√©diction avec seuil optimal (0.340)

Transformations corrig√©es:
- X1 ‚Üí Yeo-Johnson ‚Üí X1_trans
- X2 ‚Üí Yeo-Johnson ‚Üí X2_trans  
- X3 ‚Üí Box-Cox ‚Üí X3_trans
"""

import pandas as pd
import numpy as np
import joblib
import os
import logging
from pathlib import Path
from typing import Tuple, Dict, Any, Optional, Union
import warnings
warnings.filterwarnings('ignore')

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def charger_jeu_de_test(raw_data_dir: str):
    """
    Charge le jeu de donn√©es de test avec nettoyage des noms de colonnes
    (en utilisant la fonction load_data du projet).
    """
    from modules.preprocessing.data_loader import load_data

    logger = logging.getLogger(__name__)
    logger.info("üìÇ Chargement du jeu de test STA211...")

    df_test = load_data(
        file_path="data_test.csv",
        require_outcome=False,
        display_info=False,  # D√©sactiver l'affichage automatique
        raw_data_dir=raw_data_dir,
        encode_target=False
    )

    logger.info(f"üìã Dataset de test charg√© : {df_test.shape}")
    logger.info(f"üìù Colonnes : {list(df_test.columns)[:10]} ...")

    return df_test

def corriger_et_imputer_X4(df, mediane_X4=None):
    """
    Impute les valeurs manquantes de X4 par la m√©diane et convertit X4 en int si binaire.
    Args:
        df: DataFrame √† corriger (jeu de test)
        mediane_X4: valeur de m√©diane √† utiliser (optionnel, sinon calcul√©e sur df)
    Returns:
        DataFrame modifi√©
    """
    import logging
    logger = logging.getLogger(__name__)
    if 'X4' not in df.columns:
        logger.warning("X4 n'est pas dans le DataFrame, aucune correction appliqu√©e.")
        return df
    unique_values = df['X4'].dropna().unique()
    if set(unique_values).issubset({0.0, 1.0}):
        if mediane_X4 is None:
            mediane_X4 = df['X4'].median()
        df['X4'] = df['X4'].fillna(mediane_X4)
        df['X4'] = df['X4'].astype(int)
        logger.info(f"‚úÖ X4 imput√© par la m√©diane ({mediane_X4}) et converti en int.")
    else:
        logger.warning("‚ö†Ô∏è X4 contient des valeurs autres que 0 et 1, conservation en float64.")
    return df

def appliquer_transformation_variables_continues(df, verbose=False, models_dir=None):
    """
    Applique la transformation optimale (Yeo-Johnson pour X1, X2 et Box-Cox pour X3)
    sur un DataFrame, en utilisant appliquer_transformation_optimale du module transformation_optimale_mixte.
    Args:
        df: DataFrame √† transformer
        verbose: bool, affiche les informations d√©taill√©es si True
        models_dir: chemin vers le dossier des mod√®les (optionnel)
    Returns:
        DataFrame transform√© avec X1_transformed, X2_transformed, X3_transformed
    """
    import logging
    logger = logging.getLogger(__name__)
    from modules.preprocessing.transformation_optimale_mixte import appliquer_transformation_optimale
    
    # Si models_dir n'est pas fourni, utiliser le chemin par d√©faut
    if models_dir is None:
        from modules.config.paths_config import setup_project_paths
        paths = setup_project_paths()
        models_dir = paths["MODELS_DIR"] / "notebook1"
    
    df_transformed = appliquer_transformation_optimale(df, models_dir=models_dir, verbose=verbose)
    logger.info("‚úÖ Transformation optimale appliqu√©e sur X1, X2, X3 (Yeo-Johnson/Box-Cox)")
    return df_transformed
            
def nettoyer_variables_continues_transformees(df, renommer=False):
    """
    Supprime les colonnes originales X1, X2, X3 et garde les colonnes transform√©es.
    Si renommer=True, renomme X1_transformed -> X1, etc.
    Args:
        df: DataFrame √† nettoyer
        renommer: bool, si True renomme les colonnes transform√©es en X1, X2, X3
    Returns:
        DataFrame nettoy√©
    """
    import logging
    logger = logging.getLogger(__name__)
    cols_to_drop = ['X1', 'X2', 'X3']
    df_clean = df.copy()
    for col in cols_to_drop:
        if col in df_clean.columns:
            df_clean = df_clean.drop(columns=col)
    if renommer:
        df_clean = df_clean.rename(columns={
            'X1_transformed': 'X1',
            'X2_transformed': 'X2',
            'X3_transformed': 'X3'
        })
        logger.info("‚úÖ Colonnes transform√©es renomm√©es en X1, X2, X3 et originales supprim√©es.")
    else:
        logger.info("‚úÖ Colonnes originales X1, X2, X3 supprim√©es, colonnes transform√©es conserv√©es.")
    return df_clean

def supprimer_outliers_optionnelle(df, columns, supprimer=False, iqr_multiplier=1.5, method='iqr'):
    """
    Supprime les outliers des colonnes sp√©cifi√©es si supprimer=True, sinon retourne le DataFrame inchang√©.
    Args:
        df: DataFrame √† traiter
        columns: liste des colonnes √† traiter (ex: ['X1_transformed', ...])
        supprimer: bool, si True applique la suppression des outliers
        iqr_multiplier: float, multiplicateur IQR (d√©faut 1.5)
        method: str, m√©thode de d√©tection ('iqr' par d√©faut)
    Returns:
        DataFrame nettoy√© ou original
    """
    import logging
    logger = logging.getLogger(__name__)
    if supprimer:
        from modules.preprocessing.outliers import detect_and_remove_outliers
        df_clean = detect_and_remove_outliers(
            df=df,
            columns=columns,
            method=method,
            iqr_multiplier=iqr_multiplier,
            verbose=False,
            save_path=None
        )
        logger.info(f"‚úÖ Outliers supprim√©s sur {columns} (m√©thode {method}, IQR x{iqr_multiplier})")
        return df_clean
    else:
        logger.info("Suppression des outliers non appliqu√©e (option d√©sactiv√©e)")
        return df
            
def imputer_valeurs_manquantes(
    df,
    methode='knn',
    cols_to_impute=None,
    knn_k=19,
    processed_data_dir=None,
    models_dir=None
):
    """
    Impute les valeurs manquantes selon la m√©thode choisie ('knn' ou 'mice') sur les colonnes continues transform√©es.
    Renomme les colonnes transform√©es en X1_trans, X2_trans, X3_trans avant imputation.
    Args:
        df: DataFrame √† imputer
        methode: 'knn' ou 'mice'
        cols_to_impute: liste des colonnes √† imputer (d√©faut ['X1_trans', 'X2_trans', 'X3_trans'])
        knn_k: valeur de k pour KNN (d√©faut 19)
        processed_data_dir: chemin pour sauvegarde (optionnel)
        models_dir: chemin pour sauvegarde (optionnel)
    Returns:
        DataFrame imput√©
    """
    import logging
    logger = logging.getLogger(__name__)
    from modules.preprocessing.missing_values import handle_missing_values
    # Renommage des colonnes transform√©es
    rename_mapping = {
        'X1_transformed': 'X1_trans',
        'X2_transformed': 'X2_trans',
        'X3_transformed': 'X3_trans'
    }
    df_renamed = df.rename(columns=rename_mapping)
    if cols_to_impute is None:
        cols_to_impute = ['X1_trans', 'X2_trans', 'X3_trans']
    kwargs = dict(
        df=df_renamed,
        strategy="mixed_mar_mcar",
        mar_method=methode,
        mar_cols=cols_to_impute,
        mcar_cols=[],
        processed_data_dir=processed_data_dir,
        models_dir=models_dir,
        save_results=False,
        display_info=False
    )
    if methode == 'knn':
        kwargs['knn_k'] = knn_k
    df_imputed = handle_missing_values(**kwargs)
    logger.info(f"‚úÖ Imputation {methode.upper()} appliqu√©e sur {cols_to_impute} (k={knn_k if methode=='knn' else 'N/A'})")
    return df_imputed
            
def load_selected_features(imputation_method: str = "knn"):
    """
    Charge la liste des variables s√©lectionn√©es (features √† garder) selon la m√©thode d'imputation.
    Args:
        imputation_method: "knn" ou "mice"
    Returns:
        Liste des noms de variables √† garder
    """
    # Import de setup_project_paths depuis la config
    from modules.config.paths_config import setup_project_paths
    
    # R√©cup√©ration des chemins
    paths = setup_project_paths()
    MODELS_DIR = paths["MODELS_DIR"]
    
    if imputation_method == "knn":
        path = MODELS_DIR / "notebook2" / "columns_knn.pkl"
    elif imputation_method == "mice":
        path = MODELS_DIR / "notebook2" / "columns_mice.pkl"
    else:
        raise ValueError("M√©thode d'imputation inconnue : {}".format(imputation_method))
    
    try:
        return joblib.load(path)
    except FileNotFoundError:
        logger.error(f"‚ùå Fichier de features s√©lectionn√©es non trouv√©: {path}")
        # Fallback: essayer avec le chemin relatif
        fallback_path = f"models/notebook2/columns_{imputation_method}.pkl"
        try:
            return joblib.load(fallback_path)
        except FileNotFoundError:
            logger.error(f"‚ùå Fichier de fallback non trouv√© non plus: {fallback_path}")
            raise

def filter_columns(df, columns_to_keep):
    """
    Garde uniquement les colonnes sp√©cifi√©es dans columns_to_keep.
    Args:
        df: DataFrame √† filtrer
        columns_to_keep: liste des colonnes √† garder
    Returns:
        DataFrame filtr√©
    """
    cols_present = [col for col in columns_to_keep if col in df.columns]
    return df[cols_present]

def pipeline_prediction_finale(
    raw_data_dir: str = "data/raw",
    imputation_method: str = "knn",
    knn_k: int = 19,
    remove_outliers: bool = False,
    mediane_X4: float = None,
    verbose: bool = False
) -> pd.DataFrame:
    """
    Pipeline complet pour la pr√©diction finale utilisant le meilleur XGBoost.
    
    Args:
        raw_data_dir: Chemin vers les donn√©es brutes
        imputation_method: "knn" ou "mice"
        knn_k: Valeur de k pour KNN
        remove_outliers: Si True, supprime les outliers
        mediane_X4: M√©diane de X4 √† utiliser (optionnel)
        verbose: Si True, affiche les informations d√©taill√©es
    
    Returns:
        DataFrame avec les pr√©dictions et probabilit√©s
    """
    logger.info("üöÄ D√âMARRAGE DU PIPELINE DE PR√âDICTION FINALE")
    logger.info("=" * 60)
    
    # 1. Chargement du jeu de test
    logger.info("üìÇ √âtape 1: Chargement du jeu de test...")
    df_test = charger_jeu_de_test(raw_data_dir)
    if df_test is None:
        logger.error("‚ùå √âchec du chargement du jeu de test")
        return None
    
    # 2. Correction et imputation de X4
    logger.info("üîß √âtape 2: Correction et imputation de X4...")
    df_test = corriger_et_imputer_X4(df_test, mediane_X4)
    
    # 3. Application des transformations optimales
    logger.info("üîÑ √âtape 3: Application des transformations optimales...")
    df_test = appliquer_transformation_variables_continues(df_test, verbose=verbose)
    
    # 4. Nettoyage des variables transform√©es
    logger.info("üßπ √âtape 4: Nettoyage des variables transform√©es...")
    df_test = nettoyer_variables_continues_transformees(df_test, renommer=False)
    
    # 5. Suppression optionnelle des outliers
    if remove_outliers:
        logger.info("üóëÔ∏è √âtape 5: Suppression des outliers...")
        columns_to_check = ['X1_transformed', 'X2_transformed', 'X3_transformed']
        df_test = supprimer_outliers_optionnelle(
            df_test, 
            columns_to_check, 
            supprimer=True
        )
    else:
        logger.info("‚è≠Ô∏è √âtape 5: Suppression des outliers ignor√©e")
    
    # 6. Imputation des valeurs manquantes
    logger.info(f"üîß √âtape 6: Imputation des valeurs manquantes ({imputation_method.upper()})...")
    df_test = imputer_valeurs_manquantes(
        df=df_test,
        methode=imputation_method,
        knn_k=knn_k
    )
    
    # 7. S√©lection des features
    logger.info("üéØ √âtape 7: S√©lection des features...")
    try:
        selected_features = load_selected_features(imputation_method)
        df_test = filter_columns(df_test, selected_features)
        logger.info(f"‚úÖ {len(selected_features)} features s√©lectionn√©es")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la s√©lection des features: {e}")
        return None
    
    # 8. Chargement du meilleur mod√®le XGBoost
    logger.info("ü§ñ √âtape 8: Chargement du meilleur mod√®le XGBoost...")
    from modules.config.paths_config import setup_project_paths
    
    # R√©cup√©ration des chemins
    paths = setup_project_paths()
    MODELS_DIR = paths["MODELS_DIR"]
    
    model_path = MODELS_DIR / "notebook2" / f"best_xgboost_{imputation_method}.joblib"
    threshold_path = MODELS_DIR / "notebook2" / "meilleur_modele" / f"threshold_xgboost_{imputation_method}.json"
    
    try:
        best_model = joblib.load(model_path)
        logger.info(f"‚úÖ Mod√®le XGBoost charg√©: {model_path}")
    except FileNotFoundError:
        logger.error(f"‚ùå Mod√®le non trouv√©: {model_path}")
        # Fallback: essayer avec le chemin relatif
        fallback_model_path = f"models/notebook2/best_xgboost_{imputation_method}.joblib"
        try:
            best_model = joblib.load(fallback_model_path)
            logger.info(f"‚úÖ Mod√®le XGBoost charg√© (fallback): {fallback_model_path}")
        except FileNotFoundError:
            logger.error(f"‚ùå Mod√®le non trouv√© m√™me en fallback: {fallback_model_path}")
            return None
    
    # 9. Chargement du seuil optimal
    try:
        import json
        with open(threshold_path, 'r') as f:
            threshold_data = json.load(f)
            optimal_threshold = threshold_data.get('optimal_threshold', 0.5)
        logger.info(f"‚úÖ Seuil optimal charg√©: {optimal_threshold}")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur lors du chargement du seuil, essai avec fallback: {e}")
        # Fallback: essayer avec le chemin relatif
        fallback_threshold_path = f"models/notebook2/meilleur_modele/threshold_xgboost_{imputation_method}.json"
        try:
            with open(fallback_threshold_path, 'r') as f:
                threshold_data = json.load(f)
                optimal_threshold = threshold_data.get('optimal_threshold', 0.5)
            logger.info(f"‚úÖ Seuil optimal charg√© (fallback): {optimal_threshold}")
        except Exception as e2:
            logger.warning(f"‚ö†Ô∏è Erreur lors du chargement du seuil en fallback, utilisation du seuil par d√©faut (0.5): {e2}")
            optimal_threshold = 0.5
    
    # 10. Pr√©dictions
    logger.info("üéØ √âtape 9: G√©n√©ration des pr√©dictions...")
    try:
        # Pr√©dictions de probabilit√©s
        probabilities = best_model.predict_proba(df_test)[:, 1]
        
        # Pr√©dictions binaires avec seuil optimal
        predictions = (probabilities >= optimal_threshold).astype(int)
        
        # Cr√©ation du DataFrame de r√©sultats
        results_df = pd.DataFrame({
            'id': range(1, len(predictions) + 1),
            'prediction': predictions,
            'probability': probabilities
        })
        
        # Mapping des pr√©dictions
        results_df['prediction_label'] = results_df['prediction'].map({0: 'noad.', 1: 'ad.'})
        
        logger.info(f"‚úÖ Pr√©dictions g√©n√©r√©es: {len(results_df)} √©chantillons")
        logger.info(f"üìä Statistiques: {results_df['prediction_label'].value_counts().to_dict()}")
        logger.info(f"üìà Probabilit√© moyenne: {results_df['probability'].mean():.3f}")
        logger.info(f"üéØ Seuil utilis√©: {optimal_threshold}")
        
        return results_df
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la g√©n√©ration des pr√©dictions: {e}")
        return None

def generer_fichier_soumission(results_df, output_path="predictions_finales.csv", format_simple=False):
    """
    G√©n√®re le fichier de soumission final.
    
    Args:
        results_df: DataFrame avec les pr√©dictions
        output_path: Chemin du fichier de sortie
        format_simple: Si True, g√©n√®re seulement les pr√©dictions (format soumission)
                      Si False, g√©n√®re le fichier d√©taill√© complet
    
    Returns:
        Chemin du fichier g√©n√©r√©
    """
    try:
        if format_simple:
            # Format de soumission : seulement les pr√©dictions sans en-t√™te
            submission_df = results_df['prediction_label']
            submission_df.to_csv(output_path, index=False, header=False)
            logger.info(f"üìÑ Fichier de soumission g√©n√©r√© : {output_path}")
        else:
            # Format d√©taill√© : toutes les colonnes
            results_df.to_csv(output_path, index=False, header=False)
            logger.info(f"üìä Fichier d√©taill√© g√©n√©r√© : {output_path}")
        
        return output_path
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la g√©n√©ration du fichier : {e}")
        return None

def charger_modele_stacking(imputation_method: str = "mice"):
    """
    Charge le meilleur mod√®le de stacking et son seuil optimal.
    
    Args:
        imputation_method: M√©thode d'imputation ("knn" ou "mice")
    
    Returns:
        Tuple (chemin_du_modele, seuil_optimal)
    """
    from modules.config.paths_config import setup_project_paths
    import json
    
    # R√©cup√©ration des chemins
    paths = setup_project_paths()
    MODELS_DIR = paths["MODELS_DIR"]
    
    # D√©terminer le meilleur mod√®le de stacking
    # D'apr√®s les performances, MICE a un meilleur F1-score (0.9185 vs ~0.91 pour KNN)
    if imputation_method == "mice":
        model_path = MODELS_DIR / "notebook3" / "stacking" / "stack_no_refit_mice.joblib"
        threshold_path = MODELS_DIR / "notebook3" / "stacking" / "best_thr_stack_no_refit_mice.json"
    else:  # knn
        model_path = MODELS_DIR / "notebook3" / "stacking" / "stack_no_refit_knn.joblib"
        threshold_path = MODELS_DIR / "notebook3" / "stacking" / "best_thr_stack_no_refit_knn.json"
    
    try:
        # Charger le seuil optimal
        with open(threshold_path, 'r') as f:
            threshold_data = json.load(f)
            if imputation_method == "mice":
                optimal_threshold = threshold_data.get("best_thr_stack_no_refit_mice", 0.39)
            else:
                optimal_threshold = threshold_data.get("best_thr_stack_no_refit_knn", 0.5)
        
        logger.info(f"‚úÖ Mod√®le de stacking {imputation_method.upper()} charg√©: {model_path}")
        logger.info(f"‚úÖ Seuil optimal charg√©: {optimal_threshold}")
        
        return str(model_path), optimal_threshold
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du chargement du mod√®le de stacking: {e}")
        return None, 0.5

def charger_modele_xgboost(imputation_method: str = "knn"):
    """
    Charge le meilleur mod√®le XGBoost et son seuil optimal.
    
    Args:
        imputation_method: M√©thode d'imputation ("knn" ou "mice")
    
    Returns:
        Tuple (chemin_du_modele, seuil_optimal)
    """
    from modules.config.paths_config import setup_project_paths
    import json
    
    # R√©cup√©ration des chemins
    paths = setup_project_paths()
    MODELS_DIR = paths["MODELS_DIR"]
    
    model_path = MODELS_DIR / "notebook2" / f"best_xgboost_{imputation_method}.joblib"
    threshold_path = MODELS_DIR / "notebook2" / "meilleur_modele" / f"threshold_xgboost_{imputation_method}.json"
    
    try:
        # Charger le seuil optimal
        with open(threshold_path, 'r') as f:
            threshold_data = json.load(f)
            optimal_threshold = threshold_data.get('optimal_threshold', 0.5)
        
        logger.info(f"‚úÖ Mod√®le XGBoost {imputation_method.upper()} charg√©: {model_path}")
        logger.info(f"‚úÖ Seuil optimal charg√©: {optimal_threshold}")
        
        return str(model_path), optimal_threshold
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du chargement du mod√®le XGBoost: {e}")
        return None, 0.5

def generer_predictions(test_data, model, threshold, imputation_method="knn"):
    """
    G√©n√®re les pr√©dictions avec le mod√®le charg√©.
    
    Args:
        test_data: DataFrame des donn√©es de test
        model: Mod√®le d√©j√† charg√© (objet sklearn, xgboost, dict stacking, etc.)
        threshold: Seuil optimal
        imputation_method: M√©thode d'imputation pour charger les colonnes d'entra√Ænement
    
    Returns:
        DataFrame avec les pr√©dictions
    """
    try:
        import numpy as np
        
        # Charger les colonnes d'entra√Ænement pour s'assurer de l'ordre exact
        training_columns = load_training_columns(imputation_method)
        
        if training_columns is not None:
            # S'assurer que les features sont dans l'ordre exact d'entra√Ænement
            missing_cols = [col for col in training_columns if col not in test_data.columns]
            if missing_cols:
                logger.error(f"‚ùå Colonnes manquantes pour la pr√©diction : {missing_cols}")
                return None
            
            # R√©organiser les colonnes dans l'ordre exact d'entra√Ænement
            test_data_ordered = test_data[training_columns].copy()
            logger.info(f"‚úÖ Features r√©organis√©es dans l'ordre d'entra√Ænement : {len(test_data_ordered.columns)} colonnes")
        else:
            # Fallback : utiliser les donn√©es telles qu'elles sont
            test_data_ordered = test_data
            logger.warning("‚ö†Ô∏è Impossible de charger les colonnes d'entra√Ænement, utilisation des donn√©es telles qu'elles sont")
        
        # V√©rifier si c'est un mod√®le de stacking (dict)
        if isinstance(model, dict) and 'pipelines' in model:
            # Mod√®le de stacking (no refit) - pipelines est un dict
            pipelines = model['pipelines']
            
            logger.info(f"‚úÖ Utilisation de {len(test_data_ordered.columns)} features pour stacking")
            
            # G√©n√©rer les pr√©dictions avec chaque pipeline
            probas = [pipe.predict_proba(test_data_ordered)[:, 1] for pipe in pipelines.values()]
            # Moyenne des pr√©dictions
            probabilities = np.mean(probas, axis=0)
        else:
            # Mod√®le standard (sklearn, xgboost, etc.)
            logger.info(f"‚úÖ Utilisation de {len(test_data_ordered.columns)} features pour mod√®le standard")
            
            probabilities = model.predict_proba(test_data_ordered)[:, 1]
        
        # Pr√©dictions binaires avec seuil optimal
        predictions = (probabilities >= threshold).astype(int)
        
        # Cr√©ation du DataFrame de r√©sultats
        results_df = pd.DataFrame({
            'id': range(1, len(predictions) + 1),
            'prediction': predictions,
            'probability': probabilities
        })
        
        # Mapping des pr√©dictions
        results_df['prediction_label'] = results_df['prediction'].map({0: 'noad.', 1: 'ad.'})
        
        return results_df
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la g√©n√©ration des pr√©dictions: {e}")
        return None

def load_training_columns(imputation_method: str = "knn"):
    """
    Charge les colonnes utilis√©es lors de l'entra√Ænement du mod√®le.
    
    Args:
        imputation_method: M√©thode d'imputation ("knn" ou "mice")
    
    Returns:
        Liste des colonnes dans l'ordre d'entra√Ænement
    """
    from modules.config.paths_config import setup_project_paths
    import joblib
    
    paths = setup_project_paths()
    columns_path = paths["MODELS_DIR"] / "notebook2" / f"columns_{imputation_method}.pkl"
    
    try:
        columns = joblib.load(columns_path)
        logger.info(f"‚úÖ Colonnes d'entra√Ænement charg√©es : {len(columns)} features")
        return columns
        
    except FileNotFoundError:
        logger.warning(f"‚ö†Ô∏è Fichier columns_{imputation_method}.pkl non trouv√©")
        return None

def main_pipeline_prediction_with_params(
    imputation_method: str = "mice",
    use_stacking: bool = True
) -> str:
    """
    Pipeline principal pour la g√©n√©ration des pr√©dictions finales.
    Version mise √† jour utilisant run_prediction_pipeline avec toutes les transformations du notebook 3.
    
    Args:
        imputation_method: M√©thode d'imputation ("knn" ou "mice")
        use_stacking: Si True, utilise le mod√®le de stacking au lieu de XGBoost
    
    Returns:
        Chemin du fichier de soumission g√©n√©r√©
    """
    logger.info("üöÄ D√©marrage du pipeline de pr√©diction finale")
    logger.info(f"üìä Configuration : imputation={imputation_method}, stacking={use_stacking}")
    
    # D√©terminer le type de mod√®le √† utiliser
    if use_stacking:
        model_type = "stacking"  # Utilise stacking sans refit par d√©faut
        logger.info("ü§ñ Utilisation du mod√®le de stacking (sans refit)")
    else:
        model_type = "xgboost"
        logger.info("ü§ñ Utilisation du mod√®le XGBoost")
    
    # Utiliser la fonction run_prediction_pipeline mise √† jour
    try:
        output_file = run_prediction_pipeline(
            model_type=model_type,
            imputation_method=imputation_method,
            threshold=None,  # Utilise le seuil optimal automatiquement
            model_path=None,  # Utilise le chemin automatique
            threshold_path=None,  # Utilise le chemin automatique
            output_path=None,  # Utilise le nom automatique
            data_path=None  # Utilise le chemin automatique
        )
        
        if output_file:
            logger.info(f"üéâ Pipeline termin√© avec succ√®s! Fichier: {output_file}")
            return output_file
        else:
            logger.error("‚ùå √âchec du pipeline")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution du pipeline: {e}")
        return None

def load_test_data():
    """
    Charge les donn√©es de test.
    
    Returns:
        DataFrame des donn√©es de test
    """
    from modules.config.paths_config import setup_project_paths
    from pathlib import Path
    
    # Obtenir le chemin absolu du projet
    paths = setup_project_paths()
    ROOT_DIR = paths["ROOT_DIR"]
    
    # Construire le chemin absolu vers les donn√©es
    absolute_data_dir = ROOT_DIR / "data" / "raw"
    
    return charger_jeu_de_test(absolute_data_dir)

def imputer_X4(df):
    """
    Impute la variable X4 avec la m√©diane.
    
    Args:
        df: DataFrame avec les donn√©es
    
    Returns:
        DataFrame avec X4 imput√©
    """
    return corriger_et_imputer_X4(df)

def appliquer_transformations_optimales(df, imputation_method="knn"):
    """
    Applique les transformations optimales sur les variables continues.
    Charge les transformers d√©j√† sauvegard√©s dans le notebook 1.
    
    Args:
        df: DataFrame avec les donn√©es
        imputation_method: M√©thode d'imputation ("knn" ou "mice")
    
    Returns:
        DataFrame avec les transformations appliqu√©es
    """
    import logging
    logger = logging.getLogger(__name__)
    from modules.config.paths_config import setup_project_paths
    import joblib
    
    # R√©cup√©rer le chemin des mod√®les
    paths = setup_project_paths()
    models_dir = paths["MODELS_DIR"] / "notebook1" / imputation_method / f"{imputation_method}_transformers"
    
    # Charger les transformers d√©j√† sauvegard√©s
    try:
        yj_transformer = joblib.load(models_dir / "yeo_johnson_X1_X2.pkl")
        bc_transformer = joblib.load(models_dir / "box_cox_X3.pkl")
        logger.info(f"‚úÖ Transformers charg√©s depuis le notebook 1 ({imputation_method})")
    except FileNotFoundError:
        logger.error(f"‚ùå Transformers du notebook 1 non trouv√©s pour {imputation_method}. V√©rifiez que le notebook 1 a √©t√© ex√©cut√©.")
        raise
    
    # Appliquer les transformations
    df_transformed = df.copy()
    
    # Yeo-Johnson pour X1, X2
    X1_X2_data = df[['X1', 'X2']].values
    X1_X2_transformed = yj_transformer.transform(X1_X2_data)
    df_transformed['X1_transformed'] = X1_X2_transformed[:, 0]
    df_transformed['X2_transformed'] = X1_X2_transformed[:, 1]
    
    # Box-Cox pour X3
    X3_data = df[['X3']].values
    X3_transformed = bc_transformer.transform(X3_data)
    df_transformed['X3_transformed'] = X3_transformed.ravel()
    
    logger.info("‚úÖ Transformation optimale appliqu√©e sur X1, X2, X3 (Yeo-Johnson/Box-Cox)")
    return df_transformed

def nettoyer_variables_transformees(df):
    """
    Nettoie les variables transform√©es en supprimant les colonnes originales.
    
    Args:
        df: DataFrame avec les donn√©es
    
    Returns:
        DataFrame nettoy√©
    """
    return nettoyer_variables_continues_transformees(df, renommer=False)

def selectionner_features(df, imputation_method):
    """
    S√©lectionne les features selon la m√©thode d'imputation.
    
    Args:
        df: DataFrame avec les donn√©es
        imputation_method: M√©thode d'imputation ("knn" ou "mice")
    
    Returns:
        DataFrame avec les features s√©lectionn√©es
    """
    try:
        selected_features = load_selected_features(imputation_method)
        return filter_columns(df, selected_features)
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la s√©lection des features: {e}")
        return df

def main_pipeline_prediction():
    """
    Fonction principale pour ex√©cuter le pipeline complet avec le meilleur stacking.
    """
    return main_pipeline_prediction_with_params(imputation_method="mice", use_stacking=True)
    logger.info("üéØ EX√âCUTION DU PIPELINE DE PR√âDICTION FINALE")
    logger.info("=" * 60)
    
    # Ex√©cution du pipeline
    results_df = pipeline_prediction_finale(
        raw_data_dir="data/raw",
        imputation_method="knn",
        knn_k=19,
        remove_outliers=False,
        verbose=False
    )
    
    # G√©n√©ration du fichier de soumission
    if results_df is not None:
        output_file = generer_fichier_soumission(
            results_df=results_df,
            output_path="predictions_finales_xgboost.csv",
            format_simple=True
        )
        logger.info(f"üéâ Pipeline termin√© avec succ√®s! Fichier: {output_file}")
        return output_file
    else:
        logger.error("‚ùå √âchec du pipeline")
        return None

def run_prediction_pipeline(
    model_type: str = "xgboost",
    imputation_method: str = "knn",
    threshold: float = None,
    model_path: str = None,
    threshold_path: str = None,
    output_path: str = None,
    data_path: str = None
) -> str:
    """
    Pipeline g√©n√©rique pour la g√©n√©ration de pr√©dictions.
    Utilise directement prediction_submission.py qui fonctionne parfaitement.
    
    Args:
        model_type: Type de mod√®le ("xgboost", "gradboost", "svm", "randforest", "mlp", "logreg", "stacking", "stacking_refit")
        imputation_method: M√©thode d'imputation ("knn" ou "mice")
        threshold: Seuil personnalis√© (si None, utilise le seuil optimal)
        model_path: Chemin vers le mod√®le (si None, utilise le chemin automatique)
        threshold_path: Chemin vers le fichier de seuil (si None, utilise le chemin automatique)
        output_path: Chemin de sortie (si None, utilise le nom automatique)
        data_path: Chemin vers les donn√©es de test (si None, utilise le chemin automatique)
    
    Returns:
        Dictionnaire avec les chemins des fichiers g√©n√©r√©s
    """
    logger.info(f"üöÄ Pipeline g√©n√©rique : mod√®le={model_type}, imputation={imputation_method}, seuil={threshold}, model_path={model_path}, threshold_path={threshold_path}, data_path={data_path}")
    
    # Configuration des chemins
    from modules.config.paths_config import setup_project_paths
    paths = setup_project_paths()
    MODELS_DIR = paths["MODELS_DIR"]
    
    # Pour les mod√®les de stacking, utiliser prediction_submission_with_stacking.py
    if model_type in ["stacking", "stacking_refit"]:
        logger.info("üéØ Mod√®le stacking d√©tect√© - utilisation de prediction_submission_with_stacking.py")
        
        # Import et utilisation de prediction_submission_with_stacking.py
        import subprocess
        import sys
        
        # Construire la commande
        cmd = [
            sys.executable, "prediction_submission_with_stacking.py",
            "--model_type", model_type,
            "--imputation", imputation_method
        ]
        
        if threshold is not None:
            cmd.extend(["--threshold", str(threshold)])
        if model_path is not None:
            cmd.extend(["--model_path", model_path])
        if threshold_path is not None:
            cmd.extend(["--threshold_path", threshold_path])
        if output_path is not None:
            cmd.extend(["--output_path", output_path])
        if data_path is not None:
            cmd.extend(["--data_path", data_path])
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            logger.info("‚úÖ prediction_submission_with_stacking.py ex√©cut√© avec succ√®s")
            logger.info(f"üìÑ Sortie : {result.stdout}")
            
            # Retourner les chemins des fichiers g√©n√©r√©s
            return {
                "detailed": f"outputs/predictions/predictions_detailed_{model_type}_{imputation_method}.csv",
                "submission": f"outputs/predictions/submission_{model_type}_{imputation_method}.csv"
            }
            
        except subprocess.CalledProcessError as e:
            logger.error(f"‚ùå Erreur lors de l'ex√©cution de prediction_submission_with_stacking.py : {e}")
            logger.error(f"üìÑ Erreur : {e.stderr}")
            
            # Fallback : essayer d'utiliser directement les pipelines optimis√©s
            logger.info("üîÑ Tentative de fallback avec les pipelines optimis√©s...")
            return run_stacking_prediction_fallback(model_type, imputation_method, threshold, output_path, data_path)
    
    # Pour les mod√®les standard, utiliser prediction_submission.py
    else:
        logger.info("üéØ Mod√®le standard d√©tect√© - utilisation de prediction_submission.py")
        
        # Import et utilisation de prediction_submission.py
        from prediction_submission import generate_submission_file
        
        # D√©terminer les chemins
        if data_path is None:
            TEST_DATA_PATH = paths["RAW_DATA_DIR"] / "data_test.csv"
        else:
            TEST_DATA_PATH = Path(data_path)
            
        COLUMNS_PATH = paths["MODELS_DIR"] / "notebook2" / f"{imputation_method}" / f"columns_{imputation_method}.pkl"
        
        if output_path is None:
            SUBMISSION_PATH = paths["OUTPUTS_DIR"] / "predictions" / f"submission_{model_type}_{imputation_method}.csv"
        else:
            SUBMISSION_PATH = Path(output_path)
        
        try:
            # Utiliser generate_submission_file qui fonctionne parfaitement
            generate_submission_file(TEST_DATA_PATH, COLUMNS_PATH, paths["MODELS_DIR"], SUBMISSION_PATH)
            
            logger.info("‚úÖ prediction_submission.py ex√©cut√© avec succ√®s")
            
            # Retourner les chemins des fichiers g√©n√©r√©s
            return {
                "detailed": f"outputs/predictions/predictions_detailed_{model_type}_{imputation_method}.csv",
                "submission": str(SUBMISSION_PATH)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'ex√©cution de prediction_submission.py : {e}")
            return None

def main_pipeline_prediction_with_refit(
    imputation_method: str = "mice"
) -> str:
    """
    Pipeline principal pour la g√©n√©ration des pr√©dictions finales avec stacking refit.
    Version mise √† jour utilisant run_prediction_pipeline avec toutes les transformations du notebook 3.
    
    Args:
        imputation_method: M√©thode d'imputation ("knn" ou "mice")
    
    Returns:
        Chemin du fichier de soumission g√©n√©r√©
    """
    logger.info("üöÄ D√©marrage du pipeline de pr√©diction finale avec stacking refit")
    logger.info(f"üìä Configuration : imputation={imputation_method}, stacking=refit")
    
    # Utiliser la fonction run_prediction_pipeline mise √† jour avec stacking refit
    try:
        output_file = run_prediction_pipeline(
            model_type="stacking_refit",
            imputation_method=imputation_method,
            threshold=None,  # Utilise le seuil optimal automatiquement
            model_path=None,  # Utilise le chemin automatique
            threshold_path=None,  # Utilise le chemin automatique
            output_path=None,  # Utilise le nom automatique
            data_path=None  # Utilise le chemin automatique
        )
        
        if output_file:
            logger.info(f"üéâ Pipeline termin√© avec succ√®s! Fichier: {output_file}")
            return output_file
        else:
            logger.error("‚ùå √âchec du pipeline")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution du pipeline: {e}")
        return None

def run_stacking_prediction_fallback(model_type, imputation_method, threshold=None, output_path=None, data_path=None):
    """
    Fonction de fallback pour les mod√®les de stacking qui utilise prediction_stacking_direct.py.
    """
    logger.info(f"üîÑ Fallback stacking : mod√®le={model_type}, imputation={imputation_method}")
    
    try:
        # Utiliser le script d√©di√© pour les stacking
        import subprocess
        import sys
        
        # Construire la commande
        cmd = [
            sys.executable, "prediction_stacking_direct.py",
            "--model_type", model_type,
            "--imputation", imputation_method
        ]
        
        if threshold is not None:
            cmd.extend(["--threshold", str(threshold)])
        if output_path is not None:
            cmd.extend(["--output_path", output_path])
        if data_path is not None:
            cmd.extend(["--data_path", data_path])
        
        logger.info(f"üîÑ Ex√©cution de prediction_stacking_direct.py...")
        
        # Ex√©cuter sans capture pour voir les logs en temps r√©el
        result = subprocess.run(cmd, check=True)
        
        logger.info("‚úÖ prediction_stacking_direct.py ex√©cut√© avec succ√®s")
        
        # Retourner les chemins des fichiers g√©n√©r√©s
        return {
            "detailed": f"outputs/predictions/predictions_detailed_{model_type}_{imputation_method}.csv",
            "submission": f"outputs/predictions/submission_{model_type}_{imputation_method}.csv"
        }
        
    except subprocess.CalledProcessError as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution de prediction_stacking_direct.py : {e}")
        return None
    except Exception as e:
        logger.error(f"‚ùå Erreur dans le fallback stacking : {e}")
        return None

if __name__ == "__main__":
    main_pipeline_prediction()

