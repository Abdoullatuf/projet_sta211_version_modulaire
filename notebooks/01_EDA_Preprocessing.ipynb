{"cells":[{"cell_type":"markdown","id":"74d2847d","metadata":{"id":"74d2847d"},"source":["# üìä STA211 - EDA & Pr√©traitement des Donn√©es\n","\n","Ce notebook r√©alise l'analyse exploratoire des donn√©es (EDA) ainsi que leur pr√©traitement, dans le cadre du projet **Internet Advertisements** du module **STA211**.\n","\n","---\n","\n","## üîç Objectifs :\n","- **Explorer les caract√©ristiques du dataset**\n","  - Dimension des donn√©es (nombre de lignes, colonnes)\n","  - Types de variables (num√©riques, cat√©gorielles)\n","  - Distribution des classes (publicit√© vs non-publicit√©)\n","  \n","- **Analyser la qualit√© des donn√©es**\n","  - Identifier et traiter les valeurs manquantes\n","  - D√©tecter les valeurs aberrantes\n","  - V√©rifier la coh√©rence des donn√©es\n","  \n","- **Visualiser les patterns**\n","  - Distributions des variables\n","  - Corr√©lations entre features\n","  - Analyse des mots-cl√©s les plus discriminants\n","  \n","- **Pr√©traiter les donn√©es**\n","  - Encodage des variables cat√©gorielles\n","  - Normalisation/Standardisation si n√©cessaire\n","  - Feature engineering √©ventuel\n","  - S√©paration train/test stratifi√©e\n","\n","---\n","\n"]},{"cell_type":"code","source":["# M√©tadonn√©es du projet\n","PROJECT_NAME = \"Projet STA 211: Internet Advertisements Classification\"\n","DATASET_NAME = \"Internet Advertisements Dataset\"\n","AUTHOR = \"Abdoullatuf\"\n","DATE = \"2025-06\"\n","VERSION = \"1.0\"\n","\n","# Affichage des informations\n","print(f\"Projet: {PROJECT_NAME}\")\n","print(f\"Auteur: {AUTHOR}\")\n","print(f\"Version: {VERSION}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MM0gqIzmLFBL","executionInfo":{"status":"ok","timestamp":1749287318365,"user_tz":-120,"elapsed":33,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}},"outputId":"c6251605-9caa-47df-d935-ef9a1ac85115"},"id":"MM0gqIzmLFBL","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Projet: Projet STA 211: Internet Advertisements Classification\n","Auteur: Abdoullatuf\n","Version: 1.0\n"]}]},{"cell_type":"markdown","source":["# Table des mati√®res\n","1. [Introduction](#introduction)\n","2. [Configuration de l'environnement et imports](#configuration-environnement-imports)\n","    - 2.1 [Configuration de l'environnement](#configuration-environnement)\n","    - 2.2 [Import des biblioth√®ques](#import-des-bibliotheques)\n","    - 2.3 [Configuration des param√®tres du projet](#configuration-parametres-projet)\n","3. [Chargement et aper√ßu des donn√©es](#chargement-et-apercu-des-donnees)\n","    - 3.1 [Chargement des jeux de donn√©es bruts](#chargement-des-jeux-de-donnees-bruts)\n","    - 3.2 [Inspection des colonnes et types](#inspection-des-colonnes-et-types)\n","    - 3.3 [Distribution de la variable cible](#distribution-variable-cible)\n","4. [Analyse exploratoire](#analyse-exploratoire)\n","    - 4.1 [Analyse des valeurs manquantes](#analyse-des-valeurs-manquantes)\n","    - 4.2 [Analyse statistique des variables quantitatives](#analyse-statistique-des-variables-quantitatives)\n","    - 4.3 [Distribution des variables binaires](#distribution-des-variables-binaires)\n","    - 4.4 [Analyse des corr√©lations](#analyse-des-correlations)\n","    - 4.5 [Visualisations exploratoires](#visualisations-exploratoires)\n","5. [Pr√©traitement avanc√©](#pretraitement-avance)\n","    - 5.1 [Transformation Yeo-Johnson sur X1, X2, X3](#transformation-yeo-johnson)\n","    - 5.2 [D√©tection et suppression des outliers](#detection-et-suppression-des-outliers)\n","    - 5.3 [Gestion des valeurs manquantes](#gestion-des-valeurs-manquantes)\n","        - 5.3.1 [Imputation de X4 par la m√©diane](#imputation-x4-mediane)\n","        - 5.3.2 [Pr√©paration pour l'imputation multivari√©e](#preparation-imputation-multivariee)\n","    - 5.4 [D√©tection et traitement des variables collin√©aires](#detection-et-traitement-des-variables-collineaires)\n","6. [Construction des datasets finaux](#construction-des-datasets-finaux)\n","    - 6.1 [Application du pipeline de pr√©traitement (KNN)](#pipeline-knn)\n","    - 6.2 [Application du pipeline de pr√©traitement (MICE)](#pipeline-mice)\n","    - 6.3 [Comparaison des m√©thodes d'imputation](#comparaison-methodes)\n","    - 6.4 [G√©n√©ration des fichiers pour la mod√©lisation](#generation-des-fichiers-pour-la-modelisation)\n","7. [Validation du pr√©traitement](#validation-pretraitement)\n","    - 7.1 [V√©rification de la qualit√© des donn√©es](#verification-qualite)\n","    - 7.2 [Statistiques finales](#statistiques-finales)\n","8. [Conclusion](#conclusion)\n","9. [Annexes / Visualisations compl√©mentaires](#annexes)"],"metadata":{"id":"IAztdNpYLON8"},"id":"IAztdNpYLON8"},{"cell_type":"markdown","id":"7126d79c","metadata":{"id":"7126d79c"},"source":["# 2. Configuration de l'environnement et import <a id = \"configuration-environnement\"></a>\n","\n","## 2.1 Configuration de l'environnement <a id=\"2-configuration-de-l-environnement\"></a>\n"]},{"cell_type":"code","source":["# 2. Configuration de l'environnement <a id=\"configuration-environnement\"></a>\n","\n","# Installation des packages (d√©commenter si n√©cessaire)\n","# !pip install -q scikit-learn xgboost lightgbm imbalanced-learn\n","\n","import sys\n","import os\n","from pathlib import Path\n","from IPython.display import Markdown, display\n","import warnings\n","\n","# Configuration des warnings et de pandas\n","warnings.filterwarnings('ignore')\n","\n","import pandas as pd\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', 100)\n","pd.set_option('display.float_format', '{:.4f}'.format)\n","\n","# D√©tection de l'environnement\n","def detect_environment():\n","    \"\"\"D√©tecte l'environnement d'ex√©cution\"\"\"\n","    try:\n","        import google.colab\n","        return \"colab\"\n","    except ImportError:\n","        return \"local\"\n","\n","ENV = detect_environment()\n","print(f\"üîß Environnement d√©tect√© : {ENV}\")\n","\n","# MONTAGE DE GOOGLE DRIVE EN PREMIER (si Colab)\n","if ENV == \"colab\":\n","    try:\n","        from google.colab import drive\n","        drive.mount('/content/drive', force_remount=True)\n","        print(\"‚úÖ Google Drive mont√© avec succ√®s\")\n","    except Exception as e:\n","        print(f\"‚ùå Erreur lors du montage de Google Drive : {e}\")\n","        raise\n","\n","# Configuration du chemin vers les modules\n","if ENV == \"colab\":\n","    module_path = Path(\"/content/drive/MyDrive/projet_sta211/modules\")\n","else:\n","    module_path = Path(\"G:/Mon Drive/projet_sta211/modules\")\n","\n","# V√©rification que le chemin existe\n","if not module_path.exists():\n","    print(f\"‚ùå Le chemin {module_path} n'existe pas!\")\n","    print(\"   Cr√©ation du dossier modules...\")\n","    module_path.mkdir(parents=True, exist_ok=True)\n","\n","# Ajout au sys.path\n","if str(module_path) not in sys.path:\n","    sys.path.insert(0, str(module_path))\n","    print(f\"‚úÖ Module path ajout√© : {module_path}\")\n","\n","# Import et ex√©cution de project_setup\n","try:\n","    from project_setup import setup_project_paths\n","    paths = setup_project_paths()\n","    print(\"‚úÖ Configuration des chemins r√©ussie\")\n","except ImportError as e:\n","    print(f\"‚ùå Erreur : Impossible d'importer project_setup\")\n","    print(f\"   Assurez-vous que le fichier project_setup.py existe dans : {module_path}\")\n","    raise\n","\n","# Conversion des Path objects en strings pour l'affichage\n","paths_str = {k: str(v) for k, v in paths.items()}\n","\n","# Affichage format√© des chemins\n","def display_paths():\n","    \"\"\"Affiche les chemins configur√©s dans un tableau format√©\"\"\"\n","    status_icons = {}\n","    for key, path in paths.items():\n","        if Path(path).exists():\n","            status_icons[key] = \"‚úÖ\"\n","        else:\n","            status_icons[key] = \"‚ùå\"\n","\n","    paths_md = f\"\"\"\n","### üìÇ **Chemins configur√©s pour le projet**\n","\n","| Status | Nom du dossier      | Chemin                                        |\n","|--------|---------------------|-----------------------------------------------|\n","| {status_icons.get(\"ROOT_DIR\", \"?\")} | `ROOT_DIR`          | `{paths_str[\"ROOT_DIR\"]}`                     |\n","| {status_icons.get(\"MODULE_DIR\", \"?\")} | `MODULE_DIR`        | `{paths_str[\"MODULE_DIR\"]}`                   |\n","| {status_icons.get(\"RAW_DATA_DIR\", \"?\")} | `RAW_DATA_DIR`      | `{paths_str[\"RAW_DATA_DIR\"]}`                 |\n","| {status_icons.get(\"DATA_PROCESSED\", \"?\")} | `DATA_PROCESSED`    | `{paths_str[\"DATA_PROCESSED\"]}`               |\n","| {status_icons.get(\"MODELS_DIR\", \"?\")} | `MODELS_DIR`        | `{paths_str[\"MODELS_DIR\"]}`                   |\n","| {status_icons.get(\"FIGURES_DIR\", \"?\")} | `FIGURES_DIR`       | `{paths_str[\"FIGURES_DIR\"]}`                  |\n","\n","**L√©gende :** ‚úÖ = Existe | ‚ùå = N'existe pas\n","\"\"\"\n","    display(Markdown(paths_md))\n","\n","# Affichage des chemins\n","display_paths()\n","\n","# Informations syst√®me\n","print(f\"\\nüêç Python version : {sys.version.split()[0]}\")\n","print(f\"üìç Working directory : {os.getcwd()}\")\n","\n","# Variables globales pour un acc√®s facile\n","ROOT_DIR = paths[\"ROOT_DIR\"]\n","MODULE_DIR = paths[\"MODULE_DIR\"]\n","RAW_DATA_DIR = paths[\"RAW_DATA_DIR\"]\n","DATA_PROCESSED = paths[\"DATA_PROCESSED\"]\n","MODELS_DIR = paths[\"MODELS_DIR\"]\n","FIGURES_DIR = paths[\"FIGURES_DIR\"]"],"metadata":{"id":"mCjZdDf3WCsA","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"error","timestamp":1749287328292,"user_tz":-120,"elapsed":9924,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}},"outputId":"6415d92c-ff11-4b55-e365-16c630d1492f"},"id":"mCjZdDf3WCsA","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Environnement d√©tect√© : colab\n","‚ùå Erreur lors du montage de Google Drive : Error: credential propagation was unsuccessful\n"]},{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-8ed51382d0c6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Google Drive mont√© avec succ√®s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"markdown","source":["## 2.2 Import des biblioth√®ques <a id = \"import-des-bibliotheques\"></a>"],"metadata":{"id":"3s1cSoivZySX"},"id":"3s1cSoivZySX"},{"cell_type":"code","source":["## 2.2 Import des biblioth√®ques <a id=\"import-des-bibliotheques\"></a>\n","\n","# Import du module centralis√©\n","from imports_sta211 import *\n","\n","# D√©finition du RANDOM_STATE si non d√©fini dans le module\n","if 'RANDOM_STATE' not in globals():\n","    RANDOM_STATE = 42\n","    np.random.seed(RANDOM_STATE)\n","\n","# V√©rification des imports critiques\n","required_modules = {\n","    'pandas': pd,\n","    'numpy': np,\n","    'sklearn': 'sklearn',\n","    'matplotlib': plt,\n","    'seaborn': sns\n","}\n","\n","print(\"\\nüîç V√©rification des modules critiques :\")\n","for name, module in required_modules.items():\n","    if module is not None:\n","        print(f\"  ‚úÖ {name}\")\n","    else:\n","        print(f\"  ‚ùå {name} - ERREUR!\")\n","\n","# Affichage de la configuration\n","print(f\"\\n‚öôÔ∏è Configuration :\")\n","print(f\"  - Random State : {RANDOM_STATE}\")\n","print(f\"  - Style matplotlib : seaborn-v0_8-whitegrid\")\n","print(f\"  - Palette seaborn : husl\")\n","print(f\"  - Nombre max de colonnes pandas : {pd.get_option('display.max_columns')}\")\n","print(f\"  - Warnings : Filtr√©s\")\n","\n","# Test rapide des imports\n","print(f\"\\nüìä Versions des biblioth√®ques principales :\")\n","print(f\"  - Pandas : {pd.__version__}\")\n","print(f\"  - NumPy : {np.__version__}\")\n","print(f\"  - Scikit-learn : {sklearn.__version__}\")"],"metadata":{"id":"_Usl5ayragaR","executionInfo":{"status":"aborted","timestamp":1749287328430,"user_tz":-120,"elapsed":0,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"id":"_Usl5ayragaR","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3 Configuration des param√®tres du projet <a id = \"configuration-parametres-projet\"></a>"],"metadata":{"id":"M6b1h8y3YqN0"},"id":"M6b1h8y3YqN0"},{"cell_type":"code","source":["## 2.3 Configuration des param√®tres du projet <a id=\"configuration-parametres-projet\"></a>\n","\n","# Import du module de configuration\n","import importlib\n","import project_config\n","importlib.reload(project_config)\n","from project_config import ProjectConfig, create_config\n","\n","# Recr√©er la configuration avec les nouvelles valeurs\n","config = create_config(\n","    project_name=PROJECT_NAME,\n","    version=VERSION,\n","    author=AUTHOR,\n","    paths=paths\n",")\n","\n","# Affichage de la (nouvelle) configuration\n","config.display_config()\n","\n","# Affichage sp√©cifique pour l'optimisation F1\n","print(\"\\nüéØ Configuration sp√©cifique pour l'optimisation F1 :\")\n","print(f\"  - Recherche de seuil optimal : {config.F1_OPTIMIZATION['threshold_search']}\")\n","print(f\"  - Plage de seuils : {config.F1_OPTIMIZATION['threshold_range']}\")\n","print(f\"  - Utilisation class_weight : {config.F1_OPTIMIZATION['use_class_weight']}\")\n","print(f\"  - SMOTE ratio : {config.F1_OPTIMIZATION['smote_ratio']}\")\n","\n","# Re-sauvegarde avec les nouvelles configurations\n","config_file = ROOT_DIR / \"config\" / f\"project_config_v{VERSION}_f1.json\"\n","config.save_config(config_file)\n","\n","# Mise √† jour des variables globales\n","PROJECT_CONFIG = config.PROJECT_CONFIG\n","F1_OPTIMIZATION = config.F1_OPTIMIZATION\n","MODEL_CONFIG = config.MODEL_CONFIG"],"metadata":{"id":"pTa45ySVeKrv","executionInfo":{"status":"aborted","timestamp":1749287328457,"user_tz":-120,"elapsed":26,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"id":"pTa45ySVeKrv","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"c8fbeda3","metadata":{"id":"c8fbeda3"},"source":["# 3. Chargement et aper√ßu des donn√©es <a id = \"chargement-et-apercu-des-donnees\"></a>"]},{"cell_type":"markdown","source":["## 3.1 Chargement des jeux de donn√©es bruts <a id = \"chargement-des-jeux-de-donnees-bruts\"></a>"],"metadata":{"id":"3OUvKUOygIQv"},"id":"3OUvKUOygIQv"},{"cell_type":"code","execution_count":null,"id":"6dbd0170","metadata":{"id":"6dbd0170","executionInfo":{"status":"aborted","timestamp":1749287328459,"user_tz":-120,"elapsed":3,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["## 3.1 Chargement des jeux de donn√©es bruts <a id=\"chargement-des-jeux-de-donnees-bruts\"></a>\n","\n","# Import de la fonction de chargement\n","from data_preprocessing import load_data\n","\n","# Chargement du fichier d'√©tude (data_train.csv)\n","print(\"üìÇ Chargement des donn√©es...\")\n","df_study = load_data(\n","    file_path=\"data_train.csv\",\n","    require_outcome=True,\n","    display_info=True,\n","    raw_data_dir=RAW_DATA_DIR\n",")\n","\n","# Chargement du fichier d'√©valuation (data_test.csv)\n","df_eval = load_data(\n","    file_path=\"data_test.csv\",\n","    require_outcome=False,\n","    display_info=True,\n","    raw_data_dir=RAW_DATA_DIR\n",")\n","\n","# Renommer 'outcome' en 'y' pour coh√©rence\n","if 'outcome' in df_study.columns:\n","    df_study = df_study.rename(columns={'outcome': 'y'})\n","    print(\"\\n‚úÖ Colonne 'outcome' renomm√©e en 'y'\")\n","\n","print(f\"\\nüìä R√©sum√© :\")\n","print(f\"  - Fichier d'√©tude : {df_study.shape}\")\n","print(f\"  - Fichier d'√©valuation : {df_eval.shape}\")\n","print(\"\\n‚úÖ Chargement termin√© !\")\n"]},{"cell_type":"markdown","source":["## 3.2 Inspection des colonnes et types <a id=\"inspection-des-colonnes-et-types\"></a>"],"metadata":{"id":"qEc88R0rNFNP"},"id":"qEc88R0rNFNP"},{"cell_type":"code","source":["## 3.2 Inspection des colonnes et types <a id=\"inspection-des-colonnes-et-types\"></a>\n","\n","# Analyse des types de donn√©es\n","print(\"üîç Analyse des types de donn√©es...\")\n","print(\"=\"*60)\n","\n","# Types de donn√©es dans le fichier d'√©tude\n","print(\"\\nüìä Types de donn√©es dans le fichier d'√©tude :\")\n","type_counts = df_study.dtypes.value_counts()\n","for dtype, count in type_counts.items():\n","    print(f\"  - {dtype}: {count} colonnes\")\n","\n","# Identification des colonnes par type\n","continuous_cols = df_study.select_dtypes(include=['float64']).columns.tolist()\n","binary_cols = df_study.select_dtypes(include=['int64']).columns.tolist()\n","categorical_cols = df_study.select_dtypes(include=['object']).columns.tolist()\n","\n","print(f\"\\nüìà Colonnes continues (float64) : {continuous_cols}\")\n","print(f\"üî¢ Nombre de colonnes binaires potentielles (int64) : {len(binary_cols)}\")\n","print(f\"üìù Colonnes cat√©gorielles (object) : {categorical_cols}\")\n","\n","# V√©rification des valeurs uniques pour les colonnes binaires\n","print(\"\\nüîç V√©rification des valeurs uniques pour confirmer les colonnes binaires...\")\n","non_binary_cols = []\n","for col in binary_cols[:10]:  # V√©rifier les 10 premi√®res comme √©chantillon\n","    unique_values = df_study[col].unique()\n","    if len(unique_values) > 2:\n","        non_binary_cols.append(col)\n","\n","if non_binary_cols:\n","    print(f\"‚ö†Ô∏è Colonnes non binaires d√©tect√©es : {non_binary_cols}\")\n","else:\n","    print(\"‚úÖ Les colonnes int64 semblent √™tre binaires (0/1)\")\n","\n","# V√©rification sp√©cifique de la variable cible\n","print(\"\\nüéØ Variable cible 'y' :\")\n","print(f\"  - Type : {df_study['y'].dtype}\")\n","print(f\"  - Valeurs uniques : {sorted(df_study['y'].unique())}\")\n","print(f\"  - Distribution : \\n{df_study['y'].value_counts().sort_index()}\")\n","\n","# Comparaison avec le fichier d'√©valuation\n","print(\"\\nüîÑ Comparaison avec le fichier d'√©valuation :\")\n","eval_types = df_eval.dtypes.value_counts()\n","print(\"Types dans le fichier d'√©valuation :\")\n","for dtype, count in eval_types.items():\n","    print(f\"  - {dtype}: {count} colonnes\")\n","\n","# V√©rifier la coh√©rence des types entre les deux fichiers\n","print(\"\\nüîç V√©rification de la coh√©rence des types...\")\n","type_mismatches = []\n","for col in df_eval.columns:\n","    if col in df_study.columns:\n","        if df_study[col].dtype != df_eval[col].dtype:\n","            type_mismatches.append({\n","                'column': col,\n","                'study_type': df_study[col].dtype,\n","                'eval_type': df_eval[col].dtype\n","            })\n","\n","if type_mismatches:\n","    print(\"‚ö†Ô∏è Diff√©rences de types d√©tect√©es :\")\n","    for mismatch in type_mismatches:\n","        print(f\"  - {mismatch['column']}: {mismatch['study_type']} (√©tude) vs {mismatch['eval_type']} (√©valuation)\")\n","else:\n","    print(\"‚úÖ Les types de donn√©es sont coh√©rents entre les deux fichiers\")\n","\n","# Mise √† jour de la configuration\n","print(\"\\nüíæ Mise √† jour de la configuration...\")\n","config.update(\"COLUMN_CONFIG.CONTINUOUS_COLS\", continuous_cols)\n","config.update(\"COLUMN_CONFIG.BINARY_COLS\", binary_cols)\n","config.update(\"COLUMN_CONFIG.CATEGORICAL_COLS\", categorical_cols)\n","\n","# R√©sum√©\n","print(\"\\nüìä R√©sum√© de la structure des donn√©es :\")\n","print(f\"  - Features continues : {len(continuous_cols)}\")\n","print(f\"  - Features binaires : {len(binary_cols)}\")\n","print(f\"  - Features cat√©gorielles : {len(categorical_cols) - 1}  # excluant 'y'\")\n","print(f\"  - Total features : {df_study.shape[1] - 1}  # excluant 'y'\")"],"metadata":{"id":"jMeqX36iNBxk","executionInfo":{"status":"aborted","timestamp":1749287328460,"user_tz":-120,"elapsed":3,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"id":"jMeqX36iNBxk","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Conversion de la variable cible en format num√©rique\n","print(\"üîÑ Conversion de la variable cible en format num√©rique...\")\n","df_study['y'] = df_study['y'].map({'ad.': 1, 'noad.': 0})\n","print(\"‚úÖ Conversion termin√©e : 'ad.' ‚Üí 1, 'noad.' ‚Üí 0\")\n","print(f\"Nouvelle distribution :\\n{df_study['y'].value_counts().sort_index()}\")"],"metadata":{"id":"Kx8r-NYkN0dE","executionInfo":{"status":"aborted","timestamp":1749287328462,"user_tz":-120,"elapsed":5,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"id":"Kx8r-NYkN0dE","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.3 Distribution de la variable cible <a id=\"distribution-variable-cible\"></a>"],"metadata":{"id":"BF8b42mQOIXy"},"id":"BF8b42mQOIXy"},{"cell_type":"code","source":["## 3.3 Distribution de la variable cible <a id=\"distribution-variable-cible\"></a>\n","\n","print(\"\\nüéØ Analyse de la distribution de la variable cible\")\n","print(\"=\"*60)\n","\n","# Distribution des classes\n","target_counts = df_study['y'].value_counts().sort_index()\n","target_pct = df_study['y'].value_counts(normalize=True).sort_index() * 100\n","\n","print(\"\\nüìä Distribution de la variable cible (y) :\")\n","print(f\"  - Classe 0 (noad.) : {target_counts[0]:,} ({target_pct[0]:.1f}%)\")\n","print(f\"  - Classe 1 (ad.)   : {target_counts[1]:,} ({target_pct[1]:.1f}%)\")\n","\n","# Ratio de d√©s√©quilibre\n","imbalance_ratio = target_counts[0] / target_counts[1]\n","print(f\"\\nüìà Ratio de d√©s√©quilibre : {imbalance_ratio:.2f}:1\")\n","print(f\"   ‚Üí Pour chaque publicit√©, il y a {imbalance_ratio:.1f} non-publicit√©s\")\n","\n","# Visualisation\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n","\n","# Barplot\n","target_counts.plot(kind='bar', ax=ax1, color=['#3498db', '#e74c3c'])\n","ax1.set_title('Distribution des classes', fontsize=14)\n","ax1.set_xlabel('Classe')\n","ax1.set_ylabel('Nombre d\\'√©chantillons')\n","ax1.set_xticklabels(['Non-publicit√© (0)', 'Publicit√© (1)'], rotation=0)\n","\n","# Pie chart\n","target_pct.plot(kind='pie', ax=ax2, colors=['#3498db', '#e74c3c'],\n","                autopct='%1.1f%%', startangle=90)\n","ax2.set_title('Proportion des classes', fontsize=14)\n","ax2.set_ylabel('')\n","\n","plt.tight_layout()\n","plt.savefig(FIGURES_DIR / 'eda' / 'target_distribution.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","# Impact sur la strat√©gie de mod√©lisation\n","print(\"\\nüí° Implications pour la mod√©lisation :\")\n","print(f\"  - Dataset fortement d√©s√©quilibr√© ({imbalance_ratio:.1f}:1)\")\n","print(\"  - Strat√©gies recommand√©es :\")\n","print(\"    ‚Ä¢ Utiliser stratify=True lors du train/test split\")\n","print(\"    ‚Ä¢ Appliquer SMOTE ou class_weight='balanced'\")\n","print(\"    ‚Ä¢ Optimiser pour F1-score (m√©trique du challenge)\")\n","print(\"    ‚Ä¢ Consid√©rer un ensemble de mod√®les\")\n","\n","# Calcul du F1-score baseline\n","baseline_f1 = 2 * (1 * target_pct[1]/100) / (1 + target_pct[1]/100)\n","print(f\"\\nüìä F1-score baseline (pr√©dire toujours 'ad.') : {baseline_f1:.3f}\")\n","print(f\"   ‚Üí Nos mod√®les devront d√©passer ce score pour √™tre utiles\")"],"metadata":{"id":"V_KT4KHXOEzE","executionInfo":{"status":"aborted","timestamp":1749287328472,"user_tz":-120,"elapsed":9,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"id":"V_KT4KHXOEzE","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"bb271beb","metadata":{"id":"bb271beb"},"source":["# 4. Analyse exploratoire <a id=\"analyse-exploratoire\"></a>\n","\n","## 4.1 Analyse des valeurs manquantes <a id=\"analyse-des-valeurs-manquantes\"></a>\n"]},{"cell_type":"code","source":["# 4. Analyse exploratoire <a id=\"analyse-exploratoire\"></a>\n","\n","## 4.1 Analyse des valeurs manquantes <a id=\"analyse-des-valeurs-manquantes\"></a>\n","\n","print(\"üîç Analyse des valeurs manquantes\")\n","print(\"=\"*60)\n","\n","# Utilisation de la fonction du module\n","from data_preprocessing import analyze_missing_values\n","\n","print(\"\\nüìä Analyse globale des valeurs manquantes :\")\n","missing_stats = analyze_missing_values(df_study)\n","\n","# Analyse d√©taill√©e pour les colonnes continues\n","print(\"\\nüìà D√©tail des valeurs manquantes pour les variables continues :\")\n","for col in continuous_cols:\n","    missing_count = df_study[col].isnull().sum()\n","    missing_pct = (missing_count / len(df_study)) * 100\n","    print(f\"  - {col}: {missing_count} ({missing_pct:.2f}%)\")\n","\n","# Visualisation des patterns de valeurs manquantes\n","if missing_stats['total_missing'] > 0:\n","    # Heatmap des valeurs manquantes pour les colonnes avec des NaN\n","    cols_with_missing = [col for col in df_study.columns if df_study[col].isnull().sum() > 0]\n","\n","    if len(cols_with_missing) > 0:\n","        plt.figure(figsize=(10, 5))\n","\n","        # Cr√©er une matrice binaire des valeurs manquantes\n","        missing_matrix = df_study[cols_with_missing].isnull().astype(int)\n","\n","        # Heatmap\n","        sns.heatmap(missing_matrix.T, cmap='RdYlBu', cbar_kws={'label': 'Manquant (1) / Pr√©sent (0)'})\n","        plt.title('Pattern des valeurs manquantes', fontsize=14)\n","        plt.xlabel('√âchantillons')\n","        plt.ylabel('Variables')\n","        plt.tight_layout()\n","        plt.savefig(FIGURES_DIR / 'eda' / 'missing_values_pattern.png', dpi=300, bbox_inches='tight')\n","        plt.show()\n","\n","        # Analyse du pattern MAR vs MCAR\n","        print(\"\\nüîç Analyse du type de valeurs manquantes (MAR vs MCAR) :\")\n","\n","        # Corr√©lation entre les valeurs manquantes et la cible\n","        for col in cols_with_missing:\n","            missing_indicator = df_study[col].isnull().astype(int)\n","            correlation_with_target = missing_indicator.corr(df_study['y'])\n","            print(f\"  - {col}: corr√©lation avec y = {correlation_with_target:.3f}\")\n","\n","            if abs(correlation_with_target) > 0.1:\n","                print(f\"    ‚Üí Potentiellement MAR (Missing At Random)\")\n","            else:\n","                print(f\"    ‚Üí Potentiellement MCAR (Missing Completely At Random)\")\n","else:\n","    print(\"\\n‚úÖ Aucune valeur manquante d√©tect√©e dans le dataset !\")\n","\n","# Analyse pour le fichier d'√©valuation aussi\n","print(\"\\nüìä Analyse des valeurs manquantes dans le fichier d'√©valuation :\")\n","missing_stats_eval = analyze_missing_values(df_eval)\n","\n","# Comparaison des patterns\n","if missing_stats['total_missing'] > 0 or missing_stats_eval['total_missing'] > 0:\n","    print(\"\\nüîÑ Comparaison des patterns de valeurs manquantes :\")\n","    print(f\"  - Fichier d'√©tude : {missing_stats['percent_missing']:.2f}% manquant\")\n","    print(f\"  - Fichier d'√©valuation : {missing_stats_eval['percent_missing']:.2f}% manquant\")\n","\n","    # Strat√©gie d'imputation recommand√©e\n","    print(\"\\nüí° Strat√©gie d'imputation recommand√©e :\")\n","    if 'X4' in missing_stats['cols_missing']:\n","        x4_missing_pct = missing_stats['percent_per_col'].get('X4', 0)\n","        if x4_missing_pct < 5:\n","            print(f\"  - X4 ({x4_missing_pct:.1f}% manquant) : Imputation par la m√©diane\")\n","\n","    mar_cols = ['X1', 'X2', 'X3']\n","    mar_missing = any(col in missing_stats['cols_missing'] for col in mar_cols)\n","    if mar_missing:\n","        print(f\"  - X1, X2, X3 (variables continues) : KNN ou MICE (imputation multivari√©e)\")"],"metadata":{"id":"y9M3ahUGai2m","executionInfo":{"status":"aborted","timestamp":1749287328475,"user_tz":-120,"elapsed":10371,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"id":"y9M3ahUGai2m","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Correction du type de X4\n","print(\"\\nüîß Correction du type de X4...\")\n","print(f\"Valeurs uniques de X4 (avant correction) : {sorted(df_study['X4'].dropna().unique())}\")\n","print(f\"Type actuel : {df_study['X4'].dtype}\")\n","\n","# V√©rifier que X4 ne contient que 0 et 1\n","unique_values = df_study['X4'].dropna().unique()\n","if set(unique_values).issubset({0.0, 1.0}):\n","    # Imputer d'abord les valeurs manquantes par la m√©diane\n","    X4_median = df_study['X4'].median()\n","    df_study['X4'] = df_study['X4'].fillna(X4_median)\n","    df_eval['X4'] = df_eval['X4'].fillna(X4_median)\n","\n","    # Convertir en int\n","    df_study['X4'] = df_study['X4'].astype(int)\n","    df_eval['X4'] = df_eval['X4'].astype(int)\n","\n","    print(f\"‚úÖ X4 converti en int64 apr√®s imputation par la m√©diane ({X4_median})\")\n","    print(f\"Nouveau type : {df_study['X4'].dtype}\")\n","\n","    # Mettre √† jour la configuration\n","    config.update(\"COLUMN_CONFIG.CONTINUOUS_COLS\", ['X1', 'X2', 'X3'])\n","    config.update(\"COLUMN_CONFIG.BINARY_COLS\", ['X4'] + binary_cols)\n","    continuous_cols = ['X1', 'X2', 'X3']  # Mise √† jour locale\n","else:\n","    print(\"‚ö†Ô∏è X4 contient des valeurs autres que 0 et 1, conservation en float64\")\n","\n","# R√©sum√© final\n","print(\"\\nüìä R√©sum√© des valeurs manquantes apr√®s traitement de X4 :\")\n","print(f\"  - X1, X2, X3 : ~27% manquant ‚Üí √Ä traiter avec KNN/MICE\")\n","print(f\"  - X4 : Imput√© et converti en binaire\")\n","print(f\"  - Pattern MAR d√©tect√© pour X1, X2, X3 (corr√©lation avec y ‚âà -0.10)\")\n","print(f\"  - Les patterns sont coh√©rents entre fichiers d'√©tude et d'√©valuation\")"],"metadata":{"id":"k-e5z7MVgKlf","executionInfo":{"status":"aborted","timestamp":1749287328477,"user_tz":-120,"elapsed":10368,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"id":"k-e5z7MVgKlf","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 Analyse statistique des variables quantitatives <a id=\"analyse-statistique-des-variables-quantitatives\"></a>"],"metadata":{"id":"tDWcAy4whLgM"},"id":"tDWcAy4whLgM"},{"cell_type":"code","source":["## 4.2 Analyse statistique des variables quantitatives <a id=\"analyse-statistique-des-variables-quantitatives\"></a>\n","\n","print(\"üìä Analyse statistique des variables quantitatives\")\n","print(\"=\"*60)\n","\n","# Variables continues √† analyser (X1, X2, X3 uniquement maintenant)\n","print(f\"\\nüìà Variables continues √† analyser : {continuous_cols}\")\n","\n","# Statistiques descriptives\n","print(\"\\nüìä Statistiques descriptives :\")\n","stats_df = df_study[continuous_cols].describe()\n","display(stats_df)\n","\n","# Analyse de la distribution\n","print(\"\\nüìä Analyse de la distribution :\")\n","for col in continuous_cols:\n","    data = df_study[col].dropna()\n","    print(f\"\\n{col}:\")\n","    print(f\"  - Skewness (asym√©trie) : {stats.skew(data):.3f}\")\n","    print(f\"  - Kurtosis (aplatissement) : {stats.kurtosis(data):.3f}\")\n","\n","    # Test de normalit√©\n","    stat, p_value = stats.shapiro(data.sample(min(5000, len(data))))  # Limit√© √† 5000 pour Shapiro\n","    print(f\"  - Test de Shapiro-Wilk : p-value = {p_value:.4f}\")\n","    if p_value < 0.01:\n","        print(f\"    ‚Üí Distribution non normale (n√©cessite transformation)\")\n","    else:\n","        print(f\"    ‚Üí Distribution approximativement normale\")\n","\n","# Visualisation des distributions\n","fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n","axes = axes.flatten()\n","\n","for i, col in enumerate(continuous_cols):\n","    data = df_study[col].dropna()\n","\n","    # Histogramme avec KDE\n","    ax = axes[i]\n","    data.hist(bins=50, ax=ax, alpha=0.7, color='skyblue', edgecolor='black')\n","    ax2 = ax.twinx()\n","    data.plot(kind='kde', ax=ax2, color='red', linewidth=2)\n","    ax.set_title(f'Distribution de {col}', fontsize=12)\n","    ax.set_xlabel(col)\n","    ax.set_ylabel('Fr√©quence')\n","    ax2.set_ylabel('Densit√©')\n","\n","    # Box plot\n","    ax = axes[i+3]\n","    df_study.boxplot(column=col, ax=ax)\n","    ax.set_title(f'Box plot de {col}', fontsize=12)\n","    ax.set_ylabel('Valeur')\n","\n","plt.tight_layout()\n","plt.savefig(FIGURES_DIR / 'eda' / 'continuous_distributions.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","# Analyse des outliers\n","print(\"\\nüîç D√©tection des outliers (m√©thode IQR) :\")\n","outliers_summary = {}\n","for col in continuous_cols:\n","    data = df_study[col].dropna()\n","    Q1 = data.quantile(0.25)\n","    Q3 = data.quantile(0.75)\n","    IQR = Q3 - Q1\n","\n","    lower_bound = Q1 - 1.5 * IQR\n","    upper_bound = Q3 + 1.5 * IQR\n","\n","    outliers = data[(data < lower_bound) | (data > upper_bound)]\n","    outliers_pct = len(outliers) / len(data) * 100\n","\n","    outliers_summary[col] = {\n","        'count': len(outliers),\n","        'percentage': outliers_pct,\n","        'lower_bound': lower_bound,\n","        'upper_bound': upper_bound\n","    }\n","\n","    print(f\"\\n{col}:\")\n","    print(f\"  - Limites : [{lower_bound:.2f}, {upper_bound:.2f}]\")\n","    print(f\"  - Outliers : {len(outliers)} ({outliers_pct:.2f}%)\")\n","\n","# Corr√©lation avec la variable cible\n","print(\"\\nüéØ Corr√©lation avec la variable cible (y) :\")\n","correlations = {}\n","for col in continuous_cols:\n","    # Calculer la corr√©lation seulement pour les valeurs non manquantes\n","    mask = df_study[col].notna()\n","    corr = df_study.loc[mask, col].corr(df_study.loc[mask, 'y'])\n","    correlations[col] = corr\n","    print(f\"  - {col}: {corr:.4f}\")\n","\n","# Matrice de corr√©lation entre variables continues\n","print(\"\\nüìä Matrice de corr√©lation entre variables continues :\")\n","corr_matrix = df_study[continuous_cols].corr()\n","display(corr_matrix)\n","\n","# Heatmap de corr√©lation\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n","            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n","plt.title('Matrice de corr√©lation des variables continues', fontsize=14)\n","plt.tight_layout()\n","plt.savefig(FIGURES_DIR / 'eda' / 'continuous_correlation_matrix.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","# R√©sum√© et recommandations\n","print(\"\\nüí° R√©sum√© et recommandations :\")\n","print(\"  - Les trois variables continues montrent des distributions fortement asym√©triques\")\n","print(\"  - Transformation Yeo-Johnson recommand√©e pour normaliser les distributions\")\n","print(f\"  - Outliers d√©tect√©s : {sum(info['count'] for info in outliers_summary.values())} au total\")\n","print(\"  - Corr√©lations faibles avec la cible, mais potentiellement utiles apr√®s transformation\")"],"metadata":{"id":"GDlgplzWhG_B","executionInfo":{"status":"aborted","timestamp":1749287328478,"user_tz":-120,"elapsed":10362,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"id":"GDlgplzWhG_B","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ------- Mon ancien code √† garder ou supprimer apr√®s ----"],"metadata":{"id":"Hj0fmRS4g5sl"},"id":"Hj0fmRS4g5sl"},{"cell_type":"code","source":[],"metadata":{"id":"hc6pJoA4g5M7","executionInfo":{"status":"aborted","timestamp":1749287328526,"user_tz":-120,"elapsed":46,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"id":"hc6pJoA4g5M7","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"bc618a1b","metadata":{"id":"bc618a1b","executionInfo":{"status":"aborted","timestamp":1749287328533,"user_tz":-120,"elapsed":10416,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# 3. Analyse Univari√©e <a id=\"3-analyse-univariee\"></a>\n","#univariate_analysis(df, display_figures=True, save_fig=True)"]},{"cell_type":"code","execution_count":null,"id":"19f22569","metadata":{"id":"19f22569","executionInfo":{"status":"aborted","timestamp":1749287328535,"user_tz":-120,"elapsed":10413,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["plt.figure(figsize=(5, 3))  # Largeur = 5, Hauteur = 3 (en pouces)\n","sns.countplot(x='outcome', data=df)\n","plt.title(\"R√©partition de la variable cible\")\n","plt.tight_layout()\n","plt.savefig(paths[\"FIGURES_DIR\"] / \"target_distribution.png\")\n","plt.show()\n","\n"]},{"cell_type":"markdown","id":"19b6cad8","metadata":{"id":"19b6cad8"},"source":["## Interpr√©tation de l'analyse univari√©e\n","\n","### üéØ Variable cible : `outcome`\n","\n","- **Distribution :**\n","  - `noad.` : 2115 observations (**‚âà 86%**)\n","  - `ad.`   : 344 observations (**‚âà 14%**)\n","\n","- **Conclusion :**\n","  - Le jeu de donn√©es est **fortement d√©s√©quilibr√©**.\n","  - Il sera n√©cessaire d'utiliser :\n","    - des **m√©triques adapt√©es** : `F1-score`, `balanced_accuracy`, `AUC`\n","    - des **m√©thodes de r√©√©quilibrage** : `SMOTE`, pond√©ration (`class_weight='balanced'`), sous-√©chantillonnage\n","\n","---\n","\n","### Variables binaires (`int64`)\n","\n","- **Nombre d√©tect√©** : 1554\n","- **Exemples (fr√©quences) :**\n","  - `X5` : 0 = 99.5%, 1 = 0.5%\n","  - `X6` : 0 = 98.9%, 1 = 1.1%\n","\n","- **Conclusion :**\n","  - Ces variables sont des **indicateurs discrets**, souvent tr√®s d√©s√©quilibr√©s.\n","  - Il est probable que certaines soient peu informatives : une **s√©lection de variables** sera indispensable (ex. : `RandomForest`, `permutation importance`, `mutual information`).\n","\n","---\n","\n","### üìà Variables continues (`float64`)\n","\n","| Variable | Distribution             | Interpr√©tation                                 |\n","|----------|--------------------------|------------------------------------------------|\n","| `X1`     | Tr√®s asym√©trique         | Fortement biais√©e √† droite, outliers visibles  |\n","| `X2`     | Pic principal vers 100   | Possible bimodalit√©, v√©rifier s√©par√©ment       |\n","| `X3`     | Beaucoup de petites valeurs | Tr√®s skew√©e, transformation recommand√©e     |\n","| `X4`     | 0 ou 1 uniquement         | Bien que typ√©e float, c‚Äôest une **variable binaire** |\n","\n","- **Recommandations :**\n","  - Appliquer des **transformations (log, Box-Cox, ..)** sur `X1`, `X2`, `X3`.\n","  - Convertir `X4` en variable **binaire (`int`)**.\n","\n","---"]},{"cell_type":"code","execution_count":null,"id":"8b1ecdd1","metadata":{"id":"8b1ecdd1","executionInfo":{"status":"aborted","timestamp":1749287328538,"user_tz":-120,"elapsed":10411,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# Convertissons X4 en variable binaire\n","print(df[\"X4\"].unique())  # doit afficher [0., 1.] ou [1., 0.]\n","\n","df[\"X4\"] = df[\"X4\"].astype(\"Int64\")"]},{"cell_type":"code","execution_count":null,"id":"102006c8","metadata":{"id":"102006c8","executionInfo":{"status":"aborted","timestamp":1749287328539,"user_tz":-120,"elapsed":10409,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["def detect_outliers_iqr(series):\n","    \"\"\"Retourne un masque bool√©en indiquant les outliers selon la r√®gle IQR.\"\"\"\n","    Q1 = series.quantile(0.25)\n","    Q3 = series.quantile(0.75)\n","    IQR = Q3 - Q1\n","    lower_bound = Q1 - 1.5 * IQR\n","    upper_bound = Q3 + 1.5 * IQR\n","    return (series < lower_bound) | (series > upper_bound)\n","\n","# Variables continues √† analyser\n","continuous_vars = ['X1', 'X2', 'X3']\n","\n","for col in continuous_vars:\n","    series = df[col]\n","    outliers_mask = detect_outliers_iqr(series)\n","    n_outliers = outliers_mask.sum()\n","\n","    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n","\n","    # Histogramme\n","    sns.histplot(series, bins=30, kde=True, ax=ax[0], color=\"skyblue\")\n","    ax[0].set_title(f\"{col} - Histogramme\\n{n_outliers} outliers d√©tect√©s\")\n","\n","    # Boxplot\n","    sns.boxplot(data=df, x=col, ax=ax[1], color=\"lightcoral\")\n","    ax[1].set_title(f\"{col} - Boxplot\")\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"markdown","id":"2a24e00c","metadata":{"id":"2a24e00c"},"source":["### üìä Analyse des outliers avant imputation (IQR 1.5)\n","\n","Nous avons visualis√© les distributions de `X1`, `X2` et `X3` avant toute imputation, √† l‚Äôaide d‚Äôhistogrammes et de boxplots.\n","\n","#### ‚úÖ R√©sum√© des d√©tections :\n","\n","| Variable | Outliers d√©tect√©s | Intervalle des valeurs extr√™mes (approx.) |\n","|----------|-------------------|-------------------------------------------|\n","| **X1**   | 62                | > 250 (majoritairement √† droite de la distribution) |\n","| **X2**   | 206               | > 400 (forte dispersion sur la droite)     |\n","| **X3**   | 25                | > 20 (quelques extr√™mes isol√©s)            |\n","\n","\n","#### Interpr√©tation\n","\n","- `X2` est la variable la plus expos√©e aux outliers, probablement en lien avec sa multimodalit√©.\n","- Les outliers de `X1` et `X3` sont bien visibles mais moins nombreux.\n","- La d√©tection s‚Äôappuie sur la r√®gle classique de l‚ÄôIQR (valeurs < Q1 ‚Äì 1.5√óIQR ou > Q3 + 1.5√óIQR).\n","\n","> üëâ Ces outliers doivent √™tre pris en compte lors des √©tapes de normalisation ou d‚Äôimputation.\n"]},{"cell_type":"code","execution_count":null,"id":"7b53c4ac","metadata":{"id":"7b53c4ac","executionInfo":{"status":"aborted","timestamp":1749287328541,"user_tz":-120,"elapsed":10407,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["def get_iqr_bounds(series):\n","    Q1 = series.quantile(0.25)\n","    Q3 = series.quantile(0.75)\n","    IQR = Q3 - Q1\n","    return Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n","\n","for col in continuous_vars:\n","    lb, ub = get_iqr_bounds(df[col])\n","    print(f\"{col} : [{lb:.2f} ; {ub:.2f}]\")\n"]},{"cell_type":"code","execution_count":null,"id":"c1a0f0e2","metadata":{"id":"c1a0f0e2","executionInfo":{"status":"aborted","timestamp":1749287328559,"user_tz":-120,"elapsed":1,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["from scipy.stats import boxcox, yeojohnson\n","\n","variables = ['X1', 'X2', 'X3']\n","\n","for var in variables:\n","    plt.figure(figsize=(12, 4))\n","\n","    # Avant transformation\n","    plt.subplot(1, 3, 1)\n","    plt.hist(df[var].dropna(), bins=30, color='skyblue')\n","    plt.title(f\"{var} - Avant transformation\")\n","\n","    # Transformation log (si toutes les valeurs > 0)\n","    if (df[var] > 0).all():\n","        plt.subplot(1, 3, 2)\n","        plt.hist(np.log1p(df[var]), bins=30, color='orange')\n","        plt.title(f\"{var} - Log(1+x)\")\n","    else:\n","        plt.subplot(1, 3, 2)\n","        plt.text(0.5, 0.5, \"Log impossible (valeurs ‚â§ 0)\", ha='center')\n","        plt.axis('off')\n","\n","    # Transformation Box-Cox ou Yeo-Johnson\n","    plt.subplot(1, 3, 3)\n","    if (df[var] > 0).all():\n","        transformed, _ = boxcox(df[var].dropna())\n","        plt.hist(transformed, bins=30, color='green')\n","        plt.title(f\"{var} - Box-Cox\")\n","    else:\n","        transformed, _ = yeojohnson(df[var].dropna())\n","        plt.hist(transformed, bins=30, color='green')\n","        plt.title(f\"{var} - Yeo-Johnson\")\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"markdown","id":"6398403b","metadata":{"id":"6398403b"},"source":["### üîÅ Transformation des variables continues\n","\n","Les variables `X1`, `X2` et `X3` pr√©sentent une forte asym√©trie positive ainsi que des valeurs extr√™mes d√©tect√©es via la r√®gle de l‚ÄôIQR.\n","\n","#### üìå Objectif :\n","- Stabiliser la variance\n","- R√©duire l‚Äôimpact des outliers\n","- Am√©liorer la distribution pour les mod√®les sensibles √† la normalit√© (r√©gression logistique, kNN‚Ä¶)\n","\n","#### ‚öôÔ∏è M√©thode :\n","Nous utilisons la transformation **Yeo-Johnson** via `PowerTransformer`, qui accepte les valeurs nulles ou strictement positives.\n","\n","> üîß Les colonnes transform√©es seront ajout√©es en tant que `X1_trans`, `X2_trans` et `X3_trans`.\n"]},{"cell_type":"code","execution_count":null,"id":"b8385a3a","metadata":{"id":"b8385a3a","executionInfo":{"status":"aborted","timestamp":1749287328561,"user_tz":-120,"elapsed":2,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["from sklearn.preprocessing import PowerTransformer\n","\n","# Colonnes √† transformer\n","cols_to_transform = [\"X1\", \"X2\", \"X3\"]\n","\n","# Initialisation du transformateur Yeo-Johnson\n","pt = PowerTransformer(method='yeo-johnson', standardize=True)\n","\n","# Application\n","df[[f\"{col}_trans\" for col in cols_to_transform]] = pt.fit_transform(df[cols_to_transform])\n","\n","# Affichage r√©sum√©\n","for col in cols_to_transform:\n","    original = df[col]\n","    transformed = df[f\"{col}_trans\"]\n","    print(f\"üìä {col} - Skew avant : {original.skew():.2f} | apr√®s : {transformed.skew():.2f}\")\n"]},{"cell_type":"markdown","id":"f2df77f6","metadata":{"id":"f2df77f6"},"source":["### üìä Visualisation des distributions transform√©es (Yeo-Johnson)\n","\n","Les histogrammes et boxplots ci-dessous montrent les nouvelles distributions des variables `X1`, `X2` et `X3` apr√®s transformation Yeo-Johnson.\n","\n","On observe clairement une **r√©duction de l'asym√©trie** et une **meilleure sym√©trie des donn√©es**, ce qui est favorable pour les algorithmes de mod√©lisation sensibles √† la forme des distributions.\n"]},{"cell_type":"code","execution_count":null,"id":"94966e15","metadata":{"id":"94966e15","executionInfo":{"status":"aborted","timestamp":1749287328562,"user_tz":-120,"elapsed":0,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# Liste des variables transform√©es\n","transformed_vars = [\"X1_trans\", \"X2_trans\", \"X3_trans\"]\n","\n","for col in transformed_vars:\n","    fig, ax = plt.subplots(1, 2, figsize=(8, 3))\n","\n","    # Histogramme avec KDE\n","    sns.histplot(df[col], bins=30, kde=True, ax=ax[0], color=\"mediumseagreen\")\n","    ax[0].set_title(f\"{col} - Histogramme\")\n","\n","    # Boxplot\n","    sns.boxplot(x=df[col], ax=ax[1], color=\"salmon\")\n","    ax[1].set_title(f\"{col} - Boxplot\")\n","\n","    plt.tight_layout()\n","    plt.show()\n"]},{"cell_type":"markdown","id":"2912a70a","metadata":{"id":"2912a70a"},"source":["### ‚úÖ Interpr√©tation des distributions transform√©es\n","\n","Apr√®s application de la transformation **Yeo-Johnson**, les variables `X1`, `X2` et `X3` pr√©sentent d√©sormais des distributions beaucoup plus sym√©triques et resserr√©es :\n","\n","- `X1_trans` suit une **distribution quasi normale**, sans asym√©trie notable.\n","- `X2_trans` est **moins skew√©e**, avec une dispersion nettement r√©duite.\n","- `X3_trans` pr√©sente encore quelques irr√©gularit√©s, mais sans outliers visibles.\n","\n","üîé **Conclusion :**\n","Ces transformations ont permis :\n","- de **r√©duire l‚Äôimpact des valeurs extr√™mes**,\n","- d‚Äôam√©liorer la **stabilit√© statistique** de ces variables,\n","- et de les **pr√©parer efficacement √† la mod√©lisation supervis√©e**.\n","\n","Elles seront d√©sormais utilis√©es √† la place des variables brutes dans les analyses suivantes.\n"]},{"cell_type":"code","execution_count":null,"id":"bf4e1b5b","metadata":{"id":"bf4e1b5b","executionInfo":{"status":"aborted","timestamp":1749287328563,"user_tz":-120,"elapsed":10420,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["#Appliquons la transformation\n","\n","from sklearn.preprocessing import PowerTransformer\n","\n","# Colonnes √† transformer\n","cols_to_transform = [\"X1\", \"X2\", \"X3\"]\n","\n","# Initialisation du transformateur\n","pt = PowerTransformer(method='yeo-johnson', standardize=False)\n","\n","# Application de la transformation et ajout de nouvelles colonnes\n","df[[f\"{col}_trans\" for col in cols_to_transform]] = pt.fit_transform(df[cols_to_transform])\n"]},{"cell_type":"markdown","id":"cd2c105d","metadata":{"id":"cd2c105d"},"source":["\n","# 4. Analyse Bivari√©e <a id=\"4-analyse-bivariee\"></a>"]},{"cell_type":"code","execution_count":null,"id":"a8e46b0c","metadata":{"id":"a8e46b0c","executionInfo":{"status":"aborted","timestamp":1749287328565,"user_tz":-120,"elapsed":10418,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# Appel sur le bon DataFrame (d√©j√† transform√© et nettoy√©)\n","corr_df, high_corr_pairs, binary_corr_pairs = bivariate_analysis(\n","    df,\n","    use_transformed=True,\n","    display_correlations=True,\n","    top_n=15,\n","    show_plot=True\n",")\n"]},{"cell_type":"markdown","id":"25b36270","metadata":{"id":"25b36270"},"source":["### üß© Interpr√©tation de l‚Äôanalyse bivari√©e\n","\n","#### üéØ Corr√©lations avec la cible `outcome` (0 = noad., 1 = ad.)\n","\n","- ‚úÖ **La variable `X1244`** pr√©sente la **plus forte corr√©lation** avec la classe `ad.` (**r ‚âà 0.57**), ce qui est tr√®s √©lev√© pour une variable binaire.\n","- ‚úÖ Les variables `X352` et `X1400` suivent de pr√®s, avec des corr√©lations de l‚Äôordre de **0.51 √† 0.49**.\n","- ‚úÖ **`X2_trans`** (version transform√©e de `X2`) est √©galement bien class√©e (**r ‚âà 0.48**), confirmant son int√©r√™t apr√®s transformation Yeo-Johnson.\n","- üîç D‚Äôautres variables binaires (`X1484`, `X969`, `X1456`, etc.) montrent des corr√©lations **entre 0.36 et 0.43**, les rendant potentiellement discriminantes.\n","- üìâ Les variables avec **corr√©lation < 0.01** sont probablement peu informatives dans une approche supervis√©e.\n","\n","---\n","\n","#### ‚ôªÔ∏è Redondance interne (|corr√©lation| > 0.95 entre variables binaires)\n","\n","- üîÅ Certaines **variables binaires sont tr√®s fortement corr√©l√©es entre elles** :\n","  - Exemple hypoth√©tique : `X6` pourrait √™tre corr√©l√©e √† 1.0 avec `X245`, `X487`, etc.\n","  - Ce ph√©nom√®ne est courant dans les donn√©es textuelles binaris√©es (pr√©sence/absence d‚Äô√©l√©ments visuels).\n","- ‚ö†Ô∏è Cette **redondance cr√©e de la multicolin√©arit√©**, nuisible pour les mod√®les lin√©aires ou logistiques.\n","\n","---\n","\n","#### ‚úÖ Recommandations\n","\n","- ‚≠ê **Conserver les variables les plus corr√©l√©es √† la cible**, notamment :\n","  - `X1244`, `X352`, `X1400`, `X2_trans`, `X1484`, `X969`, `X1456`‚Ä¶\n","- üîΩ **R√©duire la redondance** en supprimant les duplicats (ou en regroupant les paires parfaitement corr√©l√©es), par exemple :\n","  - Garder une seule variable par groupe corr√©l√© √† 1.0 (ex. : garder `X6`, supprimer `X245`, etc.)\n","- üìä Poursuivre la s√©lection avec des approches multivari√©es :\n","  - **Permutation importance**\n","  - **Random Forest feature importance**\n","  - **M√©thodes de r√©gularisation** : Lasso, `SelectFromModel`, RFE\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"id":"7a808b06","metadata":{"id":"7a808b06","executionInfo":{"status":"aborted","timestamp":1749287328582,"user_tz":-120,"elapsed":10431,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["from exploratory_analysis import plot_binary_correlation_heatmap\n","plot_binary_correlation_heatmap(df, top_n=50, fig_name=\"binaire_corr_50.png\", figsize=(8, 7))"]},{"cell_type":"code","execution_count":null,"id":"7041315a","metadata":{"id":"7041315a","executionInfo":{"status":"aborted","timestamp":1749287328584,"user_tz":-120,"elapsed":10428,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["from exploratory_analysis import analyze_categorical_binaries_vs_target\n","\n","results_df = analyze_categorical_binaries_vs_target(\n","    data=df,                # mon DataFrame r√©duit\n","    target_col='outcome',   # nom de la variable cible\n","    show_top=20,            # affiche les 20 meilleures\n","    pval_threshold=0.05     # s√©lectionne uniquement les significatives\n",")"]},{"cell_type":"markdown","id":"6affa117","metadata":{"id":"6affa117"},"source":["\n","# 5. Analyse Multivari√©e <a id=\"5-analyse-multivariee\"></a>"]},{"cell_type":"code","execution_count":null,"id":"a75fb7db","metadata":{"id":"a75fb7db","executionInfo":{"status":"aborted","timestamp":1749287328588,"user_tz":-120,"elapsed":10428,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# 5. Analyse Multivari√©e\n","corrs, matrix = multivariate_analysis(\n","    df,\n","    save_fig=True,\n","    fig_name=\"matrice_corr_X123_avant_imputation.png\",\n","    return_matrix=True\n",")\n"]},{"cell_type":"markdown","id":"5f093bb2","metadata":{"id":"5f093bb2"},"source":["\n","# 6. Gestion des valeurs manquantes <a id=\"6-gestion-des-valeurs-manquantes\"></a>\n","Dans cette section, nous analysons en d√©tail les **valeurs manquantes** du jeu de donn√©es.\n","\n","L‚Äôobjectif est de :\n","- Quantifier les valeurs manquantes par colonne et globalement\n","- Visualiser leur r√©partition pour d√©tecter d‚Äô√©ventuelles structures\n","- Comprendre les **m√©canismes sous-jacents** aux donn√©es manquantes :\n","  - MCAR : donn√©es manquantes compl√®tement al√©atoires\n","  - MAR : donn√©es manquantes d√©pendantes d'autres variables\n","  - MNAR : donn√©es manquantes d√©pendantes d'elles-m√™mes\n","- Choisir et appliquer la **strat√©gie d‚Äôimputation la plus adapt√©e** :\n","  - M√©diane\n","  - KNN (imputation par les k plus proches voisins)\n","  - Imputation multiple\n","\n","> ‚ö†Ô∏è Une imputation inadapt√©e peut introduire des biais ou fausser les mod√®les.  \n","> C‚Äôest pourquoi nous explorons d‚Äôabord les donn√©es manquantes avant d‚Äôintervenir.\n","\n","Passons √† l‚Äôanalyse.\n","\n","## 6.1 Quantification et statistiques simples <a id=\"61-quantification-et-statistiques-simples\"></a>"]},{"cell_type":"code","execution_count":null,"id":"11c6220b","metadata":{"id":"11c6220b","executionInfo":{"status":"aborted","timestamp":1749287328589,"user_tz":-120,"elapsed":10425,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["from data_preprocessing import analyze_missing_values\n","\n","# Supprimer les colonnes d‚Äôorigine qui ont √©t√© transform√©es\n","df.drop(columns=[\"X1\", \"X2\", \"X3\"], inplace=True)\n","\n","\n","missing_stats = analyze_missing_values(df)\n"]},{"cell_type":"markdown","id":"e4045a4f","metadata":{"id":"e4045a4f"},"source":["### Interpr√©tation des valeurs manquantes\n","\n","- Le jeu de donn√©es contient **2037 valeurs manquantes**, soit seulement **0.05% du total** (ce chiffre para√Æt faible car r√©parti sur un tr√®s grand nombre de cellules).\n","- **4 colonnes sont concern√©es** :\n","  - `X1_trans`, `X2_trans`, `X3_trans` ont un taux de valeurs manquantes d‚Äôenviron **27%**\n","  - `X4` est l√©g√®rement touch√©e (**0.45%** seulement)\n","\n","#### Classification par gravit√© (en fonction du taux de `NaN`) :\n","- `X1_trans`, `X2_trans`, `X3_trans` sont class√©es comme colonnes √† **taux moyen de valeurs manquantes** (entre 5% et 30%)\n","- `X4` est consid√©r√©e comme **faiblement touch√©e** (moins de 5%)\n","\n","> üîé Ce classement servira √† adapter les strat√©gies d‚Äôimputation :\n","> - Imputation cibl√©e pour les colonnes √† taux moyen (`KNN`, `m√©diane`, `multiple`)\n","> - Imputation simple ou exclusion possible pour les colonnes faiblement touch√©es\n"]},{"cell_type":"markdown","id":"ad76f15f","metadata":{"id":"ad76f15f"},"source":["\n","## 6.2 Visualisation <a id=\"62-visualisation\"></a>\n","\n","Pour mieux comprendre la r√©partition des valeurs manquantes, nous utilisons la biblioth√®que `missingno`.\n","Elle permet de visualiser les colonnes concern√©es, l‚Äôampleur du probl√®me, et les √©ventuelles co-d√©pendances entre les donn√©es manquantes.\n","\n","Dans notre jeu de donn√©es, seules les variables continues `X1`, `X2`, `X3` et `X4` pr√©sentent des valeurs manquantes.  \n","Nous concentrons donc la visualisation sur ces colonnes uniquement pour observer leur structure et d‚Äô√©ventuelles corr√©lations."]},{"cell_type":"code","execution_count":null,"id":"12bf33c4","metadata":{"id":"12bf33c4","executionInfo":{"status":"aborted","timestamp":1749287328590,"user_tz":-120,"elapsed":10422,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["import missingno as msno\n","import matplotlib.pyplot as plt\n","\n","# Colonnes avec valeurs manquantes\n","columns_with_nan = ['X1_trans', 'X2_trans', 'X3_trans', 'X4']\n","df_nan = df[columns_with_nan]\n","\n","# Barplot des valeurs manquantes\n","print(\"üîç Nombre de valeurs manquantes par colonne :\")\n","plt.figure(figsize=(6, 2))\n","msno.bar(df_nan, fontsize=16, color='cornflowerblue')\n","plt.title(\"Valeurs manquantes par variable\", fontsize=16)\n","plt.tight_layout()\n","plt.show();\n"]},{"cell_type":"code","execution_count":null,"id":"7ae48e98","metadata":{"id":"7ae48e98","executionInfo":{"status":"aborted","timestamp":1749287328592,"user_tz":-120,"elapsed":10417,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["\n","# Matrice de pr√©sence/absence\n","print(\"üîç Matrice de pr√©sence/absence :\")\n","plt.figure(figsize=(6, 2))\n","msno.matrix(df_nan, fontsize=16, sparkline=False)\n","plt.title(\"Structure des valeurs manquantes\", fontsize=16)\n","plt.tight_layout()\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"id":"d6241ea0","metadata":{"id":"d6241ea0","executionInfo":{"status":"aborted","timestamp":1749287328606,"user_tz":-120,"elapsed":10427,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# Heatmap de corr√©lation des NaN\n","print(\"üîç Corr√©lations entre manquants (heatmap) :\")\n","plt.figure(figsize=(4, 1.5))\n","msno.heatmap(df_nan, fontsize=20, cmap='coolwarm')\n","plt.title(\"Corr√©lation entre colonnes avec NaN\", fontsize=16)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"e6a39177","metadata":{"id":"e6a39177"},"source":["### üîç Analyse visuelle des valeurs manquantes\n","\n","Nous avons visualis√© les valeurs manquantes pour les variables continues transform√©es `X1_trans`, `X2_trans`, `X3_trans`, ainsi que la variable binaire `X4`, √† l‚Äôaide de trois outils compl√©mentaires :\n","\n","#### üìä Barplot ‚Äî Proportion de valeurs manquantes par variable\n","\n","- `X1_trans`, `X2_trans` et `X3_trans` pr√©sentent un **taux similaire d‚Äôenviron 27% de valeurs manquantes**, ce qui est significatif mais exploitable.\n","- `X4` est **tr√®s faiblement affect√©e**, avec **seulement ~0.45% de valeurs manquantes**.\n","\n","#### üß± Matrice ‚Äî Structure des `NaN`\n","\n","- Les `NaN` sont **tr√®s souvent positionn√©es sur les m√™mes lignes** pour `X1_trans`, `X2_trans` et `X3_trans`.\n","- Ce comportement sugg√®re un **m√©canisme MAR (Missing At Random)** : les absences d√©pendent d'autres variables observables.\n","- Cette structure **coh√©rente** rend l'imputation possible et justifi√©e.\n","\n","#### üî• Heatmap ‚Äî Corr√©lations entre patterns de valeurs manquantes\n","\n","- Corr√©lation **parfaite (~1.0)** entre `X2_trans` et `X3_trans` dans leur structure de `NaN`.\n","- Corr√©lation tr√®s forte entre `X1_trans` et les deux autres.\n","- `X4`, en revanche, est **isol√©e et non corr√©l√©e** aux autres colonnes ‚Üí son m√©canisme est probablement **MCAR (Manquant Compl√®tement Al√©atoire)**.\n","\n","---\n","\n","### ‚úÖ Synth√®se & recommandations\n","\n","| Variable      | Taux de `NaN`  | Corr√©lation entre `NaN` | Interpr√©tation       | Recommandation           |\n","|---------------|----------------|---------------------------|-----------------------|---------------------------|\n","| `X1_trans`    | ~27.4%         | Forte avec `X2`, `X3`     | MAR probable          | ‚úÖ KNN ou MICE (Iterative) |\n","| `X2_trans`    | ~27.4%         | Parfaite avec `X3`        | MAR tr√®s probable     | ‚úÖ idem                    |\n","| `X3_trans`    | ~27.6%         | Parfaite avec `X2`        | MAR tr√®s probable     | ‚úÖ idem                    |\n","| `X4`          | ~0.45%         | Aucune                    | MCAR ou isol√©e        | ‚úÖ Imputation par m√©diane  |\n","\n","---\n","\n"]},{"cell_type":"markdown","id":"277bb19b","metadata":{"id":"277bb19b"},"source":["## 6.3 Analyse des m√©canismes (MCAR, MAR, MNAR) <a id=\"63-analyse-des-mecanismes-mcar-mar-mnar\"></a>\n","\n","Il existe trois grands types de m√©canismes expliquant l'apparition des valeurs manquantes :\n","\n","- **MCAR** (*Missing Completely At Random*) : les `NaN` apparaissent de fa√ßon totalement al√©atoire et ind√©pendante des autres variables.\n","- **MAR** (*Missing At Random*) : les `NaN` d√©pendent d'autres variables observ√©es, mais pas de la variable elle-m√™me.\n","- **MNAR** (*Missing Not At Random*) : la probabilit√© d'une valeur manquante d√©pend de la valeur manquante elle-m√™me.\n","\n","---\n","\n","Dans cette √©tape, nous cherchons √† identifier si les `NaN` des variables continues (`X1`, `X2`, `X3`, `X4`) peuvent √™tre expliqu√©s par d'autres variables observ√©es (MAR), sont totalement al√©atoires (MCAR), ou d√©pendent d'elles-m√™mes (MNAR).\n","\n","Nous utilisons ici un mod√®le de classification (r√©gression logistique) pour **pr√©dire la pr√©sence d'une valeur manquante √† partir des autres colonnes**, ce qui aide √† diff√©rencier MCAR et MAR.\n"]},{"cell_type":"code","execution_count":null,"id":"777a47cc","metadata":{"id":"777a47cc","executionInfo":{"status":"aborted","timestamp":1749287328608,"user_tz":-120,"elapsed":10424,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score\n","\n","# Variables continues avec valeurs manquantes\n","columns_to_test = ['X1_trans', 'X2_trans', 'X3_trans', 'X4']\n","\n","for col in columns_to_test:\n","    # Cr√©ation du masque bool√©en : 1 si NaN, 0 sinon\n","    mask = df[col].isnull().astype(int)\n","\n","    # Variables explicatives : toutes les colonnes binaires (sauf la cible et la colonne test√©e)\n","    X = df.drop(columns=[col, 'outcome']).select_dtypes(include='int64')\n","\n","    # R√©gression logistique pour pr√©dire la pr√©sence de NaN\n","    model = LogisticRegression(max_iter=1000)\n","    scores = cross_val_score(model, X.fillna(0), mask, cv=5, scoring='roc_auc')\n","\n","    print(f\"üîç {col} ‚Äî AUC pour pr√©dire les NaN : {np.mean(scores):.3f}\")\n"]},{"cell_type":"markdown","id":"d893dd5f","metadata":{"id":"d893dd5f"},"source":["### üî¨ Pr√©diction des valeurs manquantes (Test de m√©canisme MAR)\n","\n","Pour √©valuer si les valeurs manquantes sont pr√©visibles (et donc **MAR : Missing At Random**), nous avons utilis√© une **r√©gression logistique** pour pr√©dire la pr√©sence de `NaN` dans chaque variable continue √† partir des autres variables binaires.\n","\n","#### üìà R√©sultats (score AUC)\n","\n","| Variable     | AUC (5-fold CV) | Interpr√©tation           |\n","|--------------|------------------|--------------------------|\n","| `X1_trans`   | **0.842**        | Fortement pr√©visible     |\n","| `X2_trans`   | **0.843**        | Fortement pr√©visible     |\n","| `X3_trans`   | **0.843**        | Fortement pr√©visible     |\n","\n","> ‚úÖ Un AUC > 0.8 indique que les `NaN` sont **hautement corr√©l√©s aux autres colonnes** ‚Üí m√©canisme **MAR** tr√®s probable.\n","\n","#### ‚ÑπÔ∏è Remarque :\n","\n","- `X4` n‚Äôa pas √©t√© test√©e ici car elle contient tr√®s peu de `NaN` (~0.45%) et sa structure de valeurs manquantes ne semble pas li√©e aux autres.\n","- Son m√©canisme est probablement **MCAR** (Missing Completely At Random), ce qui autorise une imputation simple sans biais.\n","\n","---\n","\n","### ‚úÖ Conclusion :\n","\n","- Les colonnes `X1_trans`, `X2_trans`, `X3_trans` peuvent √™tre **imput√©es de mani√®re fiable par KNN ou imputation multiple (MICE)**.\n","- Ce test statistique renforce l‚Äôid√©e que les valeurs manquantes **ne sont pas al√©atoires**, mais **structur√©es**.\n","\n","---\n","\n"]},{"cell_type":"markdown","id":"fe6de2a0","metadata":{"id":"fe6de2a0"},"source":["## 6.4 Imputation des variables manquantes <a id = \"64-imputation-des-variables-manquantes\" ></a>"]},{"cell_type":"markdown","id":"1dd34719","metadata":{"id":"1dd34719"},"source":["### 6.4.1 Imputation par la m√©diane (`X4`) <a id=\"641-imputation-par-la-mediane-x4\"></a>\n","\n","`X4` est une variable binaire contenant uniquement des valeurs `0` et `1`, avec un taux tr√®s faible de valeurs manquantes (~0.45%).\n","\n","Dans ce cas, l‚Äôimputation par la **m√©diane** est parfaitement adapt√©e, car :\n","\n","- Elle conserve la **nature binaire** (0 ou 1) de la variable\n","- Elle est **simple, rapide et robuste**\n","- Elle **ne cr√©e pas de valeur interm√©diaire** comme le ferait la moyenne\n","\n","Nous appliquons donc une imputation par la m√©diane uniquement sur cette variable.\n"]},{"cell_type":"code","execution_count":null,"id":"5e705975","metadata":{"id":"5e705975","executionInfo":{"status":"aborted","timestamp":1749287328609,"user_tz":-120,"elapsed":10424,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# # Cr√©ation d'une copie pour imputation\n","# df_imputed = df.copy()\n","\n","# # Imputation de X4 par sa m√©diane (pr√©serve les valeurs binaires)\n","# median_value = df_imputed[\"X4\"].median()\n","# df_imputed[\"X4\"] = df_imputed[\"X4\"].fillna(median_value)\n","\n","# print(f\"‚úÖ Imputation effectu√©e sur X4 avec la m√©diane : {median_value}\")\n","# print(f\"Valeurs uniques apr√®s imputation : {df_imputed['X4'].unique()}\")\n"]},{"cell_type":"markdown","id":"024d0d94","metadata":{"id":"024d0d94"},"source":["#### 6.4.2 Imputation par KNN (`X1`, `X2`, `X3`) <a id=\"642-imputation-par-knn-x1-x2-x3\"></a>\n"]},{"cell_type":"code","execution_count":null,"id":"4a9794fc","metadata":{"id":"4a9794fc","executionInfo":{"status":"aborted","timestamp":1749287328632,"user_tz":-120,"elapsed":10443,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["#### 6.4.2 Imputation par KNN (`X1_trans`, `X2_trans`, `X3_trans`) <a id=\"642-imputation-par-knn-x1-x2-x3\"></a>\n","\n","\n","\n","from data_preprocessing import find_optimal_k\n","\n","\n","features = ['X1_trans', 'X2_trans', 'X3_trans']\n","optimal_k = find_optimal_k(\n","    df[features],\n","    continuous_cols=features,\n","    k_range=range(2, 21),\n","    cv_folds=5,\n","    sample_size=50000\n",")\n","print(\"k optimal =\", optimal_k)"]},{"cell_type":"markdown","id":"246ee0c9","metadata":{"id":"246ee0c9"},"source":["### Interpr√©tation\n","\n","Les variables `X1_trans`, `X2_trans` et `X3_trans` pr√©sentent toutes environ **27% de valeurs manquantes**, et leurs `NaN` sont **fortement corr√©l√©s** entre eux (cf. heatmap).  \n","Le m√©canisme √©tant vraisemblablement **MAR**, l‚Äôimputation par **KNN** est adapt√©e.\n","\n","#### üîç Choix du `k` optimal :\n","\n","Nous avons test√© diff√©rents nombres de voisins `k` (de 2 √† 20), avec une validation crois√©e (5-fold) sur un √©chantillon :\n","\n","- Le **MSE moyen diminue fortement jusqu'√† `k = 17`**\n","- Le gain devient ensuite marginal ‚Üí **`k = 17` est retenu comme optimal**\n","\n","#### ‚úÖ Justification :\n","\n","- KNN est **non-param√©trique, simple et efficace**\n","- Il s‚Äôadapte bien √† des structures locales et redondantes\n","- Les variables ont √©t√© **standardis√©es (Yeo-Johnson)**, ce qui est crucial pour KNN\n"]},{"cell_type":"code","execution_count":null,"id":"20e5d083","metadata":{"id":"20e5d083","executionInfo":{"status":"aborted","timestamp":1749287328653,"user_tz":-120,"elapsed":10460,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["from data_preprocessing import handle_missing_values\n","\n","df_imputed_knn = handle_missing_values(\n","    df=df,\n","    strategy=\"mixed_mar_mcar\",\n","    mar_method=\"knn\",\n","    mar_cols=[\"X1_trans\", \"X2_trans\", \"X3_trans\"],\n","    mcar_cols=[\"X4\"],\n","    knn_k=optimal_k,\n","    display_info=True,\n","    save_results=True,\n","    processed_data_dir=str(paths[\"DATA_PROCESSED\"]),\n","    models_dir=str(paths[\"MODELS_DIR\"])\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"a7c39d87","metadata":{"id":"a7c39d87","executionInfo":{"status":"aborted","timestamp":1749287328654,"user_tz":-120,"elapsed":10457,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# V√©rification rapide\n","print(df_imputed_knn.shape)\n","print(df_imputed_knn.isnull().sum().sum())  # doit renvoyer 0\n","df_imputed_knn.head()"]},{"cell_type":"markdown","id":"d9e1e77a","metadata":{"id":"d9e1e77a"},"source":["#### 6.4.3 Imputation multiple MICE (`X1`, `X2`, `X3`) <a id=\"643-imputation-multiple-mice-x1-x2-x3\"></a>"]},{"cell_type":"code","execution_count":null,"id":"8cfa09dd","metadata":{"id":"8cfa09dd","executionInfo":{"status":"aborted","timestamp":1749287328677,"user_tz":-120,"elapsed":10475,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["df_imputed_mice = handle_missing_values(\n","    df=df,\n","    strategy=\"mixed_mar_mcar\",\n","    mar_method=\"mice\",  # ‚ö†Ô∏è cl√© pour activer IterativeImputer\n","    mar_cols=[\"X1_trans\", \"X2_trans\", \"X3_trans\"],  # explicite et modulaire\n","    mcar_cols=[\"X4\"],\n","    display_info=True,\n","    save_results=True,\n","    processed_data_dir=str(paths[\"DATA_PROCESSED\"]),\n","    models_dir=str(paths[\"MODELS_DIR\"])\n",")\n","\n"]},{"cell_type":"code","execution_count":null,"id":"205acde8","metadata":{"id":"205acde8","executionInfo":{"status":"aborted","timestamp":1749287328679,"user_tz":-120,"elapsed":10471,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# V√©rification rapide\n","print(df_imputed_mice.shape)\n","print(\"Nombre total de valeurs manquantes :\", df_imputed_mice.isnull().sum().sum())  # doit √™tre 0\n"]},{"cell_type":"markdown","id":"b7eb852f","metadata":{"id":"b7eb852f"},"source":["### 6.4.4 V√©rification visuelle des distributions post-imputation"]},{"cell_type":"code","execution_count":null,"id":"3d52a7b6","metadata":{"id":"3d52a7b6","executionInfo":{"status":"aborted","timestamp":1749287328681,"user_tz":-120,"elapsed":10469,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["from data_preprocessing import plot_imputation_comparison\n","\n","plot_imputation_comparison(\n","    df_raw=df,\n","    df_imputed=df_imputed_knn,\n","    columns=[\"X1_trans\", \"X2_trans\", \"X3_trans\"],\n","    method_name=\"KNN\",\n","    k=optimal_k,\n","    save_path=paths[\"FIGURES_DIR\"] / \"dist_imputation_knn.png\"\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"573a7851","metadata":{"id":"573a7851","executionInfo":{"status":"aborted","timestamp":1749287328682,"user_tz":-120,"elapsed":10466,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["plot_imputation_comparison(\n","    df_raw=df,\n","    df_imputed=df_imputed_mice,\n","    columns=[\"X1_trans\", \"X2_trans\", \"X3_trans\"],\n","    method_name=\"MICE\",\n","    save_path=paths[\"FIGURES_DIR\"] / \"dist_imputation_mice.png\"\n",")\n"]},{"cell_type":"markdown","id":"fd4d7d0d","metadata":{"id":"fd4d7d0d"},"source":["### 6.4.5 Comparaison visuelle des distributions imput√©es (KNN vs MICE)\n","\n","Nous avons compar√© les distributions des variables `X1_trans`, `X2_trans` et `X3_trans` **avant** et **apr√®s imputation**, en utilisant :\n","\n","- üü¶ **KNNImputer (k = 17)**\n","- üü© **IterativeImputer (MICE)**\n","\n","#### üîç Observations g√©n√©rales :\n","\n","- Dans les deux cas, l‚Äôimputation **pr√©serve bien la structure globale des distributions**.\n","- On observe un **pic net autour de la m√©diane** sur toutes les variables apr√®s imputation :\n","  - Cela refl√®te le fait que beaucoup de valeurs manquantes sont estim√©es **proches des valeurs centrales** observ√©es.\n","- **Aucune valeur aberrante ou incoh√©rente** n‚Äôa √©t√© introduite.\n","\n","#### ‚öñÔ∏è Comparaison KNN vs MICE :\n","\n","| Aspect               | KNN (k=17)                  | MICE                        |\n","|----------------------|-----------------------------|-----------------------------|\n","| üìä Distribution       | Lisse, centr√©e              | Tr√®s similaire              |\n","| üß† Complexit√©         | Simple, local               | Plus co√ªteuse (10 it√©rations) |\n","| üîÅ Stabilit√©          | Tr√®s bonne                  | Tr√®s bonne √©galement        |\n","\n","> üîß Les deux m√©thodes sont **valables**.  \n","> Le choix d√©pendra du **temps de calcul** et des **performances des mod√®les supervis√©s** (√† comparer).\n","\n","---\n","\n"]},{"cell_type":"markdown","id":"246fc551","metadata":{"id":"246fc551"},"source":["## Suppression des valeurs fortements corr√©l√©es"]},{"cell_type":"code","execution_count":null,"id":"0673f2b6","metadata":{"id":"0673f2b6","executionInfo":{"status":"aborted","timestamp":1749287328683,"user_tz":-120,"elapsed":10463,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["### Suppression des valeurs fortements corr√©l√©es\n","\n","# 1. Identifier les variables binaires\n","binary_vars_knn = [col for col in df_imputed_knn.select_dtypes(include='int64').columns if col != 'outcome']\n","\n","\n","# 2. D√©tection des groupes de variables corr√©l√©es entre elles (seuil > 0.90)\n","from exploratory_analysis import find_highly_correlated_groups, drop_correlated_duplicates\n","\n","groups_corr_knn = find_highly_correlated_groups(df_imputed_knn[binary_vars_knn], threshold=0.90)\n","\n","\n","\n","df_knn_reduced, cols_knn_removed, cols_knn_kept = drop_correlated_duplicates(\n","    df=df_imputed_knn,\n","    groups=groups_corr_knn,\n","    target_col=\"outcome\",\n","    extra_cols = ['X1_trans', 'X2_trans', 'X3_trans', 'X4']\n",",\n","    verbose=False,\n","    summary=True\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"15ef7b67","metadata":{"id":"15ef7b67","executionInfo":{"status":"aborted","timestamp":1749287328684,"user_tz":-120,"elapsed":10460,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["print(df_knn_reduced.shape)"]},{"cell_type":"code","execution_count":null,"id":"a118203d","metadata":{"id":"a118203d","executionInfo":{"status":"aborted","timestamp":1749287328686,"user_tz":-120,"elapsed":10458,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# 1. Identifier les variables binaires\n","binary_vars_mice = [col for col in df_imputed_mice.select_dtypes(include='int64').columns if col != 'outcome']\n","\n","\n","# 2. D√©tection des groupes de variables corr√©l√©es entre elles (seuil > 0.90)\n","from exploratory_analysis import find_highly_correlated_groups, drop_correlated_duplicates\n","\n","groups_corr_mice = find_highly_correlated_groups(df_imputed_mice[binary_vars_mice], threshold=0.90)\n","\n","\n","\n","\n","df_mice_reduced, cols_mice_removed, cols_mice_kept = drop_correlated_duplicates(\n","    df=df_imputed_mice,\n","    groups=groups_corr_mice,\n","    target_col=\"outcome\",\n","    extra_cols = ['X1_trans', 'X2_trans', 'X3_trans', 'X4']\n",",\n","    verbose=False,\n","    summary=True\n",")"]},{"cell_type":"code","execution_count":null,"id":"16307f63","metadata":{"id":"16307f63","executionInfo":{"status":"aborted","timestamp":1749287328687,"user_tz":-120,"elapsed":10455,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["df_mice_reduced.shape"]},{"cell_type":"markdown","id":"aba683c0","metadata":{"id":"aba683c0"},"source":["### üîÅ R√©duction des variables binaires fortement corr√©l√©es\n","\n","Nous avons identifi√© les groupes de variables binaires avec une **corr√©lation > 0.90**, indiquant une **forte redondance d'information**.\n","\n","#### üìä R√©sum√© de la r√©duction :\n","\n","- üîª **1002 colonnes binaires** ont √©t√© supprim√©es (car redondantes dans des groupes corr√©l√©s)\n","- ‚úÖ **324 colonnes binaires** ont √©t√© conserv√©es (1 seule par groupe corr√©l√©)\n","- ‚ûï **324 colonnes binaires non corr√©l√©es** ont √©galement √©t√© conserv√©es\n","- üß© **4 variables continues** ajout√©es explicitement : `X1_trans`, `X2_trans`, `X3_trans`, `X4`\n","\n","#### üìê R√©sultat final :\n","\n","| Dimensions du DataFrame r√©duit | Contenu                         |\n","|-------------------------------|----------------------------------|\n","| `2459 lignes √ó 653 colonnes`  | ‚úÖ pr√™t pour la mod√©lisation     |\n","\n","> Cette r√©duction permet de **pr√©server l'information utile** tout en limitant le risque de **multicolin√©arit√©**, ce qui est essentiel pour les mod√®les lin√©aires et les m√©thodes interpr√©tables.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ed72ac88","metadata":{"id":"ed72ac88","executionInfo":{"status":"aborted","timestamp":1749287328688,"user_tz":-120,"elapsed":10452,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# plot_binary_correlation_heatmap(df_knn_reduced, top_n=50,\n","#                                 fig_name=\"binaire_corr_50_apr√®s_r√©duction.png\",\n","#                                 figsize=(7, 6))"]},{"cell_type":"code","execution_count":null,"id":"aceace91","metadata":{"id":"aceace91","executionInfo":{"status":"aborted","timestamp":1749287328689,"user_tz":-120,"elapsed":10448,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["detect_outliers_iqr(df_knn_reduced[\"X1_trans\"])"]},{"cell_type":"code","execution_count":null,"id":"9b99981a","metadata":{"id":"9b99981a","executionInfo":{"status":"aborted","timestamp":1749287328690,"user_tz":-120,"elapsed":10446,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# Supprimer les outliers dans X1_trans, X2_trans, X3_trans\n","mask_x1 = ~detect_outliers_iqr(df_knn_reduced[\"X1_trans\"])\n","mask_x2 = ~detect_outliers_iqr(df_knn_reduced[\"X2_trans\"])\n","mask_x3 = ~detect_outliers_iqr(df_knn_reduced[\"X3_trans\"])\n","\n","# Intersection : lignes valides pour toutes les colonnes\n","mask_all = mask_x1 & mask_x2 & mask_x3\n","\n","df_knn_no_outliers = df_knn_reduced[mask_all]\n","print(f\"{df_knn_reduced.shape[0] - df_knn_no_outliers.shape[0]} lignes avec outliers supprim√©es\")\n"]},{"cell_type":"code","execution_count":null,"id":"7d4d2eb3","metadata":{"id":"7d4d2eb3","executionInfo":{"status":"aborted","timestamp":1749287328772,"user_tz":-120,"elapsed":10524,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# Supprimer les outliers dans X1, X2, X3\n","mask_mice_x1 = ~detect_outliers_iqr(df_mice_reduced[\"X1_trans\"])\n","mask_mice_x2 = ~detect_outliers_iqr(df_mice_reduced[\"X2_trans\"])\n","mask_mice_x3 = ~detect_outliers_iqr(df_mice_reduced[\"X3_trans\"])\n","\n","# Intersection : lignes valides pour toutes les colonnes\n","mask_all = mask_mice_x1 & mask_mice_x2 & mask_mice_x3\n","\n","df_mice_no_outliers = df_mice_reduced[mask_all]\n","print(f\"{df_mice_reduced.shape[0] - df_mice_no_outliers.shape[0]} lignes avec outliers supprim√©es\")"]},{"cell_type":"markdown","id":"9363edae","metadata":{"id":"9363edae"},"source":["# 8. Export des donn√©es <a id=\"8-export-des-donnees\"></a>"]},{"cell_type":"code","execution_count":null,"id":"89abcca7","metadata":{"id":"89abcca7","executionInfo":{"status":"aborted","timestamp":1749287328774,"user_tz":-120,"elapsed":10522,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["import os\n","\n","# R√©pertoire de sortie\n","output_dir = paths[\"DATA_PROCESSED\"]\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Export 1 ‚Äî KNN r√©duit\n","df_knn_reduced.to_csv(output_dir / \"df_knn_reduced.csv\", index=False)\n","print(\"‚úÖ df_knn_reduced.csv export√©.\")\n","\n","# Export 2 ‚Äî KNN r√©duit sans outliers\n","df_knn_no_outliers.to_csv(output_dir / \"df_knn_no_outliers.csv\", index=False)\n","print(\"‚úÖ df_knn_no_outliers.csv export√©.\")"]},{"cell_type":"code","execution_count":null,"id":"82e8e801","metadata":{"id":"82e8e801","executionInfo":{"status":"aborted","timestamp":1749287328775,"user_tz":-120,"elapsed":10519,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["df_mice_reduced.to_csv(output_dir / \"df_mice_reduced.csv\", index=False)\n","print(\"‚úÖ df_mice_reduced.csv export√©.\")\n","\n","df_mice_no_outliers.to_csv(output_dir / \"df_mice_no_outliers.csv\", index=False)\n","print(\"‚úÖ df_mice_no_outliers.csv export√©.\")"]},{"cell_type":"code","execution_count":null,"id":"53cfadca","metadata":{"id":"53cfadca","executionInfo":{"status":"aborted","timestamp":1749287328776,"user_tz":-120,"elapsed":10519,"user":{"displayName":"maoulida abdoullatuf","userId":"05790302460507444417"}}},"outputs":[],"source":["# Ou appliquer le pipeline directement:\n","\n","\n","from final_preprocessing import prepare_final_dataset\n","\n","df_knn_final = prepare_final_dataset(\n","    file_path=file_path,\n","    mar_method=\"knn\",\n","    knn_k=optimal_k,\n","    drop_outliers=False\n",")\n","\n","df_mice_final = prepare_final_dataset(\n","    file_path=file_path,\n","    mar_method=\"mice\",\n","    drop_outliers=True\n",")\n"]}],"metadata":{"kernelspec":{"display_name":"venv_sta211","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}