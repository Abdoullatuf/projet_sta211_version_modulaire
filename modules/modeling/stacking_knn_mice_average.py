## Moyennage des probabilit√©s stacking KNN / MICE

import numpy as np
import joblib
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix

def load_stacking_results(stacking_dir, imputation_type):
    """
    Charge les r√©sultats de stacking pour un type d'imputation donn√©
    """
    # Charger le mod√®le de stacking
    stack_model = joblib.load(stacking_dir / f"stack_no_refit_{imputation_type}.joblib")
    
    # Charger le seuil optimal
    with open(stacking_dir / f"best_thr_stack_no_refit_{imputation_type}.json", "r") as f:
        threshold_data = json.load(f)
    
    # Charger les m√©triques de performance
    with open(stacking_dir / f"stack_no_refit_{imputation_type}_performance.json", "r") as f:
        performance = json.load(f)
    
    return stack_model, threshold_data[f"best_thr_stack_no_refit_{imputation_type}"], performance

def predict_stacking_proba(X, stack_model):
    """
    Fait des pr√©dictions de probabilit√© avec le mod√®le de stacking
    
    Parameters:
    -----------
    X : array-like
        Donn√©es √† pr√©dire
    stack_model : dict
        Mod√®le de stacking charg√©
    
    Returns:
    --------
    proba_mean : array
        Probabilit√©s moyennes
    """
    pipelines = stack_model["pipelines"]
    
    # Pr√©dictions de probabilit√© pour chaque mod√®le
    proba_rf = pipelines["rf"].predict_proba(X)[:, 1]
    proba_xgb = pipelines["xgb"].predict_proba(X)[:, 1]
    proba_logreg = pipelines["logreg"].predict_proba(X)[:, 1]
    proba_svm = pipelines["svm"].predict_proba(X)[:, 1]
    proba_mlp = pipelines["mlp"].predict_proba(X)[:, 1]
    
    # Moyenne des probabilit√©s
    proba_mean = np.mean([proba_rf, proba_xgb, proba_logreg, proba_svm, proba_mlp], axis=0)
    
    return proba_mean

def average_knn_mice_stacking(X_test_knn, X_test_mice, y_test_knn, y_test_mice, stacking_dir):
    """
    Moyennage des probabilit√©s entre stacking KNN et MICE
    """
    print("üîÑ Moyennage des probabilit√©s stacking KNN / MICE")
    print("="*60)
    
    # 1. Charger les mod√®les de stacking
    print("üì• Chargement des mod√®les de stacking...")
    
    stack_knn, thr_knn, perf_knn = load_stacking_results(stacking_dir, "knn")
    stack_mice, thr_mice, perf_mice = load_stacking_results(stacking_dir, "mice")
    
    print(f"‚úÖ Mod√®le KNN charg√© (F1 = {perf_knn['f1_score']:.4f})")
    print(f"‚úÖ Mod√®le MICE charg√© (F1 = {perf_mice['f1_score']:.4f})")
    
    # 2. Pr√©dictions de probabilit√©
    print("\nüîÆ G√©n√©ration des pr√©dictions de probabilit√©...")
    
    proba_knn = predict_stacking_proba(X_test_knn, stack_knn)
    proba_mice = predict_stacking_proba(X_test_mice, stack_mice)
    
    print(f"‚úÖ Probabilit√©s KNN : {len(proba_knn)} √©chantillons")
    print(f"‚úÖ Probabilit√©s MICE : {len(proba_mice)} √©chantillons")
    
    # 3. Moyennage des probabilit√©s
    print("\nüìä Moyennage des probabilit√©s...")
    
    # V√©rifier que les deux ensembles ont la m√™me taille
    if len(proba_knn) != len(proba_mice):
        print("‚ö†Ô∏è  Attention : Les ensembles KNN et MICE ont des tailles diff√©rentes")
        min_size = min(len(proba_knn), len(proba_mice))
        proba_knn = proba_knn[:min_size]
        proba_mice = proba_mice[:min_size]
        y_test_knn = y_test_knn[:min_size]
        y_test_mice = y_test_mice[:min_size]
        print(f"üìè Taille ajust√©e : {min_size} √©chantillons")
    
    # Moyennage simple
    proba_average = np.mean([proba_knn, proba_mice], axis=0)
    
    print(f"‚úÖ Probabilit√©s moyenn√©es : {len(proba_average)} √©chantillons")
    
    # 4. Optimisation du seuil pour le moyennage
    print("\nüéØ Optimisation du seuil pour le moyennage...")
    
    thresholds = np.linspace(0.2, 0.8, 61)
    best_f1 = 0
    best_thr_average = 0.5
    
    for thr in thresholds:
        y_pred = (proba_average >= thr).astype(int)
        f1 = f1_score(y_test_knn, y_pred)  # Utiliser y_test_knn comme r√©f√©rence
        if f1 > best_f1:
            best_f1 = f1
            best_thr_average = thr
    
    # 5. Pr√©diction finale au seuil optimal
    y_pred_opt = (proba_average >= best_thr_average).astype(int)
    
    # 6. Analyse d√©taill√©e
    f1 = f1_score(y_test_knn, y_pred_opt)
    precision = precision_score(y_test_knn, y_pred_opt)
    recall = recall_score(y_test_knn, y_pred_opt)
    cm = confusion_matrix(y_test_knn, y_pred_opt)
    
    print(f"\nüìä R√âSULTATS DU MOYENNAGE KNN/MICE")
    print("="*60)
    print(f"F1-Score : {f1:.4f} (seuil = {best_thr_average:.3f})")
    print(f"Pr√©cision : {precision:.4f}")
    print(f"Rappel : {recall:.4f}")
    print("Matrice de confusion :")
    print(cm)
    
    # 7. Comparaison avec les mod√®les individuels
    print(f"\nüìà COMPARAISON AVEC LES MOD√àLES INDIVIDUELS")
    print("="*60)
    
    comparison_data = {
        "M√©thode": ["KNN seul", "MICE seul", "Moyennage KNN/MICE"],
        "F1-Score": [perf_knn["f1_score"], perf_mice["f1_score"], f1],
        "Pr√©cision": [perf_knn["precision"], perf_mice["precision"], precision],
        "Rappel": [perf_knn["recall"], perf_mice["recall"], recall],
        "Seuil optimal": [thr_knn, thr_mice, best_thr_average]
    }
    
    df_comparison = pd.DataFrame(comparison_data)
    print(df_comparison.to_string(index=False, float_format='%.4f'))
    
    # D√©terminer le meilleur
    best_idx = df_comparison["F1-Score"].idxmax()
    best_method = df_comparison.loc[best_idx, "M√©thode"]
    best_f1 = df_comparison.loc[best_idx, "F1-Score"]
    
    print(f"\nüèÜ Meilleur mod√®le : {best_method} (F1 = {best_f1:.4f})")
    
    # 8. Affichage graphique de la matrice de confusion
    plt.figure(figsize=(4, 3))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
                xticklabels=["Pr√©dit: Non-ad", "Pr√©dit: Ad"],
                yticklabels=["R√©el: Non-ad", "R√©el: Ad"])
    plt.xlabel("Pr√©dit")
    plt.ylabel("R√©el")
    plt.title(f"Matrice de confusion\nMoyennage KNN/MICE (F1={f1:.3f}, seuil={best_thr_average:.2f})")
    plt.tight_layout()
    plt.show()
    
    # 9. Sauvegarde des r√©sultats
    print("\nüíæ Sauvegarde des r√©sultats...")
    
    # Cr√©er le mod√®le de moyennage
    average_model = {
        "knn_model": stack_knn,
        "mice_model": stack_mice,
        "threshold": float(best_thr_average),
        "performance": {
            "f1_score": float(f1),
            "precision": float(precision),
            "recall": float(recall)
        },
        "comparison": {
            "knn_f1": float(perf_knn["f1_score"]),
            "mice_f1": float(perf_mice["f1_score"]),
            "average_f1": float(f1)
        }
    }
    
    # Sauvegarder le mod√®le
    joblib.dump(average_model, stacking_dir / "stack_average_knn_mice.joblib")
    
    # Sauvegarder le seuil optimal
    with open(stacking_dir / "best_thr_stack_average_knn_mice.json", "w") as f:
        json.dump({"best_thr_stack_average_knn_mice": float(best_thr_average)}, f, indent=2)
    
    # Sauvegarder les m√©triques de performance
    performance_metrics = {
        "f1_score": float(f1),
        "precision": float(precision),
        "recall": float(recall),
        "threshold": float(best_thr_average),
        "confusion_matrix": cm.tolist()
    }
    
    with open(stacking_dir / "stack_average_knn_mice_performance.json", "w") as f:
        json.dump(performance_metrics, f, indent=2)
    
    # Sauvegarder la comparaison
    df_comparison.to_csv(stacking_dir / "comparison_average_knn_mice.csv", index=False)
    
    print("‚úÖ R√©sultats sauvegard√©s !")
    print(f"üìÅ Fichiers dans : {stacking_dir}")
    
    return average_model, df_comparison, f1, precision, recall, best_thr_average

# Ex√©cution
if __name__ == "__main__":
    # V√©rifier que les variables sont d√©finies
    required_vars = ["X_test_knn", "X_test_mice", "y_test_knn", "y_test_mice", "stacking_dir"]
    
    missing_vars = []
    for var in required_vars:
        if var not in globals():
            missing_vars.append(var)
    
    if missing_vars:
        print(f"‚ùå Variables manquantes : {missing_vars}")
        print("Assurez-vous que ces variables sont d√©finies dans votre notebook")
    else:
        # Ex√©cuter le moyennage
        average_model, df_comparison, f1, precision, recall, threshold = average_knn_mice_stacking(
            X_test_knn, X_test_mice, y_test_knn, y_test_mice, stacking_dir
        )
        
        print(f"\nüéâ Moyennage KNN/MICE termin√© !")
        print(f"üìä F1-Score final : {f1:.4f}")
        print(f"üéØ Seuil optimal : {threshold:.3f}") 